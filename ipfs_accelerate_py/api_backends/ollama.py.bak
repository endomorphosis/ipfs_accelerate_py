import asyncio
import json
import requests
import os
import logging
from typing import Dict, List, Optional, Union, Any, Callable

import time
import hashlib
import threading
import queue
import uuid
from concurrent.futures import ThreadPoolExecutor, Future

class ollama:
    """Ollama API Backend Integration
    
    This class provides a comprehensive interface for interacting with Ollama model endpoints.
    It supports all major Ollama API features including:
    - Text completion generation
    - Chat completions
    - Streaming responses
    - Text embeddings
    - Model management
    
    Features:
    - Dynamic endpoint management
    - Multiple response types (completion, chat, streaming, embeddings)
    - Async and sync request options
    - Request queueing and batch processing
    - Model listing and status tracking
    - Queue system with exponential backoff
    
    The handler methods follow these patterns:
    - completion: Takes a prompt, returns generated text
    - chat: Takes message list, returns assistant response
    - streaming: Takes prompt/messages, yields response chunks
    - embedding: Takes text, returns vector embedding
    """

    def __init__(self, resources=None, metadata=None):
        """Initialize Ollama backend interface
        
        Args:
            resources: Resources configuration dictionary
            metadata: Additional metadata dictionary
        """
        self.resources = resources
        self.metadata = metadata

        # Get API settings from metadata if available
        self.api_key = None
        self.api_url = None
        if metadata:
            self.api_key = metadata.get("api_key", None)
            self.api_url = metadata.get("api_url", None)
            self.ollama_model = metadata.get("ollama_model", "llama2")
            
        # Register method references
        self.create_remote_ollama_endpoint_handler = self.create_remote_ollama_endpoint_handler
        self.create_remote_ollama_chat_endpoint_handler = self.create_remote_ollama_chat_endpoint_handler
        self.create_remote_ollama_streaming_endpoint_handler = self.create_remote_ollama_streaming_endpoint_handler
        self.create_remote_ollama_embedding_endpoint_handler = self.create_remote_ollama_embedding_endpoint_handler
        self.request_ollama_endpoint = self.request_ollama_endpoint
        self.test_ollama_endpoint = self.test_ollama_endpoint
        self.make_post_request_ollama = self.make_post_request_ollama
        self.make_stream_request_ollama = self.make_stream_request_ollama
        self.make_async_post_request_ollama = self.make_async_post_request_ollama
        self.create_ollama_endpoint_handler = self.create_ollama_endpoint_handler
        self.create_ollama_chat_endpoint_handler = self.create_ollama_chat_endpoint_handler
        self.create_ollama_streaming_endpoint_handler = self.create_ollama_streaming_endpoint_handler
        self.create_ollama_embedding_endpoint_handler = self.create_ollama_embedding_endpoint_handler
        self.list_available_ollama_models = self.list_available_ollama_models
        self.list_models = self.list_models
        self.pull_model = self.pull_model
        self.chat = self.chat
        self.stream_chat = self.stream_chat
        self.init = self.init
        self.__test__ = self.__test__
        
        # Add endpoints tracking
        self.endpoints = {}
        self.endpoint_status = {}
        self.registered_models = {}
        
        # Configure logging
        self.logger = logging.getLogger("ollama_api")
        self.logger.setLevel(logging.INFO)
        if not self.logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
            handler.setFormatter(formatter)
            self.logger.addHandler(handler)
            
        # Retry and backoff settings
        self.max_retries = 5
        self.initial_retry_delay = 1
        self.backoff_factor = 2
        self.max_retry_delay = 60  # Maximum delay in seconds
        
        # Request queue settings
        self.queue_enabled = True
        self.queue_size = 100
        self.queue_processing = False
        self.current_requests = 0
        self.max_concurrent_requests = 5
        self.request_queue = []
        self.queue_lock = threading.RLock()
        
        # Stats tracking
        self.total_requests = 0
        self.successful_requests = 0
        self.failed_requests = 0
        self.total_tokens = 0
        self.input_tokens = 0
        self.output_tokens = 0
        
        # Initialize async queue for managing requests
        self.async_request_queue = asyncio.Queue(64)
        return None
    
    

    def _process_queue(self, endpoint_id=None):

    
    """Process requests in the queue for a specific endpoint or global queue"""

    
    # Get the endpoint or use global settings

    
    if endpoint_id and endpoint_id in self.endpoints:

    
    
    endpoint = self.endpoints[endpoint_id]

    
    
    with endpoint["queue_lock"]:

    
    
    
    if endpoint["queue_processing"]:

    
    
    
    
    return  # Another thread is already processing this endpoint's queue

    
    
    
    endpoint["queue_processing"] = True

    
    
    
    

    
    
    queue_to_process = endpoint["request_queue"]

    
    
    is_global_queue = False

    
    else:

    
    
    # Use global queue if no endpoint specified or endpoint doesn't exist

    
    
    with self.queue_lock:

    
    
    
    if self.queue_processing:

    
    
    
    
    return  # Another thread is already processing the global queue

    
    
    
    self.queue_processing = True

    
    
    
    

    
    
    queue_to_process = self.request_queue

    
    
    is_global_queue = True

    
    

    
    try:

    
    
    while True:

    
    
    
    # Get the next request from the queue

    
    
    
    request_info = None

    
    
    
    

    
    
    
    if is_global_queue:

    
    
    
    
    with self.queue_lock:

    
    
    
    
    
    if not queue_to_process:

    
    
    
    
    
    
    self.queue_processing = False

    
    
    
    
    
    
    break

    
    
    
    
    
    
    

    
    
    
    
    
    # Check if we're at the concurrent request limit

    
    
    
    
    
    if self.current_requests >= self.max_concurrent_requests:

    
    
    
    
    
    
    # Sleep briefly then check again

    
    
    
    
    
    
    time.sleep(0.1)

    
    
    
    
    
    
    continue

    
    
    
    
    
    
    

    
    
    
    
    
    # Get the next request and increase counter

    
    
    
    
    
    request_info = queue_to_process.pop(0)

    
    
    
    
    
    self.current_requests += 1

    
    
    
    else:

    
    
    
    
    with endpoint["queue_lock"]:

    
    
    
    
    
    if not queue_to_process:

    
    
    
    
    
    
    endpoint["queue_processing"] = False

    
    
    
    
    
    
    break

    
    
    
    
    
    
    

    
    
    
    
    
    # Check if we're at the concurrent request limit

    
    
    
    
    
    if endpoint["current_requests"] >= endpoint["max_concurrent_requests"]:

    
    
    
    
    
    
    # Sleep briefly then check again

    
    
    
    
    
    
    time.sleep(0.1)

    
    
    
    
    
    
    continue

    
    
    
    
    
    
    

    
    
    
    
    
    # Get the next request and increase counter

    
    
    
    
    
    request_info = queue_to_process.pop(0)

    
    
    
    
    
    endpoint["current_requests"] += 1

    
    
    
    

    
    
    
    # Process the request outside the lock

    
    
    
    if request_info:

    
    
    
    
    try:

    
    
    
    
    
    # Extract request details

    
    
    
    
    
    endpoint_url = request_info.get("endpoint_url")

    
    
    
    
    
    data = request_info.get("data")

    
    
    
    
    
    api_key = request_info.get("api_key")

    
    
    
    
    
    request_id = request_info.get("request_id")

    
    
    
    
    
    endpoint_id = request_info.get("endpoint_id")

    
    
    
    
    
    future = request_info.get("future")

    
    
    
    
    
    method_name = request_info.get("method", "make_request")

    
    
    
    
    
    method_args = request_info.get("args", [])

    
    
    
    
    
    method_kwargs = request_info.get("kwargs", {})

    
    
    
    
    
    

    
    
    
    
    
    # Make the request (without queueing again)

    
    
    
    
    
    # Save original queue_enabled value to prevent recursion

    
    
    
    
    
    if is_global_queue:

    
    
    
    
    
    
    original_queue_enabled = self.queue_enabled

    
    
    
    
    
    
    self.queue_enabled = False  # Disable queueing to prevent recursion

    
    
    
    
    
    else:

    
    
    
    
    
    
    original_queue_enabled = endpoint["queue_enabled"]

    
    
    
    
    
    
    endpoint["queue_enabled"] = False  # Disable queueing to prevent recursion

    
    
    
    
    
    

    
    
    
    
    
    try:

    
    
    
    
    
    
    # Make the request based on method name

    
    
    
    
    
    
    if hasattr(self, method_name) and callable(getattr(self, method_name)):

    
    
    
    
    
    
    
    method = getattr(self, method_name)

    
    
    
    
    
    
    
    

    
    
    
    
    
    
    
    # Call the method with the provided arguments

    
    
    
    
    
    
    
    if method_name.startswith("make_"):

    
    
    
    
    
    
    
    
    # Direct API request methods

    
    
    
    
    
    
    
    
    result = method(

    
    
    
    
    
    
    
    
    
    endpoint_url=endpoint_url,

    
    
    
    
    
    
    
    
    
    data=data,

    
    
    
    
    
    
    
    
    
    api_key=api_key,

    
    
    
    
    
    
    
    
    
    request_id=request_id,

    
    
    
    
    
    
    
    
    
    endpoint_id=endpoint_id

    
    
    
    
    
    
    
    
    )

    
    
    
    
    
    
    
    else:

    
    
    
    
    
    
    
    
    # Higher-level methods

    
    
    
    
    
    
    
    
    method_kwargs.update({

    
    
    
    
    
    
    
    
    
    "request_id": request_id,

    
    
    
    
    
    
    
    
    
    "endpoint_id": endpoint_id,

    
    
    
    
    
    
    
    
    
    "api_key": api_key

    
    
    
    
    
    
    
    
    })

    
    
    
    
    
    
    
    
    result = method(*method_args, **method_kwargs)

    
    
    
    
    
    
    else:

    
    
    
    
    
    
    
    # Fallback to make_request or similar method

    
    
    
    
    
    
    
    make_method = getattr(self, "make_request", None)

    
    
    
    
    
    
    
    if not make_method:

    
    
    
    
    
    
    
    
    make_method = getattr(self, f"make_post_request_{self.__class__.__name__.lower()}", None)

    
    
    
    
    
    
    
    
    

    
    
    
    
    
    
    
    if make_method and callable(make_method):

    
    
    
    
    
    
    
    
    result = make_method(

    
    
    
    
    
    
    
    
    
    endpoint_url=endpoint_url,

    
    
    
    
    
    
    
    
    
    data=data,

    
    
    
    
    
    
    
    
    
    api_key=api_key,

    
    
    
    
    
    
    
    
    
    request_id=request_id,

    
    
    
    
    
    
    
    
    
    endpoint_id=endpoint_id

    
    
    
    
    
    
    
    
    )

    
    
    
    
    
    
    
    else:

    
    
    
    
    
    
    
    
    raise AttributeError(f"Method {method_name} not found")

    
    
    
    
    
    
    

    
    
    
    
    
    
    # Store result in future

    
    
    
    
    
    
    future["result"] = result

    
    
    
    
    
    
    future["completed"] = True

    
    
    
    
    
    
    

    
    
    
    
    
    
    # Update counters

    
    
    
    
    
    
    if not is_global_queue:

    
    
    
    
    
    
    
    with endpoint["queue_lock"]:

    
    
    
    
    
    
    
    
    endpoint["successful_requests"] += 1

    
    
    
    
    
    
    
    
    endpoint["last_request_at"] = time.time()

    
    
    
    
    
    
    
    
    

    
    
    
    
    
    
    
    
    # Update token counts if present in result

    
    
    
    
    
    
    
    
    if isinstance(result, dict) and "usage" in result:

    
    
    
    
    
    
    
    
    
    usage = result["usage"]

    
    
    
    
    
    
    
    
    
    endpoint["total_tokens"] += usage.get("total_tokens", 0)

    
    
    
    
    
    
    
    
    
    endpoint["input_tokens"] += usage.get("prompt_tokens", 0)

    
    
    
    
    
    
    
    
    
    endpoint["output_tokens"] += usage.get("completion_tokens", 0)

    
    
    
    
    
    
    

    
    
    
    
    
    except Exception as e:

    
    
    
    
    
    
    # Store error in future

    
    
    
    
    
    
    future["error"] = e

    
    
    
    
    
    
    future["completed"] = True

    
    
    
    
    
    
    print(f"Error processing queued request: {str(e)}")

    
    
    
    
    
    
    

    
    
    
    
    
    
    # Update counters

    
    
    
    
    
    
    if not is_global_queue:

    
    
    
    
    
    
    
    with endpoint["queue_lock"]:

    
    
    
    
    
    
    
    
    endpoint["failed_requests"] += 1

    
    
    
    
    
    
    
    
    endpoint["last_request_at"] = time.time()

    
    
    
    
    
    

    
    
    
    
    
    finally:

    
    
    
    
    
    
    # Restore original queue_enabled value

    
    
    
    
    
    
    if is_global_queue:

    
    
    
    
    
    
    
    self.queue_enabled = original_queue_enabled

    
    
    
    
    
    
    else:

    
    
    
    
    
    
    
    endpoint["queue_enabled"] = original_queue_enabled

    
    
    
    
    

    
    
    
    
    finally:

    
    
    
    
    
    # Decrement counter

    
    
    
    
    
    if is_global_queue:

    
    
    
    
    
    
    with self.queue_lock:

    
    
    
    
    
    
    
    self.current_requests = max(0, self.current_requests - 1)

    
    
    
    
    
    else:

    
    
    
    
    
    
    with endpoint["queue_lock"]:

    
    
    
    
    
    
    
    endpoint["current_requests"] = max(0, endpoint["current_requests"] - 1)

    
    
    
    
    

    
    
    
    
    # Brief pause to prevent CPU hogging

    
    
    
    
    time.sleep(0.01)

    
    
    
    
    

    
    except Exception as e:

    
    
    print(f"Error in queue processing thread: {str(e)}")

    
    
    

    
    finally:

    
    
    # Reset queue processing flag

    
    
    if is_global_queue:

    
    
    
    with self.queue_lock:

    
    
    
    
    self.queue_processing = False

    
    
    else:

    
    
    
    with endpoint["queue_lock"]:

    
    
    
    
    endpoint["queue_processing"] = False


    def create_endpoint(self, endpoint_id=None, api_key=None, max_retries=None, initial_retry_delay=None, 

    
    
    
    
       backoff_factor=None, max_retry_delay=None, queue_enabled=None, 

    
    
    
    
       max_concurrent_requests=None, queue_size=None):

    
    """Create a new endpoint with its own settings and counters"""

    
    # Generate a unique endpoint ID if not provided

    
    if endpoint_id is None:

    
    
    endpoint_id = f"endpoint_{int(time.time())}_{hashlib.md5(str(time.time()).encode()).hexdigest()[:8]}"

    
    
    

    
    # Use provided values or defaults

    
    endpoint_settings = {

    
    
    "api_key": api_key if api_key is not None else self.api_key,

    
    
    "max_retries": max_retries if max_retries is not None else self.max_retries,

    
    
    "initial_retry_delay": initial_retry_delay if initial_retry_delay is not None else self.initial_retry_delay,

    
    
    "backoff_factor": backoff_factor if backoff_factor is not None else self.backoff_factor,

    
    
    "max_retry_delay": max_retry_delay if max_retry_delay is not None else self.max_retry_delay,

    
    
    "queue_enabled": queue_enabled if queue_enabled is not None else self.queue_enabled,

    
    
    "max_concurrent_requests": max_concurrent_requests if max_concurrent_requests is not None else self.max_concurrent_requests,

    
    
    "queue_size": queue_size if queue_size is not None else self.queue_size,

    
    
    

    
    
    # Initialize endpoint-specific counters and state

    
    
    "current_requests": 0,

    
    
    "total_requests": 0,

    
    
    "successful_requests": 0,

    
    
    "failed_requests": 0,

    
    
    "total_tokens": 0,

    
    
    "input_tokens": 0,

    
    
    "output_tokens": 0,

    
    
    "queue_processing": False,

    
    
    "request_queue": [],

    
    
    "queue_lock": threading.RLock(),

    
    
    "created_at": time.time(),

    
    
    "last_request_at": None

    
    }

    
    

    
    # Store the endpoint settings

    
    self.endpoints[endpoint_id] = endpoint_settings

    
    

    
    return endpoint_id


    

    def get_endpoint(self, endpoint_id=None):

    
    """Get an endpoint's settings or create a default one if not found"""

    
    # If no endpoint_id provided, use the first one or create a default

    
    if endpoint_id is None:

    
    
    if not self.endpoints:

    
    
    
    endpoint_id = self.create_endpoint()

    
    
    else:

    
    
    
    endpoint_id = next(iter(self.endpoints))

    
    
    
    

    
    # If endpoint doesn't exist, create it

    
    if endpoint_id not in self.endpoints:

    
    
    endpoint_id = self.create_endpoint(endpoint_id=endpoint_id)

    
    
    

    
    return self.endpoints[endpoint_id]


    

    def update_endpoint(self, endpoint_id, **kwargs):

    
    """Update an endpoint's settings"""

    
    if endpoint_id not in self.endpoints:

    
    
    raise ValueError(f"Endpoint {endpoint_id} not found")

    
    
    

    
    # Update only the provided settings

    
    for key, value in kwargs.items():

    
    
    if key in self.endpoints[endpoint_id]:

    
    
    
    self.endpoints[endpoint_id][key] = value

    
    
    
    

    
    return self.endpoints[endpoint_id]


    def _process_queue(self, endpoint_id=None):

    
    """Process requests in the queue for a specific endpoint or global queue"""

    
    # Get the endpoint or use global settings

    
    if endpoint_id and endpoint_id in self.endpoints:

    
    
    endpoint = self.endpoints[endpoint_id]

    
    
    with endpoint["queue_lock"]:

    
    
    
    if endpoint["queue_processing"]:

    
    
    
    
    return  # Another thread is already processing this endpoint's queue

    
    
    
    endpoint["queue_processing"] = True

    
    
    
    

    
    
    queue_to_process = endpoint["request_queue"]

    
    
    is_global_queue = False

    
    else:

    
    
    # Use global queue if no endpoint specified or endpoint doesn't exist

    
    
    with self.queue_lock:

    
    
    
    if self.queue_processing:

    
    
    
    
    return  # Another thread is already processing the global queue

    
    
    
    self.queue_processing = True

    
    
    
    

    
    
    queue_to_process = self.request_queue

    
    
    is_global_queue = True

    
    

    
    try:

    
    
    while True:

    
    
    
    # Get the next request from the queue

    
    
    
    request_info = None

    
    
    
    

    
    
    
    if is_global_queue:

    
    
    
    
    with self.queue_lock:

    
    
    
    
    
    if not queue_to_process:

    
    
    
    
    
    
    self.queue_processing = False

    
    
    
    
    
    
    break

    
    
    
    
    
    
    

    
    
    
    
    
    # Check if we're at the concurrent request limit

    
    
    
    
    
    if self.current_requests >= self.max_concurrent_requests:

    
    
    
    
    
    
    # Sleep briefly then check again

    
    
    
    
    
    
    time.sleep(0.1)

    
    
    
    
    
    
    continue

    
    
    
    
    
    
    

    
    
    
    
    
    # Get the next request and increase counter

    
    
    
    
    
    request_info = queue_to_process.pop(0)

    
    
    
    
    
    self.current_requests += 1

    
    
    
    else:

    
    
    
    
    with endpoint["queue_lock"]:

    
    
    
    
    
    if not queue_to_process:

    
    
    
    
    
    
    endpoint["queue_processing"] = False

    
    
    
    
    
    
    break

    
    
    
    
    
    
    

    
    
    
    
    
    # Check if we're at the concurrent request limit

    
    
    
    
    
    if endpoint["current_requests"] >= endpoint["max_concurrent_requests"]:

    
    
    
    
    
    
    # Sleep briefly then check again

    
    
    
    
    
    
    time.sleep(0.1)

    
    
    
    
    
    
    continue

    
    
    
    
    
    
    

    
    
    
    
    
    # Get the next request and increase counter

    
    
    
    
    
    request_info = queue_to_process.pop(0)

    
    
    
    
    
    endpoint["current_requests"] += 1

    
    
    
    

    
    
    
    # Process the request outside the lock

    
    
    
    if request_info:

    
    
    
    
    try:

    
    
    
    
    
    # Extract request details

    
    
    
    
    
    endpoint_url = request_info.get("endpoint_url")

    
    
    
    
    
    data = request_info.get("data")

    
    
    
    
    
    api_key = request_info.get("api_key")

    
    
    
    
    
    request_id = request_info.get("request_id")

    
    
    
    
    
    endpoint_id = request_info.get("endpoint_id")

    
    
    
    
    
    future = request_info.get("future")

    
    
    
    
    
    method_name = request_info.get("method", "make_request")

    
    
    
    
    
    method_args = request_info.get("args", [])

    
    
    
    
    
    method_kwargs = request_info.get("kwargs", {})

    
    
    
    
    
    

    
    
    
    
    
    # Make the request (without queueing again)

    
    
    
    
    
    # Save original queue_enabled value to prevent recursion

    
    
    
    
    
    if is_global_queue:

    
    
    
    
    
    
    original_queue_enabled = self.queue_enabled

    
    
    
    
    
    
    self.queue_enabled = False  # Disable queueing to prevent recursion

    
    
    
    
    
    else:

    
    
    
    
    
    
    original_queue_enabled = endpoint["queue_enabled"]

    
    
    
    
    
    
    endpoint["queue_enabled"] = False  # Disable queueing to prevent recursion

    
    
    
    
    
    

    
    
    
    
    
    try:

    
    
    
    
    
    
    # Make the request based on method name

    
    
    
    
    
    
    if hasattr(self, method_name) and callable(getattr(self, method_name)):

    
    
    
    
    
    
    
    method = getattr(self, method_name)

    
    
    
    
    
    
    
    

    
    
    
    
    
    
    
    # Call the method with the provided arguments

    
    
    
    
    
    
    
    if method_name.startswith("make_"):

    
    
    
    
    
    
    
    
    # Direct API request methods

    
    
    
    
    
    
    
    
    result = method(

    
    
    
    
    
    
    
    
    
    endpoint_url=endpoint_url,

    
    
    
    
    
    
    
    
    
    data=data,

    
    
    
    
    
    
    
    
    
    api_key=api_key,

    
    
    
    
    
    
    
    
    
    request_id=request_id,

    
    
    
    
    
    
    
    
    
    endpoint_id=endpoint_id

    
    
    
    
    
    
    
    
    )

    
    
    
    
    
    
    
    else:

    
    
    
    
    
    
    
    
    # Higher-level methods

    
    
    
    
    
    
    
    
    method_kwargs.update({

    
    
    
    
    
    
    
    
    
    "request_id": request_id,

    
    
    
    
    
    
    
    
    
    "endpoint_id": endpoint_id,

    
    
    
    
    
    
    
    
    
    "api_key": api_key

    
    
    
    
    
    
    
    
    })

    
    
    
    
    
    
    
    
    result = method(*method_args, **method_kwargs)

    
    
    
    
    
    
    else:

    
    
    
    
    
    
    
    # Fallback to make_request or similar method

    
    
    
    
    
    
    
    make_method = getattr(self, "make_request", None)

    
    
    
    
    
    
    
    if not make_method:

    
    
    
    
    
    
    
    
    make_method = getattr(self, f"make_post_request_{self.__class__.__name__.lower()}", None)

    
    
    
    
    
    
    
    
    

    
    
    
    
    
    
    
    if make_method and callable(make_method):

    
    
    
    
    
    
    
    
    result = make_method(

    
    
    
    
    
    
    
    
    
    endpoint_url=endpoint_url,

    
    
    
    
    
    
    
    
    
    data=data,

    
    
    
    
    
    
    
    
    
    api_key=api_key,

    
    
    
    
    
    
    
    
    
    request_id=request_id,

    
    
    
    
    
    
    
    
    
    endpoint_id=endpoint_id

    
    
    
    
    
    
    
    
    )

    
    
    
    
    
    
    
    else:

    
    
    
    
    
    
    
    
    raise AttributeError(f"Method {method_name} not found")

    
    
    
    
    
    
    

    
    
    
    
    
    
    # Store result in future

    
    
    
    
    
    
    future["result"] = result

    
    
    
    
    
    
    future["completed"] = True

    
    
    
    
    
    
    

    
    
    
    
    
    
    # Update counters

    
    
    
    
    
    
    if not is_global_queue:

    
    
    
    
    
    
    
    with endpoint["queue_lock"]:

    
    
    
    
    
    
    
    
    endpoint["successful_requests"] += 1

    
    
    
    
    
    
    
    
    endpoint["last_request_at"] = time.time()

    
    
    
    
    
    
    
    
    

    
    
    
    
    
    
    
    
    # Update token counts if present in result

    
    
    
    
    
    
    
    
    if isinstance(result, dict) and "usage" in result:

    
    
    
    
    
    
    
    
    
    usage = result["usage"]

    
    
    
    
    
    
    
    
    
    endpoint["total_tokens"] += usage.get("total_tokens", 0)

    
    
    
    
    
    
    
    
    
    endpoint["input_tokens"] += usage.get("prompt_tokens", 0)

    
    
    
    
    
    
    
    
    
    endpoint["output_tokens"] += usage.get("completion_tokens", 0)

    
    
    
    
    
    
    

    
    
    
    
    
    except Exception as e:

    
    
    
    
    
    
    # Store error in future

    
    
    
    
    
    
    future["error"] = e

    
    
    
    
    
    
    future["completed"] = True

    
    
    
    
    
    
    print(f"Error processing queued request: {str(e)}")

    
    
    
    
    
    
    

    
    
    
    
    
    
    # Update counters

    
    
    
    
    
    
    if not is_global_queue:

    
    
    
    
    
    
    
    with endpoint["queue_lock"]:

    
    
    
    
    
    
    
    
    endpoint["failed_requests"] += 1

    
    
    
    
    
    
    
    
    endpoint["last_request_at"] = time.time()

    
    
    
    
    
    

    
    
    
    
    
    finally:

    
    
    
    
    
    
    # Restore original queue_enabled value

    
    
    
    
    
    
    if is_global_queue:

    
    
    
    
    
    
    
    self.queue_enabled = original_queue_enabled

    
    
    
    
    
    
    else:

    
    
    
    
    
    
    
    endpoint["queue_enabled"] = original_queue_enabled

    
    
    
    
    

    
    
    
    
    finally:

    
    
    
    
    
    # Decrement counter

    
    
    
    
    
    if is_global_queue:

    
    
    
    
    
    
    with self.queue_lock:

    
    
    
    
    
    
    
    self.current_requests = max(0, self.current_requests - 1)

    
    
    
    
    
    else:

    
    
    
    
    
    
    with endpoint["queue_lock"]:

    
    
    
    
    
    
    
    endpoint["current_requests"] = max(0, endpoint["current_requests"] - 1)

    
    
    
    
    

    
    
    
    
    # Brief pause to prevent CPU hogging

    
    
    
    
    time.sleep(0.01)

    
    
    
    
    

    
    except Exception as e:

    
    
    print(f"Error in queue processing thread: {str(e)}")

    
    
    

    
    finally:

    
    
    # Reset queue processing flag

    
    
    if is_global_queue:

    
    
    
    with self.queue_lock:

    
    
    
    
    self.queue_processing = False

    
    
    else:

    
    
    
    with endpoint["queue_lock"]:

    
    
    
    
    endpoint["queue_processing"] = False


    

    

    def get_stats(self, endpoint_id=None):

    
    """Get usage statistics for an endpoint or global stats"""

    
    if endpoint_id and endpoint_id in self.endpoints:

    
    
    endpoint = self.endpoints[endpoint_id]

    
    
    stats = {

    
    
    
    "endpoint_id": endpoint_id,

    
    
    
    "total_requests": endpoint["total_requests"],

    
    
    
    "successful_requests": endpoint["successful_requests"],

    
    
    
    "failed_requests": endpoint["failed_requests"],

    
    
    
    "total_tokens": endpoint["total_tokens"],

    
    
    
    "input_tokens": endpoint["input_tokens"],

    
    
    
    "output_tokens": endpoint["output_tokens"],

    
    
    
    "created_at": endpoint["created_at"],

    
    
    
    "last_request_at": endpoint["last_request_at"],

    
    
    
    "current_queue_size": len(endpoint["request_queue"]),

    
    
    
    "current_requests": endpoint["current_requests"]

    
    
    }

    
    
    return stats

    
    else:

    
    
    # Aggregate stats across all endpoints

    
    
    total_requests = sum(e["total_requests"] for e in self.endpoints.values()) if self.endpoints else 0

    
    
    successful_requests = sum(e["successful_requests"] for e in self.endpoints.values()) if self.endpoints else 0

    
    
    failed_requests = sum(e["failed_requests"] for e in self.endpoints.values()) if self.endpoints else 0

    
    
    total_tokens = sum(e["total_tokens"] for e in self.endpoints.values()) if self.endpoints else 0

    
    
    input_tokens = sum(e["input_tokens"] for e in self.endpoints.values()) if self.endpoints else 0

    
    
    output_tokens = sum(e["output_tokens"] for e in self.endpoints.values()) if self.endpoints else 0

    
    
    

    
    
    stats = {

    
    
    
    "endpoints_count": len(self.endpoints),

    
    
    
    "total_requests": total_requests,

    
    
    
    "successful_requests": successful_requests,

    
    
    
    "failed_requests": failed_requests,

    
    
    
    "total_tokens": total_tokens,

    
    
    
    "input_tokens": input_tokens,

    
    
    
    "output_tokens": output_tokens,

    
    
    
    "global_queue_size": len(self.request_queue),

    
    
    
    "global_current_requests": self.current_requests

    
    
    }

    
    
    return stats


    

    def reset_stats(self, endpoint_id=None):

    
    """Reset usage statistics for an endpoint or globally"""

    
    if endpoint_id and endpoint_id in self.endpoints:

    
    
    # Reset stats just for this endpoint

    
    
    endpoint = self.endpoints[endpoint_id]

    
    
    endpoint["total_requests"] = 0

    
    
    endpoint["successful_requests"] = 0

    
    
    endpoint["failed_requests"] = 0

    
    
    endpoint["total_tokens"] = 0

    
    
    endpoint["input_tokens"] = 0

    
    
    endpoint["output_tokens"] = 0

    
    elif endpoint_id is None:

    
    
    # Reset stats for all endpoints

    
    
    for endpoint in self.endpoints.values():

    
    
    
    endpoint["total_requests"] = 0

    
    
    
    endpoint["successful_requests"] = 0

    
    
    
    endpoint["failed_requests"] = 0

    
    
    
    endpoint["total_tokens"] = 0

    
    
    
    endpoint["input_tokens"] = 0

    
    
    
    endpoint["output_tokens"] = 0

    
    else:

    
    
    raise ValueError(f"Endpoint {endpoint_id} not found")
