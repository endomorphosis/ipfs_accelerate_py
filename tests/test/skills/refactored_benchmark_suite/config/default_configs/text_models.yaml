# Default configuration for text models benchmarking

models:
  - id: bert-base-uncased
    task: fill-mask
    batch_sizes: [1, 2, 4, 8]
    sequence_lengths: [16, 32, 64, 128]
  
  - id: gpt2
    task: text-generation
    batch_sizes: [1, 2, 4]
    sequence_lengths: [32, 64, 128]
    
  - id: t5-small
    task: text2text-generation
    batch_sizes: [1, 2]
    sequence_lengths: [32, 64]
    
  - id: facebook/bart-base
    task: text2text-generation
    batch_sizes: [1, 2]
    sequence_lengths: [32, 64]

# Hardware platforms to benchmark on
hardware:
  - cpu
  - cuda  # Will be ignored if not available

# Metrics to collect
metrics:
  - latency
  - throughput
  - memory
  - flops

# Benchmark parameters
warmup_iterations: 5
test_iterations: 20

# Output options
output_dir: benchmark_results
save_results: true

# Export options
export:
  formats:
    - json
    - csv
    - markdown