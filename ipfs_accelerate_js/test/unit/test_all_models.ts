// FIXME: Complex template literal
/**;
 * Converted import { {expect, describe: any, it, beforeEach: any, afterEach} from "jest"; } from "Python: test_all_models.py;"
 * Conversion date: 2025-03-11 04:08:51;
 * This file was automatically converted from Python to TypeScript.;
 * Conversion fidelity might not be 100%, please manual review recommended.;
 */;
";"

// WebGPU related imports;
// Import hardware detection capabilities if ((($1) {
try ${$1} catch(error) { any)) { any {HAS_HARDWARE_DETECTION: any: any: any = false;
// We'll detect hardware manually as fallback;'
  /** Unified test runner for ((all Hugging Face model families.}
  This script provides a centralized interface for testing different model families,;
  generating reports, && summarizing results across model architectures. */;

}
  import * as module; from "*";"
  import * as module; from "*";"
  import * as module; from "*";"
  import * as module; from "*";"
  import * as module; from "*";"
  import * as module; from "*";"
  import * as module; from "*";"
  import * as module; from "*";"
// Configure logging;
  logging.basicConfig() {)level = logging.INFO, format) { any) { any: any: any = '%())asctime)s - %())levelname)s - %())message)s');'
  logger: any: any: any = logging.getLogger())__name__;
// Constants;
  CURRENT_DIR: any: any: any = Path())os.path.dirname())os.path.abspath())__file__));
  RESULTS_DIR: any: any: any = CURRENT_DIR / "collected_results";"
  SUMMARY_FILE: any: any: any = CURRENT_DIR / "test_summary.json";"
  REPORT_FILE: any: any: any = CURRENT_DIR / "test_report.md";"
// Map of model categories to test modules;
  MODEL_FAMILIES: any: any = {}
  "bert": {}"
  "module": "test_hf_bert",;"
  "description": "BERT-family masked language models",;"
  "default_model": "bert-base-uncased",;"
  "class": "TestBertModels",;"
  "status": "complete";"
  },;
  "gpt2": {}"
  "module": "test_hf_gpt2",;"
  "description": "GPT-2 causal language models",;"
  "default_model": "gpt2",;"
  "class": "TestGpt2Models",;"
  "status": "complete";"
  },;
  "t5": {}"
  "module": "test_hf_t5",;"
  "description": "T5 encoder-decoder models",;"
  "default_model": "t5-small",;"
  "class": "TestT5Models",;"
  "status": "complete";"
  },;
  "clip": {}"
  "module": "test_hf_clip",;"
  "description": "CLIP vision-language models",;"
  "default_model": "openai/clip-vit-base-patch32",;"
  "class": "TestClipModels",;"
  "status": "complete";"
  },;
  "llama": {}"
  "module": "test_hf_llama",;"
  "description": "LLaMA causal language models",;"
  "default_model": "meta-llama/Llama-2-7b-hf",;"
  "class": "TestLlamaModels",;"
  "status": "complete";"
  },;
  "whisper": {}"
  "module": "test_hf_whisper",;"
  "description": "Whisper speech recognition models",;"
  "default_model": "openai/whisper-tiny",;"
  "class": "TestWhisperModels",;"
  "status": "complete";"
  },;
  "wav2vec2": {}"
  "module": "test_hf_wav2vec2",;"
  "description": "Wav2Vec2 speech models",;"
  "default_model": "facebook/wav2vec2-base",;"
  "class": "TestWav2Vec2Models",;"
  "status": "complete";"
  },;
  "vit": {}"
  "module": "test_hf_vit",;"
  "description": "Vision Transformer models",;"
  "default_model": "google/vit-base-patch16-224",;"
  "class": "TestVitModels",;"
  "status": "complete";"
  },;
  "detr": {}"
  "module": "test_hf_detr",;"
  "description": "Detection Transformer models for ((object detection",;"
  "default_model") {"facebook/detr-resnet-50",;"
  "class") { "TestDetrModels",;"
  "status": "complete"},;"
  "layoutlmv2": {}"
  "module": "test_hf_layoutlmv2",;"
  "description": "LayoutLMv2 models for ((document understanding",;"
  "default_model") {"microsoft/layoutlmv2-base-uncased",;"
  "class") { "TestLayoutLMv2Models",;"
  "status": "complete"},;"
  "time_series_transformer": {}"
  "module": "test_hf_time_series_transformer",;"
  "description": "Time Series Transformer models for ((forecasting",;"
  "default_model") {"huggingface/time-series-transformer-tourism-monthly",;"
  "class") { "TestTimeSeriesTransformerModels",;"
  "status": "complete"},;"
  "llava": {}"
  "module": "test_hf_llava",;"
  "description": "Large Language-and-Vision Assistant models",;"
  "default_model": "llava-hf/llava-1.5-7b-hf",;"
  "class": "TestLlavaModels",;"
  "status": "complete";"
  },;
  "roberta": {}"
  "module": "test_hf_roberta",;"
  "description": "RoBERTa masked language models",;"
  "default_model": "roberta-base",;"
  "class": "TestRobertaModels",;"
  "status": "complete";"
  },;
  "phi": {}"
  "module": "test_hf_phi",;"
  "description": "Phi language models from Microsoft",;"
  "default_model": "microsoft/phi-2",;"
  "class": "TestPhiModels",;"
  "status": "complete";"
  },;
  "distilbert": {}"
  "module": "test_hf_distilbert",;"
  "description": "DistilBERT masked language models",;"
  "default_model": "distilbert-base-uncased",;"
  "class": "TestDistilBertModels",;"
  "status": "complete";"
  },;
  "visual_bert": {}"
  "module": "test_hf_visual_bert",;"
  "description": "VisualBERT for ((vision-language tasks",;"
  "default_model") {"uclanlp/visualbert-vqa-coco-pre",;"
  "class") { "TestVisualBertModels",;"
  "status": "complete"},;"
  "zoedepth": {}"
  "module": "test_hf_zoedepth",;"
  "description": "ZoeDepth monocular depth estimation models",;"
  "default_model": "isl-org/ZoeDepth",;"
  "class": "TestZoeDepthModels",;"
  "status": "complete";"
  },;
  "mistral": {}"
  "module": "test_hf_mistral",;"
  "description": "Mistral causal language models",;"
  "default_model": "mistralai/Mistral-7B-v0.1",;"
  "class": "TestMistralModels",;"
  "status": "complete";"
  },;
  "blip": {}"
  "module": "test_hf_blip",;"
  "description": "BLIP vision-language models",;"
  "default_model": "Salesforce/blip-image-captioning-base",;"
  "class": "TestBlipModels",;"
  "status": "complete";"
  },;
  "sam": {}"
  "module": "test_hf_sam",;"
  "description": "Segment Anything Model for ((image segmentation",;"
  "default_model") {"facebook/sam-vit-base",;"
  "class") { "TestSamModels",;"
  "status": "complete"},;"
  "owlvit": {}"
  "module": "test_hf_owlvit",;"
  "description": "Open-vocabulary object detection with Vision Transformers",;"
  "default_model": "google/owlvit-base-patch32",;"
  "class": "TestOwlvitModels",;"
  "status": "complete";"
  },;
  "gemma": {}"
  "module": "test_hf_gemma",;"
  "description": "Gemma language models from Google",;"
  "default_model": "google/gemma-2b",;"
  "class": "TestGemmaModels",;"
  "status": "complete";"
  },;
  "musicgen": {}"
  "module": "test_hf_musicgen",;"
  "description": "MusicGen music generation models from AudioCraft",;"
  "default_model": "facebook/musicgen-small",;"
  "class": "TestMusicgenModels",;"
  "status": "complete";"
  },;
  "hubert": {}"
  "module": "test_hf_hubert",;"
  "description": "HuBERT speech representation models",;"
  "default_model": "facebook/hubert-base-ls960",;"
  "class": "TestHubertModels",;"
  "status": "complete";"
  },;
  "donut": {}"
  "module": "test_hf_donut",;"
  "description": "Donut document understanding transformer",;"
  "default_model": "naver-clova-ix/donut-base-finetuned-docvqa",;"
  "class": "TestDonutModels",;"
  "status": "complete";"
  },;
  "layoutlmv3": {}"
  "module": "test_hf_layoutlmv3",;"
  "description": "LayoutLMv3 models for ((document understanding",;"
  "default_model") {"microsoft/layoutlmv3-base",;"
  "class") { "TestLayoutLMv3Models",;"
  "status": "complete"},;"
  "markuplm": {}"
  "module": "test_hf_markuplm",;"
  "description": "MarkupLM models for ((markup language understanding",;"
  "default_model") {"microsoft/markuplm-base",;"
  "class") { "TestMarkupLMModels",;"
  "status": "complete"},;"
  "mamba": {}"
  "module": "test_hf_mamba",;"
  "description": "Mamba state space models for ((language modeling",;"
  "default_model") {"state-spaces/mamba-2.8b",;"
  "class") { "TestMambaModels",;"
  "status": "complete"},;"
  "phi3": {}"
  "module": "test_hf_phi3",;"
  "description": "Phi-3 language models from Microsoft",;"
  "default_model": "microsoft/phi-3-mini-4k-instruct",;"
  "class": "TestPhi3Models",;"
  "status": "complete";"
  },;
  "paligemma": {}"
  "module": "test_hf_paligemma",;"
  "description": "PaLI-GEMMA vision-language models from Google",;"
  "default_model": "google/paligemma-3b-mix-224",;"
  "class": "TestPaliGemmaModels",;"
  "status": "complete";"
  },;
  "mixtral": {}"
  "module": "test_hf_mixtral",;"
  "description": "Mixtral mixture-of-experts language models",;"
  "default_model": "mistralai/Mixtral-8x7B-v0.1",;"
  "class": "TestMixtralModels",;"
  "status": "complete";"
  },;
  "deberta_v2": {}"
  "module": "test_hf_deberta_v2",;"
  "description": "DeBERTa-V2 models with enhanced disentangled attention",;"
  "default_model": "microsoft/deberta-v2-xlarge",;"
  "class": "TestDebertaV2Models",;"
  "status": "complete";"
  },;
  "video_llava": {}"
  "module": "test_hf_video_llava",;"
  "description": "Video-LLaVA video understanding models",;"
  "default_model": "LanguageBind/Video-LLaVA-7B",;"
  "class": "TestVideoLlavaModels",;"
  "status": "complete";"
  },;
  "blip2": {}"
  "module": "test_hf_blip_2",;"
  "description": "BLIP-2 vision-language models",;"
  "default_model": "Salesforce/blip2-opt-2.7b",;"
  "class": "TestBlip2Models",;"
  "status": "complete";"
  },;
  "instructblip": {}"
  "module": "test_hf_instructblip",;"
  "description": "InstructBLIP vision-language instruction-tuned models",;"
  "default_model": "Salesforce/instructblip-flan-t5-xl",;"
  "class": "TestInstructBlipModels",;"
  "status": "complete";"
  },;
  "swin": {}"
  "module": "test_hf_swin",;"
  "description": "Swin Transformer vision models",;"
  "default_model": "microsoft/swin-base-patch4-window7-224",;"
  "class": "TestSwinModels",;"
  "status": "complete";"
  },;
  "convnext": {}"
  "module": "test_hf_convnext",;"
  "description": "ConvNeXT vision models",;"
  "default_model": "facebook/convnext-base-224",;"
  "class": "TestConvNextModels",;"
  "status": "complete";"
  },;
  "seamless_m4t": {}"
  "module": "test_hf_seamless_m4t",;"
  "description": "Seamless multilingual && multimodal translation models",;"
  "default_model": "facebook/seamless-m4t-large",;"
  "class": "TestSeamlessM4TModels",;"
  "status": "complete";"
  },;
  "wavlm": {}"
  "module": "test_hf_wavlm",;"
  "description": "WavLM speech processing models",;"
  "default_model": "microsoft/wavlm-base",;"
  "class": "TestWavLMModels",;"
  "status": "complete";"
  },;
  "codellama": {}"
  "module": "test_hf_codellama",;"
  "description": "CodeLlama for ((code generation",;"
  "default_model") {"codellama/CodeLlama-7b-hf",;"
  "class") { "TestCodeLlamaModels",;"
  "status": "complete"},;"
  "starcoder2": {}"
  "module": "test_hf_starcoder2",;"
  "description": "StarCoder2 for ((code generation",;"
  "default_model") {"bigcode/starcoder2-3b",;"
  "class") { "TestStarcoder2Models",;"
  "status": "complete"},;"
  "qwen2": {}"
  "module": "test_hf_qwen2",;"
  "description": "Qwen2 models from Alibaba",;"
  "default_model": "Qwen/Qwen2-7B-Instruct",;"
  "class": "TestQwen2Models",;"
  "status": "complete";"
  },;
  "bart": {}"
  "module": "test_hf_bart",;"
  "description": "BART sequence-to-sequence models",;"
  "default_model": "facebook/bart-large-cnn",;"
  "class": "TestBartModels",;"
  "status": "complete";"
  },;
  "segformer": {}"
  "module": "test_hf_segformer",;"
  "description": "SegFormer models for ((image segmentation",;"
  "default_model") {"nvidia/segformer-b0-finetuned-ade-512-512",;"
  "class") { "TestSegformerModels",;"
  "status": "complete"},;"
  "dinov2": {}"
  "module": "test_hf_dinov2",;"
  "description": "DINOv2 this-supervised vision models",;"
  "default_model": "facebook/dinov2-base",;"
  "class": "TestDinov2Models",;"
  "status": "complete";"
  },;
  "mamba2": {}"
  "module": "test_hf_mamba2",;"
  "description": "Mamba2 state space models",;"
  "default_model": "state-spaces/mamba2-2.8b",;"
  "class": "TestMamba2Models",;"
  "status": "complete";"
  },;
  "phi4": {}"
  "module": "test_hf_phi4",;"
  "description": "Phi-4 language models from Microsoft",;"
  "default_model": "microsoft/phi-4-mini-instruct",;"
  "class": "TestPhi4Models",;"
  "status": "complete";"
  },;
  "rwkv": {}"
  "module": "test_hf_rwkv",;"
  "description": "RWKV Receptance Weighted Key Value models",;"
  "default_model": "RWKV/rwkv-4-pile-430m",;"
  "class": "TestRwkvModels",;"
  "status": "complete";"
  },;
  "depth_anything": {}"
  "module": "test_hf_depth_anything",;"
  "description": "Depth Anything models for ((universal depth estimation",;"
  "default_model") {"LiheYoung/depth-anything-small",;"
  "class") { "TestDepthAnythingModels",;"
  "status": "complete"},;"
  "qwen2_audio": {}"
  "module": "test_hf_qwen2_audio",;"
  "description": "Qwen2 Audio models for ((speech understanding",;"
  "default_model") {"Qwen/Qwen2-Audio-7B",;"
  "class") { "TestQwen2AudioModels",;"
  "status": "complete"},;"
  "kosmos_2": {}"
  "module": "test_hf_kosmos_2",;"
  "description": "KOSMOS-2 multimodal language models with reference grounding",;"
  "default_model": "microsoft/kosmos-2-patch14-224",;"
  "class": "TestKosmos2Models",;"
  "status": "complete";"
  },;
  "grounding_dino": {}"
  "module": "test_hf_grounding_dino",;"
  "description": "Grounding DINO models for ((open-set object detection",;"
  "default_model") {"IDEA-Research/grounding-dino-base",;"
  "class") { "TestGroundingDinoModels",;"
  "status": "complete"},;"
  "wav2vec2_bert": {}"
  "module": "test_hf_wav2vec2_bert",;"
  "description": "Wav2Vec2-BERT for ((speech && language understanding",;"
  "default_model") {"facebook/wav2vec2-bert-base",;"
  "class") { "TestWav2Vec2BertModels",;"
  "status": "complete"},;"
  "idefics3": {}"
  "module": "test_hf_idefics3",;"
  "description": "IDEFICS3 vision-language models",;"
  "default_model": "HuggingFaceM4/idefics3-8b",;"
  "class": "TestIdefics3Models",;"
  "status": "complete";"
  },;
  "deepseek": {}"
  "module": "test_hf_deepseek",;"
  "description": "DeepSeek language models",;"
  "default_model": "deepseek-ai/deepseek-llm-7b-base",;"
  "class": "TestDeepSeekModels",;"
  "status": "complete";"
  },;
  "siglip": {}"
  "module": "test_hf_siglip",;"
  "description": "SigLIP vision-language models with sigmoid loss",;"
  "default_model": "google/siglip-base-patch16-224",;"
  "class": "TestSiglipModels",;"
  "status": "complete";"
  },;
  "qwen2_vl": {}"
  "module": "test_hf_qwen2_vl",;"
  "description": "Qwen2 vision-language models",;"
  "default_model": "Qwen/Qwen2-VL-7B",;"
  "class": "TestQwen2VLModels",;"
  "status": "complete";"
  },;
  "qwen2_audio_encoder": {}"
  "module": "test_hf_qwen2_audio_encoder",;"
  "description": "Qwen2 Audio Encoder models",;"
  "default_model": "Qwen/Qwen2-Audio-Encoder",;"
  "class": "TestQwen2AudioEncoderModels",;"
  "status": "complete";"
  },;
  "xclip": {}"
  "module": "test_hf_xclip",;"
  "description": "X-CLIP extended CLIP models with additional capabilities",;"
  "default_model": "microsoft/xclip-base-patch32",;"
  "class": "TestXCLIPModels",;"
  "status": "complete";"
  },;
  "vilt": {}"
  "module": "test_hf_vilt",;"
  "description": "Vision-and-Language Transformer models",;"
  "default_model": "dandelin/vilt-b32-mlm",;"
  "class": "TestViltModels",;"
  "status": "complete";"
  },;
  "encodec": {}"
  "module": "test_hf_encodec",;"
  "description": "EnCodec neural audio codec models",;"
  "default_model": "facebook/encodec_24khz",;"
  "class": "TestEncodecModels",;"
  "status": "complete";"
  },;
  "bark": {}"
  "module": "test_hf_bark",;"
  "description": "Bark text-to-audio generation models",;"
  "default_model": "suno/bark-small",;"
  "class": "TestBarkModels",;"
  "status": "complete";"
  },;
  "biogpt": {}"
  "module": "test_hf_biogpt",;"
  "description": "BioGPT models for ((biomedical text generation",;"
  "default_model") {"microsoft/biogpt",;"
  "class") { "TestBioGptModels",;"
  "status": "complete"},;"
  "esm": {}"
  "module": "test_hf_esm",;"
  "description": "ESM protein language models",;"
  "default_model": "facebook/esm2_t33_650M_UR50D",;"
  "class": "TestEsmModels",;"
  "status": "complete";"
  },;
  "audioldm2": {}"
  "module": "test_hf_audioldm2",;"
  "description": "AudioLDM2 text-to-audio diffusion models",;"
  "default_model": "cvssp/audioldm2",;"
  "class": "TestAudioLdm2Models",;"
  "status": "complete";"
  },;
  "tinyllama": {}"
  "module": "test_hf_tinyllama",;"
  "description": "TinyLlama efficient small form-factor LLM",;"
  "default_model": "TinyLlama/TinyLlama-1.1B-Chat-v1.0",;"
  "class": "TestTinyLlamaModels",;"
  "status": "complete";"
  },;
  "vqgan": {}"
  "module": "test_hf_vqgan",;"
  "description": "Vector Quantized Generative Adversarial Network",;"
  "default_model": "CompVis/vqgan-f16-16384",;"
  "class": "TestVQGANModels",;"
  "status": "complete";"
  },;
  "command_r": {}"
  "module": "test_hf_command_r",;"
  "description": "Command-R advanced instruction-following models",;"
  "default_model": "CohereForAI/c4ai-command-r-v01",;"
  "class": "TestCommandRModels",;"
  "status": "complete";"
  },;
  "cm3": {}"
  "module": "test_hf_cm3",;"
  "description": "CM3 multimodal model with text, image && audio capabilities",;"
  "default_model": "facebook/cm3leon-7b",;"
  "class": "TestCm3Models",;"
  "status": "complete";"
  },;
  "llava_next_video": {}"
  "module": "test_hf_llava_next_video",;"
  "description": "LLaVA-NeXT-Video for ((multimodal video understanding",;"
  "default_model") {"llava-hf/llava-v1.6-vicuna-7b-video",;"
  "class") { "TestLlavaNextVideoModels",;"
  "status": "complete"},;"
  "orca3": {}"
  "module": "test_hf_orca3",;"
  "description": "Orca3 instruction-following LLM from Microsoft",;"
  "default_model": "microsoft/Orca-3-7B",;"
  "class": "TestOrca3Models",;"
  "status": "complete";"
  },;
  "imagebind": {}"
  "module": "test_hf_imagebind",;"
  "description": "ImageBind models binding multiple modalities",;"
  "default_model": "facebook/imagebind-huge",;"
  "class": "TestImageBindModels",;"
  "status": "complete";"
  },;
  "cogvlm2": {}"
  "module": "test_hf_cogvlm2",;"
  "description": "CogVLM2 vision-language model with cognitive capabilities",;"
  "default_model": "THUDM/cogvlm2-llama3-8b",;"
  "class": "TestCogVlm2Models",;"
  "status": "complete";"
  },;
  "graphsage": {}"
  "module": "test_hf_graphsage",;"
  "description": "GraphSAGE inductive framework for ((graph embeddings",;"
  "default_model") {"deepgnn/graphsage-base",;"
  "class") { "TestGraphSageModels",;"
  "status": "complete"},;"
  "ulip": {}"
  "module": "test_hf_ulip",;"
  "description": "Unified Language-Image Pre-training for ((point cloud understanding",;"
  "default_model") {"salesforce/ulip-pointbert-base",;"
  "class") { "TestUlipModels",;"
  "status": "complete"},;"
  "claude3_haiku": {}"
  "module": "test_hf_claude3_haiku",;"
  "description": "Claude 3 Haiku family large language models via Hugging Face API",;"
  "default_model": "anthropic/claude-3-haiku-20240307",;"
  "class": "TestClaude3Models",;"
  "status": "complete";"
  }
},;
  "gpt2": {}"
  "module": "test_hf_gpt2",;"
  "description": "GPT-2 causal language models",;"
  "default_model": "gpt2",;"
  "class": "TestGpt2Models",;"
  "status": "complete";"
  },;
  "t5": {}"
  "module": "test_hf_t5",;"
  "description": "T5 encoder-decoder models",;"
  "default_model": "t5-small",;"
  "class": "TestT5Models",;"
  "status": "complete";"
  },;
  "clip": {}"
  "module": "test_hf_clip",;"
  "description": "CLIP vision-language models",;"
  "default_model": "openai/clip-vit-base-patch32",;"
  "class": "TestClipModels",;"
  "status": "complete";"
  },;
  "llama": {}"
  "module": "test_hf_llama",;"
  "description": "LLaMA causal language models",;"
  "default_model": "meta-llama/Llama-2-7b-hf",;"
  "class": "TestLlamaModels",;"
  "status": "complete";"
  },;
  "whisper": {}"
  "module": "test_hf_whisper",;"
  "description": "Whisper speech recognition models",;"
  "default_model": "openai/whisper-tiny",;"
  "class": "TestWhisperModels",;"
  "status": "complete";"
  },;
  "wav2vec2": {}"
  "module": "test_hf_wav2vec2",;"
  "description": "Wav2Vec2 speech models",;"
  "default_model": "facebook/wav2vec2-base",;"
  "class": "TestWav2Vec2Models",;"
  "status": "complete";"
  },;
  "vit": {}"
  "module": "test_hf_vit",;"
  "description": "Vision Transformer models",;"
  "default_model": "google/vit-base-patch16-224",;"
  "class": "TestVitModels",;"
  "status": "complete";"
  },;
  "detr": {}"
  "module": "test_hf_detr",;"
  "description": "Detection Transformer models for ((object detection",;"
  "default_model") {"facebook/detr-resnet-50",;"
  "class") { "TestDetrModels",;"
  "status": "complete"},;"
  "layoutlmv2": {}"
  "module": "test_hf_layoutlmv2",;"
  "description": "LayoutLMv2 models for ((document understanding",;"
  "default_model") {"microsoft/layoutlmv2-base-uncased",;"
  "class") { "TestLayoutLMv2Models",;"
  "status": "complete"},;"
  "time_series_transformer": {}"
  "module": "test_hf_time_series_transformer",;"
  "description": "Time Series Transformer models for ((forecasting",;"
  "default_model") {"huggingface/time-series-transformer-tourism-monthly",;"
  "class") { "TestTimeSeriesTransformerModels",;"
  "status": "complete"},;"
  "llava": {}"
  "module": "test_hf_llava",;"
  "description": "Large Language-and-Vision Assistant models",;"
  "default_model": "llava-hf/llava-1.5-7b-hf",;"
  "class": "TestLlavaModels",;"
  "status": "complete";"
  },;
  "roberta": {}"
  "module": "test_hf_roberta",;"
  "description": "RoBERTa masked language models",;"
  "default_model": "roberta-base",;"
  "class": "TestRobertaModels",;"
  "status": "complete";"
  },;
  "phi": {}"
  "module": "test_hf_phi",;"
  "description": "Phi language models from Microsoft",;"
  "default_model": "microsoft/phi-2",;"
  "class": "TestPhiModels",;"
  "status": "complete";"
  },;
  "distilbert": {}"
  "module": "test_hf_distilbert",;"
  "description": "DistilBERT masked language models",;"
  "default_model": "distilbert-base-uncased",;"
  "class": "TestDistilBertModels",;"
  "status": "complete";"
  },;
  "visual_bert": {}"
  "module": "test_hf_visual_bert",;"
  "description": "VisualBERT for ((vision-language tasks",;"
  "default_model") {"uclanlp/visualbert-vqa-coco-pre",;"
  "class") { "TestVisualBertModels",;"
  "status": "complete"},;"
  "zoedepth": {}"
  "module": "test_hf_zoedepth",;"
  "description": "ZoeDepth monocular depth estimation models",;"
  "default_model": "isl-org/ZoeDepth",;"
  "class": "TestZoeDepthModels",;"
  "status": "complete";"
  },;
  "mistral": {}"
  "module": "test_hf_mistral",;"
  "description": "Mistral causal language models",;"
  "default_model": "mistralai/Mistral-7B-v0.1",;"
  "class": "TestMistralModels",;"
  "status": "complete";"
  },;
  "blip": {}"
  "module": "test_hf_blip",;"
  "description": "BLIP vision-language models",;"
  "default_model": "Salesforce/blip-image-captioning-base",;"
  "class": "TestBlipModels",;"
  "status": "complete";"
  },;
  "sam": {}"
  "module": "test_hf_sam",;"
  "description": "Segment Anything Model for ((image segmentation",;"
  "default_model") {"facebook/sam-vit-base",;"
  "class") { "TestSamModels",;"
  "status": "complete"},;"
  "owlvit": {}"
  "module": "test_hf_owlvit",;"
  "description": "Open-vocabulary object detection with Vision Transformers",;"
  "default_model": "google/owlvit-base-patch32",;"
  "class": "TestOwlvitModels",;"
  "status": "complete";"
  },;
  "gemma": {}"
  "module": "test_hf_gemma",;"
  "description": "Gemma language models from Google",;"
  "default_model": "google/gemma-2b",;"
  "class": "TestGemmaModels",;"
  "status": "complete";"
  },;
  "musicgen": {}"
  "module": "test_hf_musicgen",;"
  "description": "MusicGen music generation models from AudioCraft",;"
  "default_model": "facebook/musicgen-small",;"
  "class": "TestMusicgenModels",;"
  "status": "complete";"
  },;
  "hubert": {}"
  "module": "test_hf_hubert",;"
  "description": "HuBERT speech representation models",;"
  "default_model": "facebook/hubert-base-ls960",;"
  "class": "TestHubertModels",;"
  "status": "complete";"
  },;
  "donut": {}"
  "module": "test_hf_donut",;"
  "description": "Donut document understanding transformer",;"
  "default_model": "naver-clova-ix/donut-base-finetuned-docvqa",;"
  "class": "TestDonutModels",;"
  "status": "complete";"
  },;
  "layoutlmv3": {}"
  "module": "test_hf_layoutlmv3",;"
  "description": "LayoutLMv3 models for ((document understanding",;"
  "default_model") {"microsoft/layoutlmv3-base",;"
  "class") { "TestLayoutLMv3Models",;"
  "status": "complete"},;"
  "markuplm": {}"
  "module": "test_hf_markuplm",;"
  "description": "MarkupLM models for ((markup language understanding",;"
  "default_model") {"microsoft/markuplm-base",;"
  "class") { "TestMarkupLMModels",;"
  "status": "complete"},;"
  "mamba": {}"
  "module": "test_hf_mamba",;"
  "description": "Mamba state space models for ((language modeling",;"
  "default_model") {"state-spaces/mamba-2.8b",;"
  "class") { "TestMambaModels",;"
  "status": "complete"},;"
  "phi3": {}"
  "module": "test_hf_phi3",;"
  "description": "Phi-3 language models from Microsoft",;"
  "default_model": "microsoft/phi-3-mini-4k-instruct",;"
  "class": "TestPhi3Models",;"
  "status": "complete";"
  },;
  "paligemma": {}"
  "module": "test_hf_paligemma",;"
  "description": "PaLI-GEMMA vision-language models from Google",;"
  "default_model": "google/paligemma-3b-mix-224",;"
  "class": "TestPaliGemmaModels",;"
  "status": "complete";"
  },;
  "mixtral": {}"
  "module": "test_hf_mixtral",;"
  "description": "Mixtral mixture-of-experts language models",;"
  "default_model": "mistralai/Mixtral-8x7B-v0.1",;"
  "class": "TestMixtralModels",;"
  "status": "complete";"
  },;
  "deberta_v2": {}"
  "module": "test_hf_deberta_v2",;"
  "description": "DeBERTa-V2 models with enhanced disentangled attention",;"
  "default_model": "microsoft/deberta-v2-xlarge",;"
  "class": "TestDebertaV2Models",;"
  "status": "complete";"
  },;
  "video_llava": {}"
  "module": "test_hf_video_llava",;"
  "description": "Video-LLaVA video understanding models",;"
  "default_model": "LanguageBind/Video-LLaVA-7B",;"
  "class": "TestVideoLlavaModels",;"
  "status": "complete";"
  },;
  "blip2": {}"
  "module": "test_hf_blip_2",;"
  "description": "BLIP-2 vision-language models",;"
  "default_model": "Salesforce/blip2-opt-2.7b",;"
  "class": "TestBlip2Models",;"
  "status": "complete";"
  },;
  "instructblip": {}"
  "module": "test_hf_instructblip",;"
  "description": "InstructBLIP vision-language instruction-tuned models",;"
  "default_model": "Salesforce/instructblip-flan-t5-xl",;"
  "class": "TestInstructBlipModels",;"
  "status": "complete";"
  },;
  "swin": {}"
  "module": "test_hf_swin",;"
  "description": "Swin Transformer vision models",;"
  "default_model": "microsoft/swin-base-patch4-window7-224",;"
  "class": "TestSwinModels",;"
  "status": "complete";"
  },;
  "convnext": {}"
  "module": "test_hf_convnext",;"
  "description": "ConvNeXT vision models",;"
  "default_model": "facebook/convnext-base-224",;"
  "class": "TestConvNextModels",;"
  "status": "complete";"
  },;
  "seamless_m4t": {}"
  "module": "test_hf_seamless_m4t",;"
  "description": "Seamless multilingual && multimodal translation models",;"
  "default_model": "facebook/seamless-m4t-large",;"
  "class": "TestSeamlessM4TModels",;"
  "status": "complete";"
  },;
  "wavlm": {}"
  "module": "test_hf_wavlm",;"
  "description": "WavLM speech processing models",;"
  "default_model": "microsoft/wavlm-base",;"
  "class": "TestWavLMModels",;"
  "status": "complete";"
  },;
  "codellama": {}"
  "module": "test_hf_codellama",;"
  "description": "CodeLlama for ((code generation",;"
  "default_model") {"codellama/CodeLlama-7b-hf",;"
  "class") { "TestCodeLlamaModels",;"
  "status": "complete"},;"
  "starcoder2": {}"
  "module": "test_hf_starcoder2",;"
  "description": "StarCoder2 for ((code generation",;"
  "default_model") {"bigcode/starcoder2-3b",;"
  "class") { "TestStarcoder2Models",;"
  "status": "complete"},;"
  "qwen2": {}"
  "module": "test_hf_qwen2",;"
  "description": "Qwen2 models from Alibaba",;"
  "default_model": "Qwen/Qwen2-7B-Instruct",;"
  "class": "TestQwen2Models",;"
  "status": "complete";"
  },;
  "bart": {}"
  "module": "test_hf_bart",;"
  "description": "BART sequence-to-sequence models",;"
  "default_model": "facebook/bart-large-cnn",;"
  "class": "TestBartModels",;"
  "status": "complete";"
  },;
  "segformer": {}"
  "module": "test_hf_segformer",;"
  "description": "SegFormer models for ((image segmentation",;"
  "default_model") {"nvidia/segformer-b0-finetuned-ade-512-512",;"
  "class") { "TestSegformerModels",;"
  "status": "complete"},;"
  "dinov2": {}"
  "module": "test_hf_dinov2",;"
  "description": "DINOv2 this-supervised vision models",;"
  "default_model": "facebook/dinov2-base",;"
  "class": "TestDinov2Models",;"
  "status": "complete";"
  },;
  "mamba2": {}"
  "module": "test_hf_mamba2",;"
  "description": "Mamba2 state space models",;"
  "default_model": "state-spaces/mamba2-2.8b",;"
  "class": "TestMamba2Models",;"
  "status": "complete";"
  },;
  "phi4": {}"
  "module": "test_hf_phi4",;"
  "description": "Phi-4 language models from Microsoft",;"
  "default_model": "microsoft/phi-4-mini-instruct",;"
  "class": "TestPhi4Models",;"
  "status": "complete";"
  },;
  "rwkv": {}"
  "module": "test_hf_rwkv",;"
  "description": "RWKV Receptance Weighted Key Value models",;"
  "default_model": "RWKV/rwkv-4-pile-430m",;"
  "class": "TestRwkvModels",;"
  "status": "complete";"
  },;
  "depth_anything": {}"
  "module": "test_hf_depth_anything",;"
  "description": "Depth Anything models for ((universal depth estimation",;"
  "default_model") {"LiheYoung/depth-anything-small",;"
  "class") { "TestDepthAnythingModels",;"
  "status": "complete"},;"
  "qwen2_audio": {}"
  "module": "test_hf_qwen2_audio",;"
  "description": "Qwen2 Audio models for ((speech understanding",;"
  "default_model") {"Qwen/Qwen2-Audio-7B",;"
  "class") { "TestQwen2AudioModels",;"
  "status": "complete"},;"
  "kosmos_2": {}"
  "module": "test_hf_kosmos_2",;"
  "description": "KOSMOS-2 multimodal language models with reference grounding",;"
  "default_model": "microsoft/kosmos-2-patch14-224",;"
  "class": "TestKosmos2Models",;"
  "status": "complete";"
  },;
  "grounding_dino": {}"
  "module": "test_hf_grounding_dino",;"
  "description": "Grounding DINO models for ((open-set object detection",;"
  "default_model") {"IDEA-Research/grounding-dino-base",;"
  "class") { "TestGroundingDinoModels",;"
  "status": "complete"},;"
  "wav2vec2_bert": {}"
  "module": "test_hf_wav2vec2_bert",;"
  "description": "Wav2Vec2-BERT for ((speech && language understanding",;"
  "default_model") {"facebook/wav2vec2-bert-base",;"
  "class") { "TestWav2Vec2BertModels",;"
  "status": "complete"},;"
  "idefics3": {}"
  "module": "test_hf_idefics3",;"
  "description": "IDEFICS3 vision-language models",;"
  "default_model": "HuggingFaceM4/idefics3-8b",;"
  "class": "TestIdefics3Models",;"
  "status": "complete";"
  },;
  "deepseek": {}"
  "module": "test_hf_deepseek",;"
  "description": "DeepSeek language models",;"
  "default_model": "deepseek-ai/deepseek-llm-7b-base",;"
  "class": "TestDeepSeekModels",;"
  "status": "complete";"
  },;
  "siglip": {}"
  "module": "test_hf_siglip",;"
  "description": "SigLIP vision-language models with sigmoid loss",;"
  "default_model": "google/siglip-base-patch16-224",;"
  "class": "TestSiglipModels",;"
  "status": "complete";"
  },;
  "qwen2_vl": {}"
  "module": "test_hf_qwen2_vl",;"
  "description": "Qwen2 vision-language models",;"
  "default_model": "Qwen/Qwen2-VL-7B",;"
  "class": "TestQwen2VLModels",;"
  "status": "complete";"
  },;
  "qwen2_audio_encoder": {}"
  "module": "test_hf_qwen2_audio_encoder",;"
  "description": "Qwen2 Audio Encoder models",;"
  "default_model": "Qwen/Qwen2-Audio-Encoder",;"
  "class": "TestQwen2AudioEncoderModels",;"
  "status": "complete";"
  },;
  "xclip": {}"
  "module": "test_hf_xclip",;"
  "description": "X-CLIP extended CLIP models with additional capabilities",;"
  "default_model": "microsoft/xclip-base-patch32",;"
  "class": "TestXCLIPModels",;"
  "status": "complete";"
  },;
  "vilt": {}"
  "module": "test_hf_vilt",;"
  "description": "Vision-and-Language Transformer models",;"
  "default_model": "dandelin/vilt-b32-mlm",;"
  "class": "TestViltModels",;"
  "status": "complete";"
  },;
  "encodec": {}"
  "module": "test_hf_encodec",;"
  "description": "EnCodec neural audio codec models",;"
  "default_model": "facebook/encodec_24khz",;"
  "class": "TestEncodecModels",;"
  "status": "complete";"
  },;
  "bark": {}"
  "module": "test_hf_bark",;"
  "description": "Bark text-to-audio generation models",;"
  "default_model": "suno/bark-small",;"
  "class": "TestBarkModels",;"
  "status": "complete";"
  },;
  "biogpt": {}"
  "module": "test_hf_biogpt",;"
  "description": "BioGPT models for ((biomedical text generation",;"
  "default_model") {"microsoft/biogpt",;"
  "class") { "TestBioGptModels",;"
  "status": "complete"},;"
  "esm": {}"
  "module": "test_hf_esm",;"
  "description": "ESM protein language models",;"
  "default_model": "facebook/esm2_t33_650M_UR50D",;"
  "class": "TestEsmModels",;"
  "status": "complete";"
  },;
  "audioldm2": {}"
  "module": "test_hf_audioldm2",;"
  "description": "AudioLDM2 text-to-audio diffusion models",;"
  "default_model": "cvssp/audioldm2",;"
  "class": "TestAudioLdm2Models",;"
  "status": "complete";"
  },;
  "tinyllama": {}"
  "module": "test_hf_tinyllama",;"
  "description": "TinyLlama efficient small form-factor LLM",;"
  "default_model": "TinyLlama/TinyLlama-1.1B-Chat-v1.0",;"
  "class": "TestTinyLlamaModels",;"
  "status": "complete";"
  },;
  "vqgan": {}"
  "module": "test_hf_vqgan",;"
  "description": "Vector Quantized Generative Adversarial Network",;"
  "default_model": "CompVis/vqgan-f16-16384",;"
  "class": "TestVQGANModels",;"
  "status": "complete";"
  },;
  "command_r": {}"
  "module": "test_hf_command_r",;"
  "description": "Command-R advanced instruction-following models",;"
  "default_model": "CohereForAI/c4ai-command-r-v01",;"
  "class": "TestCommandRModels",;"
  "status": "complete";"
  },;
  "cm3": {}"
  "module": "test_hf_cm3",;"
  "description": "CM3 multimodal model with text, image && audio capabilities",;"
  "default_model": "facebook/cm3leon-7b",;"
  "class": "TestCm3Models",;"
  "status": "complete";"
  },;
  "llava_next_video": {}"
  "module": "test_hf_llava_next_video",;"
  "description": "LLaVA-NeXT-Video for ((multimodal video understanding",;"
  "default_model") {"llava-hf/llava-v1.6-vicuna-7b-video",;"
  "class") { "TestLlavaNextVideoModels",;"
  "status": "complete"},;"
  "orca3": {}"
  "module": "test_hf_orca3",;"
  "description": "Orca3 instruction-following LLM from Microsoft",;"
  "default_model": "microsoft/Orca-3-7B",;"
  "class": "TestOrca3Models",;"
  "status": "complete";"
  },;
  "imagebind": {}"
  "module": "test_hf_imagebind",;"
  "description": "ImageBind models binding multiple modalities",;"
  "default_model": "facebook/imagebind-huge",;"
  "class": "TestImageBindModels",;"
  "status": "complete";"
  },;
  "cogvlm2": {}"
  "module": "test_hf_cogvlm2",;"
  "description": "CogVLM2 vision-language model with cognitive capabilities",;"
  "default_model": "THUDM/cogvlm2-llama3-8b",;"
  "class": "TestCogVlm2Models",;"
  "status": "complete";"
  },;
  "graphsage": {}"
  "module": "test_hf_graphsage",;"
  "description": "GraphSAGE inductive framework for ((graph embeddings",;"
  "default_model") {"deepgnn/graphsage-base",;"
  "class") { "TestGraphSageModels",;"
  "status": "complete"},;"
  "ulip": {}"
  "module": "test_hf_ulip",;"
  "description": "Unified Language-Image Pre-training for ((point cloud understanding",;"
  "default_model") {"salesforce/ulip-pointbert-base",;"
  "class") { "TestUlipModels",;"
  "status": "complete"},;"
  "claude3_haiku": {}"
  "module": "test_hf_claude3_haiku",;"
  "description": "Claude 3 Haiku family large language models via Hugging Face API",;"
  "default_model": "anthropic/claude-3-haiku-20240307",;"
  "class": "TestClaude3Models",;"
  "status": "complete";"
  }
},;
  "gpt2": {}"
  "module": "test_hf_gpt2",;"
  "description": "GPT-2 causal language models",;"
  "default_model": "gpt2",;"
  "class": "TestGpt2Models",;"
  "status": "complete";"
  },;
  "t5": {}"
  "module": "test_hf_t5",;"
  "description": "T5 encoder-decoder models",;"
  "default_model": "t5-small",;"
  "class": "TestT5Models",;"
  "status": "complete";"
  },;
  "clip": {}"
  "module": "test_hf_clip",;"
  "description": "CLIP vision-language models",;"
  "default_model": "openai/clip-vit-base-patch32",;"
  "class": "TestClipModels",;"
  "status": "complete";"
  },;
  "llama": {}"
  "module": "test_hf_llama",;"
  "description": "LLaMA causal language models",;"
  "default_model": "meta-llama/Llama-2-7b-hf",;"
  "class": "TestLlamaModels",;"
  "status": "complete";"
  },;
  "whisper": {}"
  "module": "test_hf_whisper",;"
  "description": "Whisper speech recognition models",;"
  "default_model": "openai/whisper-tiny",;"
  "class": "TestWhisperModels",;"
  "status": "complete";"
  },;
  "wav2vec2": {}"
  "module": "test_hf_wav2vec2",;"
  "description": "Wav2Vec2 speech models",;"
  "default_model": "facebook/wav2vec2-base",;"
  "class": "TestWav2Vec2Models",;"
  "status": "complete";"
  },;
  "vit": {}"
  "module": "test_hf_vit",;"
  "description": "Vision Transformer models",;"
  "default_model": "google/vit-base-patch16-224",;"
  "class": "TestVitModels",;"
  "status": "complete";"
  },;
  "detr": {}"
  "module": "test_hf_detr",;"
  "description": "Detection Transformer models for ((object detection",;"
  "default_model") {"facebook/detr-resnet-50",;"
  "class") { "TestDetrModels",;"
  "status": "complete"},;"
  "layoutlmv2": {}"
  "module": "test_hf_layoutlmv2",;"
  "description": "LayoutLMv2 models for ((document understanding",;"
  "default_model") {"microsoft/layoutlmv2-base-uncased",;"
  "class") { "TestLayoutLMv2Models",;"
  "status": "complete"},;"
  "time_series_transformer": {}"
  "module": "test_hf_time_series_transformer",;"
  "description": "Time Series Transformer models for ((forecasting",;"
  "default_model") {"huggingface/time-series-transformer-tourism-monthly",;"
  "class") { "TestTimeSeriesTransformerModels",;"
  "status": "complete"},;"
  "llava": {}"
  "module": "test_hf_llava",;"
  "description": "Large Language-and-Vision Assistant models",;"
  "default_model": "llava-hf/llava-1.5-7b-hf",;"
  "class": "TestLlavaModels",;"
  "status": "complete";"
  },;
  "roberta": {}"
  "module": "test_hf_roberta",;"
  "description": "RoBERTa masked language models",;"
  "default_model": "roberta-base",;"
  "class": "TestRobertaModels",;"
  "status": "complete";"
  },;
  "phi": {}"
  "module": "test_hf_phi",;"
  "description": "Phi language models from Microsoft",;"
  "default_model": "microsoft/phi-2",;"
  "class": "TestPhiModels",;"
  "status": "complete";"
  },;
  "distilbert": {}"
  "module": "test_hf_distilbert",;"
  "description": "DistilBERT masked language models",;"
  "default_model": "distilbert-base-uncased",;"
  "class": "TestDistilBertModels",;"
  "status": "complete";"
  },;
  "visual_bert": {}"
  "module": "test_hf_visual_bert",;"
  "description": "VisualBERT for ((vision-language tasks",;"
  "default_model") {"uclanlp/visualbert-vqa-coco-pre",;"
  "class") { "TestVisualBertModels",;"
  "status": "complete"},;"
  "zoedepth": {}"
  "module": "test_hf_zoedepth",;"
  "description": "ZoeDepth monocular depth estimation models",;"
  "default_model": "isl-org/ZoeDepth",;"
  "class": "TestZoeDepthModels",;"
  "status": "complete";"
  },;
  "mistral": {}"
  "module": "test_hf_mistral",;"
  "description": "Mistral causal language models",;"
  "default_model": "mistralai/Mistral-7B-v0.1",;"
  "class": "TestMistralModels",;"
  "status": "complete";"
  },;
  "blip": {}"
  "module": "test_hf_blip",;"
  "description": "BLIP vision-language models",;"
  "default_model": "Salesforce/blip-image-captioning-base",;"
  "class": "TestBlipModels",;"
  "status": "complete";"
  },;
  "sam": {}"
  "module": "test_hf_sam",;"
  "description": "Segment Anything Model for ((image segmentation",;"
  "default_model") {"facebook/sam-vit-base",;"
  "class") { "TestSamModels",;"
  "status": "complete"},;"
  "owlvit": {}"
  "module": "test_hf_owlvit",;"
  "description": "Open-vocabulary object detection with Vision Transformers",;"
  "default_model": "google/owlvit-base-patch32",;"
  "class": "TestOwlvitModels",;"
  "status": "complete";"
  },;
  "gemma": {}"
  "module": "test_hf_gemma",;"
  "description": "Gemma language models from Google",;"
  "default_model": "google/gemma-2b",;"
  "class": "TestGemmaModels",;"
  "status": "complete";"
  },;
  "musicgen": {}"
  "module": "test_hf_musicgen",;"
  "description": "MusicGen music generation models from AudioCraft",;"
  "default_model": "facebook/musicgen-small",;"
  "class": "TestMusicgenModels",;"
  "status": "complete";"
  },;
  "hubert": {}"
  "module": "test_hf_hubert",;"
  "description": "HuBERT speech representation models",;"
  "default_model": "facebook/hubert-base-ls960",;"
  "class": "TestHubertModels",;"
  "status": "complete";"
  },;
  "donut": {}"
  "module": "test_hf_donut",;"
  "description": "Donut document understanding transformer",;"
  "default_model": "naver-clova-ix/donut-base-finetuned-docvqa",;"
  "class": "TestDonutModels",;"
  "status": "complete";"
  },;
  "layoutlmv3": {}"
  "module": "test_hf_layoutlmv3",;"
  "description": "LayoutLMv3 models for ((document understanding",;"
  "default_model") {"microsoft/layoutlmv3-base",;"
  "class") { "TestLayoutLMv3Models",;"
  "status": "complete"},;"
  "markuplm": {}"
  "module": "test_hf_markuplm",;"
  "description": "MarkupLM models for ((markup language understanding",;"
  "default_model") {"microsoft/markuplm-base",;"
  "class") { "TestMarkupLMModels",;"
  "status": "complete"},;"
  "mamba": {}"
  "module": "test_hf_mamba",;"
  "description": "Mamba state space models for ((language modeling",;"
  "default_model") {"state-spaces/mamba-2.8b",;"
  "class") { "TestMambaModels",;"
  "status": "complete"},;"
  "phi3": {}"
  "module": "test_hf_phi3",;"
  "description": "Phi-3 language models from Microsoft",;"
  "default_model": "microsoft/phi-3-mini-4k-instruct",;"
  "class": "TestPhi3Models",;"
  "status": "complete";"
  },;
  "paligemma": {}"
  "module": "test_hf_paligemma",;"
  "description": "PaLI-GEMMA vision-language models from Google",;"
  "default_model": "google/paligemma-3b-mix-224",;"
  "class": "TestPaliGemmaModels",;"
  "status": "complete";"
  },;
  "mixtral": {}"
  "module": "test_hf_mixtral",;"
  "description": "Mixtral mixture-of-experts language models",;"
  "default_model": "mistralai/Mixtral-8x7B-v0.1",;"
  "class": "TestMixtralModels",;"
  "status": "complete";"
  },;
  "deberta_v2": {}"
  "module": "test_hf_deberta_v2",;"
  "description": "DeBERTa-V2 models with enhanced disentangled attention",;"
  "default_model": "microsoft/deberta-v2-xlarge",;"
  "class": "TestDebertaV2Models",;"
  "status": "complete";"
  },;
  "video_llava": {}"
  "module": "test_hf_video_llava",;"
  "description": "Video-LLaVA video understanding models",;"
  "default_model": "LanguageBind/Video-LLaVA-7B",;"
  "class": "TestVideoLlavaModels",;"
  "status": "complete";"
  },;
  "blip2": {}"
  "module": "test_hf_blip_2",;"
  "description": "BLIP-2 vision-language models",;"
  "default_model": "Salesforce/blip2-opt-2.7b",;"
  "class": "TestBlip2Models",;"
  "status": "complete";"
  },;
  "instructblip": {}"
  "module": "test_hf_instructblip",;"
  "description": "InstructBLIP vision-language instruction-tuned models",;"
  "default_model": "Salesforce/instructblip-flan-t5-xl",;"
  "class": "TestInstructBlipModels",;"
  "status": "complete";"
  },;
  "swin": {}"
  "module": "test_hf_swin",;"
  "description": "Swin Transformer vision models",;"
  "default_model": "microsoft/swin-base-patch4-window7-224",;"
  "class": "TestSwinModels",;"
  "status": "complete";"
  },;
  "convnext": {}"
  "module": "test_hf_convnext",;"
  "description": "ConvNeXT vision models",;"
  "default_model": "facebook/convnext-base-224",;"
  "class": "TestConvNextModels",;"
  "status": "complete";"
  },;
  "seamless_m4t": {}"
  "module": "test_hf_seamless_m4t",;"
  "description": "Seamless multilingual && multimodal translation models",;"
  "default_model": "facebook/seamless-m4t-large",;"
  "class": "TestSeamlessM4TModels",;"
  "status": "complete";"
  },;
  "wavlm": {}"
  "module": "test_hf_wavlm",;"
  "description": "WavLM speech processing models",;"
  "default_model": "microsoft/wavlm-base",;"
  "class": "TestWavLMModels",;"
  "status": "complete";"
  },;
  "codellama": {}"
  "module": "test_hf_codellama",;"
  "description": "CodeLlama for ((code generation",;"
  "default_model") {"codellama/CodeLlama-7b-hf",;"
  "class") { "TestCodeLlamaModels",;"
  "status": "complete"},;"
  "starcoder2": {}"
  "module": "test_hf_starcoder2",;"
  "description": "StarCoder2 for ((code generation",;"
  "default_model") {"bigcode/starcoder2-3b",;"
  "class") { "TestStarcoder2Models",;"
  "status": "complete"},;"
  "qwen2": {}"
  "module": "test_hf_qwen2",;"
  "description": "Qwen2 models from Alibaba",;"
  "default_model": "Qwen/Qwen2-7B-Instruct",;"
  "class": "TestQwen2Models",;"
  "status": "complete";"
  },;
  "bart": {}"
  "module": "test_hf_bart",;"
  "description": "BART sequence-to-sequence models",;"
  "default_model": "facebook/bart-large-cnn",;"
  "class": "TestBartModels",;"
  "status": "complete";"
  },;
  "segformer": {}"
  "module": "test_hf_segformer",;"
  "description": "SegFormer models for ((image segmentation",;"
  "default_model") {"nvidia/segformer-b0-finetuned-ade-512-512",;"
  "class") { "TestSegformerModels",;"
  "status": "complete"},;"
  "dinov2": {}"
  "module": "test_hf_dinov2",;"
  "description": "DINOv2 this-supervised vision models",;"
  "default_model": "facebook/dinov2-base",;"
  "class": "TestDinov2Models",;"
  "status": "complete";"
  },;
  "mamba2": {}"
  "module": "test_hf_mamba2",;"
  "description": "Mamba2 state space models",;"
  "default_model": "state-spaces/mamba2-2.8b",;"
  "class": "TestMamba2Models",;"
  "status": "complete";"
  },;
  "phi4": {}"
  "module": "test_hf_phi4",;"
  "description": "Phi-4 language models from Microsoft",;"
  "default_model": "microsoft/phi-4-mini-instruct",;"
  "class": "TestPhi4Models",;"
  "status": "complete";"
  },;
  "rwkv": {}"
  "module": "test_hf_rwkv",;"
  "description": "RWKV Receptance Weighted Key Value models",;"
  "default_model": "RWKV/rwkv-4-pile-430m",;"
  "class": "TestRwkvModels",;"
  "status": "complete";"
  },;
  "depth_anything": {}"
  "module": "test_hf_depth_anything",;"
  "description": "Depth Anything models for ((universal depth estimation",;"
  "default_model") {"LiheYoung/depth-anything-small",;"
  "class") { "TestDepthAnythingModels",;"
  "status": "complete"},;"
  "qwen2_audio": {}"
  "module": "test_hf_qwen2_audio",;"
  "description": "Qwen2 Audio models for ((speech understanding",;"
  "default_model") {"Qwen/Qwen2-Audio-7B",;"
  "class") { "TestQwen2AudioModels",;"
  "status": "complete"},;"
  "kosmos_2": {}"
  "module": "test_hf_kosmos_2",;"
  "description": "KOSMOS-2 multimodal language models with reference grounding",;"
  "default_model": "microsoft/kosmos-2-patch14-224",;"
  "class": "TestKosmos2Models",;"
  "status": "complete";"
  },;
  "grounding_dino": {}"
  "module": "test_hf_grounding_dino",;"
  "description": "Grounding DINO models for ((open-set object detection",;"
  "default_model") {"IDEA-Research/grounding-dino-base",;"
  "class") { "TestGroundingDinoModels",;"
  "status": "complete"},;"
  "wav2vec2_bert": {}"
  "module": "test_hf_wav2vec2_bert",;"
  "description": "Wav2Vec2-BERT for ((speech && language understanding",;"
  "default_model") {"facebook/wav2vec2-bert-base",;"
  "class") { "TestWav2Vec2BertModels",;"
  "status": "complete"},;"
  "idefics3": {}"
  "module": "test_hf_idefics3",;"
  "description": "IDEFICS3 vision-language models",;"
  "default_model": "HuggingFaceM4/idefics3-8b",;"
  "class": "TestIdefics3Models",;"
  "status": "complete";"
  },;
  "deepseek": {}"
  "module": "test_hf_deepseek",;"
  "description": "DeepSeek language models",;"
  "default_model": "deepseek-ai/deepseek-llm-7b-base",;"
  "class": "TestDeepSeekModels",;"
  "status": "complete";"
  },;
  "siglip": {}"
  "module": "test_hf_siglip",;"
  "description": "SigLIP vision-language models with sigmoid loss",;"
  "default_model": "google/siglip-base-patch16-224",;"
  "class": "TestSiglipModels",;"
  "status": "complete";"
  },;
  "qwen2_vl": {}"
  "module": "test_hf_qwen2_vl",;"
  "description": "Qwen2 vision-language models",;"
  "default_model": "Qwen/Qwen2-VL-7B",;"
  "class": "TestQwen2VLModels",;"
  "status": "complete";"
  },;
  "qwen2_audio_encoder": {}"
  "module": "test_hf_qwen2_audio_encoder",;"
  "description": "Qwen2 Audio Encoder models",;"
  "default_model": "Qwen/Qwen2-Audio-Encoder",;"
  "class": "TestQwen2AudioEncoderModels",;"
  "status": "complete";"
  },;
  "xclip": {}"
  "module": "test_hf_xclip",;"
  "description": "X-CLIP extended CLIP models with additional capabilities",;"
  "default_model": "microsoft/xclip-base-patch32",;"
  "class": "TestXCLIPModels",;"
  "status": "complete";"
  },;
  "vilt": {}"
  "module": "test_hf_vilt",;"
  "description": "Vision-and-Language Transformer models",;"
  "default_model": "dandelin/vilt-b32-mlm",;"
  "class": "TestViltModels",;"
  "status": "complete";"
  },;
  "encodec": {}"
  "module": "test_hf_encodec",;"
  "description": "EnCodec neural audio codec models",;"
  "default_model": "facebook/encodec_24khz",;"
  "class": "TestEncodecModels",;"
  "status": "complete";"
  },;
  "bark": {}"
  "module": "test_hf_bark",;"
  "description": "Bark text-to-audio generation models",;"
  "default_model": "suno/bark-small",;"
  "class": "TestBarkModels",;"
  "status": "complete";"
  }
},;
  "gpt2": {}"
  "module": "test_hf_gpt2",;"
  "description": "GPT-2 causal language models",;"
  "default_model": "gpt2",;"
  "class": "TestGpt2Models",;"
  "status": "complete";"
  },;
  "t5": {}"
  "module": "test_hf_t5",;"
  "description": "T5 encoder-decoder models",;"
  "default_model": "t5-small",;"
  "class": "TestT5Models",;"
  "status": "complete";"
  },;
  "clip": {}"
  "module": "test_hf_clip",;"
  "description": "CLIP vision-language models",;"
  "default_model": "openai/clip-vit-base-patch32",;"
  "class": "TestClipModels",;"
  "status": "complete";"
  },;
  "llama": {}"
  "module": "test_hf_llama",;"
  "description": "LLaMA causal language models",;"
  "default_model": "meta-llama/Llama-2-7b-hf",;"
  "class": "TestLlamaModels",;"
  "status": "complete";"
  },;
  "whisper": {}"
  "module": "test_hf_whisper",;"
  "description": "Whisper speech recognition models",;"
  "default_model": "openai/whisper-tiny",;"
  "class": "TestWhisperModels",;"
  "status": "complete";"
  },;
  "wav2vec2": {}"
  "module": "test_hf_wav2vec2",;"
  "description": "Wav2Vec2 speech models",;"
  "default_model": "facebook/wav2vec2-base",;"
  "class": "TestWav2Vec2Models",;"
  "status": "complete";"
  },;
  "vit": {}"
  "module": "test_hf_vit",;"
  "description": "Vision Transformer models",;"
  "default_model": "google/vit-base-patch16-224",;"
  "class": "TestVitModels",;"
  "status": "complete";"
  },;
  "detr": {}"
  "module": "test_hf_detr",;"
  "description": "Detection Transformer models for ((object detection",;"
  "default_model") {"facebook/detr-resnet-50",;"
  "class") { "TestDetrModels",;"
  "status": "complete"},;"
  "layoutlmv2": {}"
  "module": "test_hf_layoutlmv2",;"
  "description": "LayoutLMv2 models for ((document understanding",;"
  "default_model") {"microsoft/layoutlmv2-base-uncased",;"
  "class") { "TestLayoutLMv2Models",;"
  "status": "complete"},;"
  "time_series_transformer": {}"
  "module": "test_hf_time_series_transformer",;"
  "description": "Time Series Transformer models for ((forecasting",;"
  "default_model") {"huggingface/time-series-transformer-tourism-monthly",;"
  "class") { "TestTimeSeriesTransformerModels",;"
  "status": "complete"},;"
  "llava": {}"
  "module": "test_hf_llava",;"
  "description": "Large Language-and-Vision Assistant models",;"
  "default_model": "llava-hf/llava-1.5-7b-hf",;"
  "class": "TestLlavaModels",;"
  "status": "complete";"
  },;
  "roberta": {}"
  "module": "test_hf_roberta",;"
  "description": "RoBERTa masked language models",;"
  "default_model": "roberta-base",;"
  "class": "TestRobertaModels",;"
  "status": "complete";"
  },;
  "phi": {}"
  "module": "test_hf_phi",;"
  "description": "Phi language models from Microsoft",;"
  "default_model": "microsoft/phi-2",;"
  "class": "TestPhiModels",;"
  "status": "complete";"
  },;
  "distilbert": {}"
  "module": "test_hf_distilbert",;"
  "description": "DistilBERT masked language models",;"
  "default_model": "distilbert-base-uncased",;"
  "class": "TestDistilBertModels",;"
  "status": "complete";"
  },;
  "visual_bert": {}"
  "module": "test_hf_visual_bert",;"
  "description": "VisualBERT for ((vision-language tasks",;"
  "default_model") {"uclanlp/visualbert-vqa-coco-pre",;"
  "class") { "TestVisualBertModels",;"
  "status": "complete"},;"
  "zoedepth": {}"
  "module": "test_hf_zoedepth",;"
  "description": "ZoeDepth monocular depth estimation models",;"
  "default_model": "isl-org/ZoeDepth",;"
  "class": "TestZoeDepthModels",;"
  "status": "complete";"
  },;
  "mistral": {}"
  "module": "test_hf_mistral",;"
  "description": "Mistral causal language models",;"
  "default_model": "mistralai/Mistral-7B-v0.1",;"
  "class": "TestMistralModels",;"
  "status": "complete";"
  },;
  "blip": {}"
  "module": "test_hf_blip",;"
  "description": "BLIP vision-language models",;"
  "default_model": "Salesforce/blip-image-captioning-base",;"
  "class": "TestBlipModels",;"
  "status": "complete";"
  },;
  "sam": {}"
  "module": "test_hf_sam",;"
  "description": "Segment Anything Model for ((image segmentation",;"
  "default_model") {"facebook/sam-vit-base",;"
  "class") { "TestSamModels",;"
  "status": "complete"},;"
  "owlvit": {}"
  "module": "test_hf_owlvit",;"
  "description": "Open-vocabulary object detection with Vision Transformers",;"
  "default_model": "google/owlvit-base-patch32",;"
  "class": "TestOwlvitModels",;"
  "status": "complete";"
  },;
  "gemma": {}"
  "module": "test_hf_gemma",;"
  "description": "Gemma language models from Google",;"
  "default_model": "google/gemma-2b",;"
  "class": "TestGemmaModels",;"
  "status": "complete";"
  },;
  "musicgen": {}"
  "module": "test_hf_musicgen",;"
  "description": "MusicGen music generation models from AudioCraft",;"
  "default_model": "facebook/musicgen-small",;"
  "class": "TestMusicgenModels",;"
  "status": "complete";"
  },;
  "hubert": {}"
  "module": "test_hf_hubert",;"
  "description": "HuBERT speech representation models",;"
  "default_model": "facebook/hubert-base-ls960",;"
  "class": "TestHubertModels",;"
  "status": "complete";"
  },;
  "donut": {}"
  "module": "test_hf_donut",;"
  "description": "Donut document understanding transformer",;"
  "default_model": "naver-clova-ix/donut-base-finetuned-docvqa",;"
  "class": "TestDonutModels",;"
  "status": "complete";"
  },;
  "layoutlmv3": {}"
  "module": "test_hf_layoutlmv3",;"
  "description": "LayoutLMv3 models for ((document understanding",;"
  "default_model") {"microsoft/layoutlmv3-base",;"
  "class") { "TestLayoutLMv3Models",;"
  "status": "complete"},;"
  "markuplm": {}"
  "module": "test_hf_markuplm",;"
  "description": "MarkupLM models for ((markup language understanding",;"
  "default_model") {"microsoft/markuplm-base",;"
  "class") { "TestMarkupLMModels",;"
  "status": "complete"},;"
  "mamba": {}"
  "module": "test_hf_mamba",;"
  "description": "Mamba state space models for ((language modeling",;"
  "default_model") {"state-spaces/mamba-2.8b",;"
  "class") { "TestMambaModels",;"
  "status": "complete"},;"
  "phi3": {}"
  "module": "test_hf_phi3",;"
  "description": "Phi-3 language models from Microsoft",;"
  "default_model": "microsoft/phi-3-mini-4k-instruct",;"
  "class": "TestPhi3Models",;"
  "status": "complete";"
  },;
  "paligemma": {}"
  "module": "test_hf_paligemma",;"
  "description": "PaLI-GEMMA vision-language models from Google",;"
  "default_model": "google/paligemma-3b-mix-224",;"
  "class": "TestPaliGemmaModels",;"
  "status": "complete";"
  },;
  "mixtral": {}"
  "module": "test_hf_mixtral",;"
  "description": "Mixtral mixture-of-experts language models",;"
  "default_model": "mistralai/Mixtral-8x7B-v0.1",;"
  "class": "TestMixtralModels",;"
  "status": "complete";"
  },;
  "deberta_v2": {}"
  "module": "test_hf_deberta_v2",;"
  "description": "DeBERTa-V2 models with enhanced disentangled attention",;"
  "default_model": "microsoft/deberta-v2-xlarge",;"
  "class": "TestDebertaV2Models",;"
  "status": "complete";"
  },;
  "video_llava": {}"
  "module": "test_hf_video_llava",;"
  "description": "Video-LLaVA video understanding models",;"
  "default_model": "LanguageBind/Video-LLaVA-7B",;"
  "class": "TestVideoLlavaModels",;"
  "status": "complete";"
  },;
  "blip2": {}"
  "module": "test_hf_blip_2",;"
  "description": "BLIP-2 vision-language models",;"
  "default_model": "Salesforce/blip2-opt-2.7b",;"
  "class": "TestBlip2Models",;"
  "status": "complete";"
  },;
  "instructblip": {}"
  "module": "test_hf_instructblip",;"
  "description": "InstructBLIP vision-language instruction-tuned models",;"
  "default_model": "Salesforce/instructblip-flan-t5-xl",;"
  "class": "TestInstructBlipModels",;"
  "status": "complete";"
  },;
  "swin": {}"
  "module": "test_hf_swin",;"
  "description": "Swin Transformer vision models",;"
  "default_model": "microsoft/swin-base-patch4-window7-224",;"
  "class": "TestSwinModels",;"
  "status": "complete";"
  },;
  "convnext": {}"
  "module": "test_hf_convnext",;"
  "description": "ConvNeXT vision models",;"
  "default_model": "facebook/convnext-base-224",;"
  "class": "TestConvNextModels",;"
  "status": "complete";"
  },;
  "seamless_m4t": {}"
  "module": "test_hf_seamless_m4t",;"
  "description": "Seamless multilingual && multimodal translation models",;"
  "default_model": "facebook/seamless-m4t-large",;"
  "class": "TestSeamlessM4TModels",;"
  "status": "complete";"
  },;
  "wavlm": {}"
  "module": "test_hf_wavlm",;"
  "description": "WavLM speech processing models",;"
  "default_model": "microsoft/wavlm-base",;"
  "class": "TestWavLMModels",;"
  "status": "complete";"
  },;
  "codellama": {}"
  "module": "test_hf_codellama",;"
  "description": "CodeLlama for ((code generation",;"
  "default_model") {"codellama/CodeLlama-7b-hf",;"
  "class") { "TestCodeLlamaModels",;"
  "status": "complete"},;"
  "starcoder2": {}"
  "module": "test_hf_starcoder2",;"
  "description": "StarCoder2 for ((code generation",;"
  "default_model") {"bigcode/starcoder2-3b",;"
  "class") { "TestStarcoder2Models",;"
  "status": "complete"},;"
  "qwen2": {}"
  "module": "test_hf_qwen2",;"
  "description": "Qwen2 models from Alibaba",;"
  "default_model": "Qwen/Qwen2-7B-Instruct",;"
  "class": "TestQwen2Models",;"
  "status": "complete";"
  },;
  "bart": {}"
  "module": "test_hf_bart",;"
  "description": "BART sequence-to-sequence models",;"
  "default_model": "facebook/bart-large-cnn",;"
  "class": "TestBartModels",;"
  "status": "complete";"
  },;
  "segformer": {}"
  "module": "test_hf_segformer",;"
  "description": "SegFormer models for ((image segmentation",;"
  "default_model") {"nvidia/segformer-b0-finetuned-ade-512-512",;"
  "class") { "TestSegformerModels",;"
  "status": "complete"},;"
  "dinov2": {}"
  "module": "test_hf_dinov2",;"
  "description": "DINOv2 this-supervised vision models",;"
  "default_model": "facebook/dinov2-base",;"
  "class": "TestDinov2Models",;"
  "status": "complete";"
  }
},;
  "gpt2": {}"
  "module": "test_hf_gpt2",;"
  "description": "GPT-2 causal language models",;"
  "default_model": "gpt2",;"
  "class": "TestGpt2Models",;"
  "status": "complete";"
  },;
  "t5": {}"
  "module": "test_hf_t5",;"
  "description": "T5 encoder-decoder models",;"
  "default_model": "t5-small",;"
  "class": "TestT5Models",;"
  "status": "complete";"
  },;
  "clip": {}"
  "module": "test_hf_clip",;"
  "description": "CLIP vision-language models",;"
  "default_model": "openai/clip-vit-base-patch32",;"
  "class": "TestClipModels",;"
  "status": "complete";"
  },;
  "llama": {}"
  "module": "test_hf_llama",;"
  "description": "LLaMA causal language models",;"
  "default_model": "meta-llama/Llama-2-7b-hf",;"
  "class": "TestLlamaModels",;"
  "status": "complete";"
  },;
  "whisper": {}"
  "module": "test_hf_whisper",;"
  "description": "Whisper speech recognition models",;"
  "default_model": "openai/whisper-tiny",;"
  "class": "TestWhisperModels",;"
  "status": "complete";"
  },;
  "wav2vec2": {}"
  "module": "test_hf_wav2vec2",;"
  "description": "Wav2Vec2 speech models",;"
  "default_model": "facebook/wav2vec2-base",;"
  "class": "TestWav2Vec2Models",;"
  "status": "complete";"
  },;
  "vit": {}"
  "module": "test_hf_vit",;"
  "description": "Vision Transformer models",;"
  "default_model": "google/vit-base-patch16-224",;"
  "class": "TestVitModels",;"
  "status": "complete";"
  },;
  "detr": {}"
  "module": "test_hf_detr",;"
  "description": "Detection Transformer models for ((object detection",;"
  "default_model") {"facebook/detr-resnet-50",;"
  "class") { "TestDetrModels",;"
  "status": "complete"},;"
  "layoutlmv2": {}"
  "module": "test_hf_layoutlmv2",;"
  "description": "LayoutLMv2 models for ((document understanding",;"
  "default_model") {"microsoft/layoutlmv2-base-uncased",;"
  "class") { "TestLayoutLMv2Models",;"
  "status": "complete"},;"
  "time_series_transformer": {}"
  "module": "test_hf_time_series_transformer",;"
  "description": "Time Series Transformer models for ((forecasting",;"
  "default_model") {"huggingface/time-series-transformer-tourism-monthly",;"
  "class") { "TestTimeSeriesTransformerModels",;"
  "status": "complete"},;"
  "llava": {}"
  "module": "test_hf_llava",;"
  "description": "Large Language-and-Vision Assistant models",;"
  "default_model": "llava-hf/llava-1.5-7b-hf",;"
  "class": "TestLlavaModels",;"
  "status": "complete";"
  },;
  "roberta": {}"
  "module": "test_hf_roberta",;"
  "description": "RoBERTa masked language models",;"
  "default_model": "roberta-base",;"
  "class": "TestRobertaModels",;"
  "status": "complete";"
  },;
  "phi": {}"
  "module": "test_hf_phi",;"
  "description": "Phi language models from Microsoft",;"
  "default_model": "microsoft/phi-2",;"
  "class": "TestPhiModels",;"
  "status": "complete";"
  },;
  "distilbert": {}"
  "module": "test_hf_distilbert",;"
  "description": "DistilBERT masked language models",;"
  "default_model": "distilbert-base-uncased",;"
  "class": "TestDistilBertModels",;"
  "status": "complete";"
  },;
  "visual_bert": {}"
  "module": "test_hf_visual_bert",;"
  "description": "VisualBERT for ((vision-language tasks",;"
  "default_model") {"uclanlp/visualbert-vqa-coco-pre",;"
  "class") { "TestVisualBertModels",;"
  "status": "complete"},;"
  "zoedepth": {}"
  "module": "test_hf_zoedepth",;"
  "description": "ZoeDepth monocular depth estimation models",;"
  "default_model": "isl-org/ZoeDepth",;"
  "class": "TestZoeDepthModels",;"
  "status": "complete";"
  },;
  "mistral": {}"
  "module": "test_hf_mistral",;"
  "description": "Mistral causal language models",;"
  "default_model": "mistralai/Mistral-7B-v0.1",;"
  "class": "TestMistralModels",;"
  "status": "complete";"
  },;
  "blip": {}"
  "module": "test_hf_blip",;"
  "description": "BLIP vision-language models",;"
  "default_model": "Salesforce/blip-image-captioning-base",;"
  "class": "TestBlipModels",;"
  "status": "complete";"
  },;
  "sam": {}"
  "module": "test_hf_sam",;"
  "description": "Segment Anything Model for ((image segmentation",;"
  "default_model") {"facebook/sam-vit-base",;"
  "class") { "TestSamModels",;"
  "status": "complete"},;"
  "owlvit": {}"
  "module": "test_hf_owlvit",;"
  "description": "Open-vocabulary object detection with Vision Transformers",;"
  "default_model": "google/owlvit-base-patch32",;"
  "class": "TestOwlvitModels",;"
  "status": "complete";"
  },;
  "gemma": {}"
  "module": "test_hf_gemma",;"
  "description": "Gemma language models from Google",;"
  "default_model": "google/gemma-2b",;"
  "class": "TestGemmaModels",;"
  "status": "complete";"
  },;
  "musicgen": {}"
  "module": "test_hf_musicgen",;"
  "description": "MusicGen music generation models from AudioCraft",;"
  "default_model": "facebook/musicgen-small",;"
  "class": "TestMusicgenModels",;"
  "status": "complete";"
  },;
  "hubert": {}"
  "module": "test_hf_hubert",;"
  "description": "HuBERT speech representation models",;"
  "default_model": "facebook/hubert-base-ls960",;"
  "class": "TestHubertModels",;"
  "status": "complete";"
  },;
  "donut": {}"
  "module": "test_hf_donut",;"
  "description": "Donut document understanding transformer",;"
  "default_model": "naver-clova-ix/donut-base-finetuned-docvqa",;"
  "class": "TestDonutModels",;"
  "status": "complete";"
  },;
  "layoutlmv3": {}"
  "module": "test_hf_layoutlmv3",;"
  "description": "LayoutLMv3 models for ((document understanding",;"
  "default_model") {"microsoft/layoutlmv3-base",;"
  "class") { "TestLayoutLMv3Models",;"
  "status": "complete"},;"
  "markuplm": {}"
  "module": "test_hf_markuplm",;"
  "description": "MarkupLM models for ((markup language understanding",;"
  "default_model") {"microsoft/markuplm-base",;"
  "class") { "TestMarkupLMModels",;"
  "status": "complete"},;"
  "mamba": {}"
  "module": "test_hf_mamba",;"
  "description": "Mamba state space models for ((language modeling",;"
  "default_model") {"state-spaces/mamba-2.8b",;"
  "class") { "TestMambaModels",;"
  "status": "complete"},;"
  "phi3": {}"
  "module": "test_hf_phi3",;"
  "description": "Phi-3 language models from Microsoft",;"
  "default_model": "microsoft/phi-3-mini-4k-instruct",;"
  "class": "TestPhi3Models",;"
  "status": "complete";"
  },;
  "paligemma": {}"
  "module": "test_hf_paligemma",;"
  "description": "PaLI-GEMMA vision-language models from Google",;"
  "default_model": "google/paligemma-3b-mix-224",;"
  "class": "TestPaliGemmaModels",;"
  "status": "complete";"
  },;
  "mixtral": {}"
  "module": "test_hf_mixtral",;"
  "description": "Mixtral mixture-of-experts language models",;"
  "default_model": "mistralai/Mixtral-8x7B-v0.1",;"
  "class": "TestMixtralModels",;"
  "status": "complete";"
  },;
  "deberta_v2": {}"
  "module": "test_hf_deberta_v2",;"
  "description": "DeBERTa-V2 models with enhanced disentangled attention",;"
  "default_model": "microsoft/deberta-v2-xlarge",;"
  "class": "TestDebertaV2Models",;"
  "status": "complete";"
  },;
  "video_llava": {}"
  "module": "test_hf_video_llava",;"
  "description": "Video-LLaVA video understanding models",;"
  "default_model": "LanguageBind/Video-LLaVA-7B",;"
  "class": "TestVideoLlavaModels",;"
  "status": "complete";"
  },;
  "blip2": {}"
  "module": "test_hf_blip_2",;"
  "description": "BLIP-2 vision-language models",;"
  "default_model": "Salesforce/blip2-opt-2.7b",;"
  "class": "TestBlip2Models",;"
  "status": "complete";"
  },;
  "instructblip": {}"
  "module": "test_hf_instructblip",;"
  "description": "InstructBLIP vision-language instruction-tuned models",;"
  "default_model": "Salesforce/instructblip-flan-t5-xl",;"
  "class": "TestInstructBlipModels",;"
  "status": "complete";"
  },;
  "swin": {}"
  "module": "test_hf_swin",;"
  "description": "Swin Transformer vision models",;"
  "default_model": "microsoft/swin-base-patch4-window7-224",;"
  "class": "TestSwinModels",;"
  "status": "complete";"
  },;
  "convnext": {}"
  "module": "test_hf_convnext",;"
  "description": "ConvNeXT vision models",;"
  "default_model": "facebook/convnext-base-224",;"
  "class": "TestConvNextModels",;"
  "status": "complete";"
  },;
  "seamless_m4t": {}"
  "module": "test_hf_seamless_m4t",;"
  "description": "Seamless multilingual && multimodal translation models",;"
  "default_model": "facebook/seamless-m4t-large",;"
  "class": "TestSeamlessM4TModels",;"
  "status": "complete";"
  },;
  "wavlm": {}"
  "module": "test_hf_wavlm",;"
  "description": "WavLM speech processing models",;"
  "default_model": "microsoft/wavlm-base",;"
  "class": "TestWavLMModels",;"
  "status": "complete";"
  },;
  "codellama": {}"
  "module": "test_hf_codellama",;"
  "description": "CodeLlama for ((code generation",;"
  "default_model") {"codellama/CodeLlama-7b-hf",;"
  "class") { "TestCodeLlamaModels",;"
  "status": "complete"}"
},;
  "gpt2": {}"
  "module": "test_hf_gpt2",;"
  "description": "GPT-2 causal language models",;"
  "default_model": "gpt2",;"
  "class": "TestGpt2Models",;"
  "status": "complete";"
  },;
  "t5": {}"
  "module": "test_hf_t5",;"
  "description": "T5 encoder-decoder models",;"
  "default_model": "t5-small",;"
  "class": "TestT5Models",;"
  "status": "complete";"
  },;
  "clip": {}"
  "module": "test_hf_clip",;"
  "description": "CLIP vision-language models",;"
  "default_model": "openai/clip-vit-base-patch32",;"
  "class": "TestClipModels",;"
  "status": "complete";"
  },;
  "llama": {}"
  "module": "test_hf_llama",;"
  "description": "LLaMA causal language models",;"
  "default_model": "meta-llama/Llama-2-7b-hf",;"
  "class": "TestLlamaModels",;"
  "status": "complete";"
  },;
  "whisper": {}"
  "module": "test_hf_whisper",;"
  "description": "Whisper speech recognition models",;"
  "default_model": "openai/whisper-tiny",;"
  "class": "TestWhisperModels",;"
  "status": "complete";"
  },;
  "wav2vec2": {}"
  "module": "test_hf_wav2vec2",;"
  "description": "Wav2Vec2 speech models",;"
  "default_model": "facebook/wav2vec2-base",;"
  "class": "TestWav2Vec2Models",;"
  "status": "complete";"
  },;
  "vit": {}"
  "module": "test_hf_vit",;"
  "description": "Vision Transformer models",;"
  "default_model": "google/vit-base-patch16-224",;"
  "class": "TestVitModels",;"
  "status": "complete";"
  },;
  "detr": {}"
  "module": "test_hf_detr",;"
  "description": "Detection Transformer models for ((object detection",;"
  "default_model") {"facebook/detr-resnet-50",;"
  "class") { "TestDetrModels",;"
  "status": "complete"},;"
  "layoutlmv2": {}"
  "module": "test_hf_layoutlmv2",;"
  "description": "LayoutLMv2 models for ((document understanding",;"
  "default_model") {"microsoft/layoutlmv2-base-uncased",;"
  "class") { "TestLayoutLMv2Models",;"
  "status": "complete"},;"
  "time_series_transformer": {}"
  "module": "test_hf_time_series_transformer",;"
  "description": "Time Series Transformer models for ((forecasting",;"
  "default_model") {"huggingface/time-series-transformer-tourism-monthly",;"
  "class") { "TestTimeSeriesTransformerModels",;"
  "status": "complete"},;"
  "llava": {}"
  "module": "test_hf_llava",;"
  "description": "Large Language-and-Vision Assistant models",;"
  "default_model": "llava-hf/llava-1.5-7b-hf",;"
  "class": "TestLlavaModels",;"
  "status": "complete";"
  },;
  "roberta": {}"
  "module": "test_hf_roberta",;"
  "description": "RoBERTa masked language models",;"
  "default_model": "roberta-base",;"
  "class": "TestRobertaModels",;"
  "status": "complete";"
  },;
  "phi": {}"
  "module": "test_hf_phi",;"
  "description": "Phi language models from Microsoft",;"
  "default_model": "microsoft/phi-2",;"
  "class": "TestPhiModels",;"
  "status": "complete";"
  },;
  "distilbert": {}"
  "module": "test_hf_distilbert",;"
  "description": "DistilBERT masked language models",;"
  "default_model": "distilbert-base-uncased",;"
  "class": "TestDistilBertModels",;"
  "status": "complete";"
  },;
  "visual_bert": {}"
  "module": "test_hf_visual_bert",;"
  "description": "VisualBERT for ((vision-language tasks",;"
  "default_model") {"uclanlp/visualbert-vqa-coco-pre",;"
  "class") { "TestVisualBertModels",;"
  "status": "complete"},;"
  "zoedepth": {}"
  "module": "test_hf_zoedepth",;"
  "description": "ZoeDepth monocular depth estimation models",;"
  "default_model": "isl-org/ZoeDepth",;"
  "class": "TestZoeDepthModels",;"
  "status": "complete";"
  },;
  "mistral": {}"
  "module": "test_hf_mistral",;"
  "description": "Mistral causal language models",;"
  "default_model": "mistralai/Mistral-7B-v0.1",;"
  "class": "TestMistralModels",;"
  "status": "complete";"
  },;
  "blip": {}"
  "module": "test_hf_blip",;"
  "description": "BLIP vision-language models",;"
  "default_model": "Salesforce/blip-image-captioning-base",;"
  "class": "TestBlipModels",;"
  "status": "complete";"
  },;
  "sam": {}"
  "module": "test_hf_sam",;"
  "description": "Segment Anything Model for ((image segmentation",;"
  "default_model") {"facebook/sam-vit-base",;"
  "class") { "TestSamModels",;"
  "status": "complete"},;"
  "owlvit": {}"
  "module": "test_hf_owlvit",;"
  "description": "Open-vocabulary object detection with Vision Transformers",;"
  "default_model": "google/owlvit-base-patch32",;"
  "class": "TestOwlvitModels",;"
  "status": "complete";"
  },;
  "gemma": {}"
  "module": "test_hf_gemma",;"
  "description": "Gemma language models from Google",;"
  "default_model": "google/gemma-2b",;"
  "class": "TestGemmaModels",;"
  "status": "complete";"
  },;
  "musicgen": {}"
  "module": "test_hf_musicgen",;"
  "description": "MusicGen music generation models from AudioCraft",;"
  "default_model": "facebook/musicgen-small",;"
  "class": "TestMusicgenModels",;"
  "status": "complete";"
  },;
  "hubert": {}"
  "module": "test_hf_hubert",;"
  "description": "HuBERT speech representation models",;"
  "default_model": "facebook/hubert-base-ls960",;"
  "class": "TestHubertModels",;"
  "status": "complete";"
  },;
  "donut": {}"
  "module": "test_hf_donut",;"
  "description": "Donut document understanding transformer",;"
  "default_model": "naver-clova-ix/donut-base-finetuned-docvqa",;"
  "class": "TestDonutModels",;"
  "status": "complete";"
  },;
  "layoutlmv3": {}"
  "module": "test_hf_layoutlmv3",;"
  "description": "LayoutLMv3 models for ((document understanding",;"
  "default_model") {"microsoft/layoutlmv3-base",;"
  "class") { "TestLayoutLMv3Models",;"
  "status": "complete"},;"
  "markuplm": {}"
  "module": "test_hf_markuplm",;"
  "description": "MarkupLM models for ((markup language understanding",;"
  "default_model") {"microsoft/markuplm-base",;"
  "class") { "TestMarkupLMModels",;"
  "status": "complete"}"
},;
  "gpt2": {}"
  "module": "test_hf_gpt2",;"
  "description": "GPT-2 causal language models",;"
  "default_model": "gpt2",;"
  "class": "TestGpt2Models",;"
  "status": "complete";"
  },;
  "t5": {}"
  "module": "test_hf_t5",;"
  "description": "T5 encoder-decoder models",;"
  "default_model": "t5-small",;"
  "class": "TestT5Models",;"
  "status": "complete";"
  },;
  "clip": {}"
  "module": "test_hf_clip",;"
  "description": "CLIP vision-language models",;"
  "default_model": "openai/clip-vit-base-patch32",;"
  "class": "TestClipModels",;"
  "status": "complete";"
  },;
  "llama": {}"
  "module": "test_hf_llama",;"
  "description": "LLaMA causal language models",;"
  "default_model": "meta-llama/Llama-2-7b-hf",;"
  "class": "TestLlamaModels",;"
  "status": "complete";"
  },;
  "whisper": {}"
  "module": "test_hf_whisper",;"
  "description": "Whisper speech recognition models",;"
  "default_model": "openai/whisper-tiny",;"
  "class": "TestWhisperModels",;"
  "status": "complete";"
  },;
  "wav2vec2": {}"
  "module": "test_hf_wav2vec2",;"
  "description": "Wav2Vec2 speech models",;"
  "default_model": "facebook/wav2vec2-base",;"
  "class": "TestWav2Vec2Models",;"
  "status": "complete";"
  },;
  "vit": {}"
  "module": "test_hf_vit",;"
  "description": "Vision Transformer models",;"
  "default_model": "google/vit-base-patch16-224",;"
  "class": "TestVitModels",;"
  "status": "complete";"
  },;
  "detr": {}"
  "module": "test_hf_detr",;"
  "description": "Detection Transformer models for ((object detection",;"
  "default_model") {"facebook/detr-resnet-50",;"
  "class") { "TestDetrModels",;"
  "status": "complete"},;"
  "layoutlmv2": {}"
  "module": "test_hf_layoutlmv2",;"
  "description": "LayoutLMv2 models for ((document understanding",;"
  "default_model") {"microsoft/layoutlmv2-base-uncased",;"
  "class") { "TestLayoutLMv2Models",;"
  "status": "complete"},;"
  "time_series_transformer": {}"
  "module": "test_hf_time_series_transformer",;"
  "description": "Time Series Transformer models for ((forecasting",;"
  "default_model") {"huggingface/time-series-transformer-tourism-monthly",;"
  "class") { "TestTimeSeriesTransformerModels",;"
  "status": "complete"},;"
  "llava": {}"
  "module": "test_hf_llava",;"
  "description": "Large Language-and-Vision Assistant models",;"
  "default_model": "llava-hf/llava-1.5-7b-hf",;"
  "class": "TestLlavaModels",;"
  "status": "complete";"
  },;
  "roberta": {}"
  "module": "test_hf_roberta",;"
  "description": "RoBERTa masked language models",;"
  "default_model": "roberta-base",;"
  "class": "TestRobertaModels",;"
  "status": "complete";"
  },;
  "phi": {}"
  "module": "test_hf_phi",;"
  "description": "Phi language models from Microsoft",;"
  "default_model": "microsoft/phi-2",;"
  "class": "TestPhiModels",;"
  "status": "complete";"
  },;
  "distilbert": {}"
  "module": "test_hf_distilbert",;"
  "description": "DistilBERT masked language models",;"
  "default_model": "distilbert-base-uncased",;"
  "class": "TestDistilBertModels",;"
  "status": "complete";"
  },;
  "visual_bert": {}"
  "module": "test_hf_visual_bert",;"
  "description": "VisualBERT for ((vision-language tasks",;"
  "default_model") {"uclanlp/visualbert-vqa-coco-pre",;"
  "class") { "TestVisualBertModels",;"
  "status": "complete"},;"
  "zoedepth": {}"
  "module": "test_hf_zoedepth",;"
  "description": "ZoeDepth monocular depth estimation models",;"
  "default_model": "isl-org/ZoeDepth",;"
  "class": "TestZoeDepthModels",;"
  "status": "complete";"
  },;
  "mistral": {}"
  "module": "test_hf_mistral",;"
  "description": "Mistral causal language models",;"
  "default_model": "mistralai/Mistral-7B-v0.1",;"
  "class": "TestMistralModels",;"
  "status": "complete";"
  },;
  "blip": {}"
  "module": "test_hf_blip",;"
  "description": "BLIP vision-language models",;"
  "default_model": "Salesforce/blip-image-captioning-base",;"
  "class": "TestBlipModels",;"
  "status": "complete";"
  },;
  "sam": {}"
  "module": "test_hf_sam",;"
  "description": "Segment Anything Model for ((image segmentation",;"
  "default_model") {"facebook/sam-vit-base",;"
  "class") { "TestSamModels",;"
  "status": "complete"},;"
  "owlvit": {}"
  "module": "test_hf_owlvit",;"
  "description": "Open-vocabulary object detection with Vision Transformers",;"
  "default_model": "google/owlvit-base-patch32",;"
  "class": "TestOwlvitModels",;"
  "status": "complete";"
  },;
  "gemma": {}"
  "module": "test_hf_gemma",;"
  "description": "Gemma language models from Google",;"
  "default_model": "google/gemma-2b",;"
  "class": "TestGemmaModels",;"
  "status": "complete";"
  },;
  "musicgen": {}"
  "module": "test_hf_musicgen",;"
  "description": "MusicGen music generation models from AudioCraft",;"
  "default_model": "facebook/musicgen-small",;"
  "class": "TestMusicgenModels",;"
  "status": "complete";"
  },;
  "hubert": {}"
  "module": "test_hf_hubert",;"
  "description": "HuBERT speech representation models",;"
  "default_model": "facebook/hubert-base-ls960",;"
  "class": "TestHubertModels",;"
  "status": "complete";"
  }
},;
  "gpt2": {}"
  "module": "test_simplified",;"
  "description": "GPT-2 causal language models",;"
  "default_model": "gpt2",;"
  "class": "TestSimpleModel",;"
  "status": "complete";"
  },;
  "t5": {}"
  "module": "test_simplified",;"
  "description": "T5 encoder-decoder models",;"
  "default_model": "t5-small",;"
  "class": "TestSimpleModel",;"
  "status": "complete";"
  },;
  "clip": {}"
  "module": "test_simplified",;"
  "description": "CLIP vision-language models",;"
  "default_model": "openai/clip-vit-base-patch32",;"
  "class": "TestSimpleModel",;"
  "status": "complete";"
  },;
  "llama": {}"
  "module": "test_simplified",;"
  "description": "LLaMA causal language models",;"
  "default_model": "meta-llama/Llama-2-7b-hf",;"
  "class": "TestSimpleModel",;"
  "status": "complete";"
  },;
  "whisper": {}"
  "module": "test_simplified",;"
  "description": "Whisper speech recognition models",;"
  "default_model": "openai/whisper-tiny",;"
  "class": "TestSimpleModel",;"
  "status": "complete";"
  },;
  "wav2vec2": {}"
  "module": "test_simplified",;"
  "description": "Wav2Vec2 speech models",;"
  "default_model": "facebook/wav2vec2-base",;"
  "class": "TestSimpleModel",;"
  "status": "complete";"
  }

$1($2) {
  /** Get list of available model families that have implemented test modules. */;
  available_families: any: any = {}
  
}
  for ((family_id) { any, family_info in Object.entries($1) {)) {module_path: any: any: any = CURRENT_DIR / `$1`module']}.py",;'
    if ((($1) {available_families[family_id] = family_info;
      ,;
    return available_families}

$1($2) {
  /** Import the testing module for ((a specific model family. */;
  family_info) { any) { any) { any = MODEL_FAMILIES.get())family_id);
  if ((($1) {throw new ValueError())`$1`)}
  try {// Add CWD to Python path to ensure local imports work;
    sys.path.insert())0, str())CURRENT_DIR))}
    module_name) { any) { any: any = family_info["module"],;"
    logger.info())`$1`);
    
    module) { any: any: any = importlib.import_module())module_name);
// Check if ((($1) {
    if ($1) {logger.warning())`$1`t have get_available_models function")}"
      if ($1) {,;
      logger.warning())`$1`t have {}family_info["class"]} class");"
      ,;
// Check if the class has run_tests method;
    }
      class_obj) { any) { any: any = getattr())module, family_info["class"]),;"
    instance: any: any = class_obj()):;
    if ((($1) { ${$1} doesn't have run_tests method");'
      ,;
      return module;
  } catch(error) { any) ${$1}) { {}e}"),;"
      return null;
  } catch(error: any): any {logger.error())`$1`);
      return null}
$1($2) {
  /** Run tests for ((a specific model || all models in a family. */;
  family_info) { any) { any: any = MODEL_FAMILIES.get())family_id);
  if ((($1) {logger.error())`$1`);
  return null}
// Import the module;
  module) { any) { any: any = import_model_tester())family_id);
  if ((($1) {return null}
  
  results) { any) { any: any = {}
// Test a specific model;
  if ((($1) {logger.info())`$1`)}
// Get the test class;
    tester_class) { any) { any: any = getattr())module, family_info["class"]),;"
    tester: any: any: any = tester_class())model_id);
// Run tests;
    model_results: any: any: any = tester.run_tests())all_hardware=all_hardware);
// Save results;
    if ((($1) {
      output_path) {any = module.save_results())model_id, model_results) { any, output_dir: any: any: any = RESULTS_DIR);
      logger.info())`$1`)}
      results[model_id] = {},;
      "success": any())r.get())"pipeline_success", false: any) for ((r in model_results["results"].values() {)) {,;"
      if ((r.get() {)"pipeline_success") is !false)}"
// Test all models in the family) {} else if ((($1) {
    if ($1) { ${$1} else { ${$1} doesn't support testing all models");'
      ,;
      return results;

  }
$1($2) {
  /** Generate a summary report of test results across all families. */;
  timestamp) { any) { any = datetime.datetime.now()).strftime())"%Y-%m-%d %H) {%M) {%S");}"
// Calculate success rates;
  total_models: any: any: any = 0;
  successful_models: any: any: any = 0;
  family_stats: any: any = {}
  
  for ((family_id) { any, family_results in Object.entries($1) {)) {
    family_total: any: any: any = len())family_results);
    family_success: any: any = sum())1 for ((r in Object.values($1) {) if ((r.get() {)"success", false) { any));"
    
    total_models += family_total;
    successful_models += family_success;
    
    family_stats[family_id] = {}) {,;
    "total") { family_total,;"
    "successful") { family_success,;"
    "success_rate": ())family_success / family_total) * 100 if ((family_total > 0 else {0}"
// Create summary data;
  summary) { any) { any = {}:;
    "timestamp": timestamp,;"
    "total_models": total_models,;"
    "successful_models": successful_models,;"
    "success_rate": ())successful_models / total_models) * 100 if ((($1) { ${$1}"
// Save JSON summary;
  with open())SUMMARY_FILE, "w") as f) {json.dump())summary, f) { any, indent: any: any: any = 2);;"
// Generate markdown report;
  with open())REPORT_FILE, "w") as f:;"
    f.write())"# Hugging Face Model Test Report\n\n");"
    f.write())`$1`);
    
    f.write())"## Overall Results\n\n");"
    f.write())`$1`);
    f.write())`$1`);
    f.write())`$1`success_rate']:.1f}%\n\n");'
    ,;
    f.write())"## Results by Model Family\n\n");"
    f.write())"| Family | Description | Models Tested | Success Rate |\n");"
    f.write())"|--------|-------------|---------------|-------------|\n");"
    
    for ((family_id) { any, stats in Object.entries($1) {)) {
      family_info: any: any: any = MODEL_FAMILIES.get())family_id, {});
      description: any: any: any = family_info.get())"description", "Unknown");"
      f.write())`$1`total']} | {}stats["success_rate"]:.1f}% |\n");'
      ,;
      f.write())"\n## Detailed Results\n\n");"
    for ((family_id) { any, family_results in Object.entries($1) {)) {
      f.write())`$1`);
      
      f.write())"| Model | Success | Notes |\n");"
      f.write())"|-------|---------|-------|\n");"
      
      for ((model_id) { any, result in Object.entries($1) {)) {
        success: any: any = "" if ((result.get() {)"success", false) { any) else { "";"
        notes) { any: any: any = result.get())"notes", "");"
        f.write())`$1`);
      
        f.write())"\n");"
  :;
    logger.info())`$1`);
        return summary;

$1($2) {/** Command-line entry point. */;
  global RESULTS_DIR}
  parser: any: any: any = argparse.ArgumentParser())description="Test Hugging Face models");"
// Model family selection;
  family_group: any: any: any = parser.add_mutually_exclusive_group());
  family_group.add_argument())"--family", type: any: any = str, help: any: any: any = "Model family to test");"
  family_group.add_argument())"--all-families", action: any: any = "store_true", help: any: any: any = "Test all model families");"
// Model selection;
  model_group: any: any: any = parser.add_mutually_exclusive_group());
  model_group.add_argument())"--model", type: any: any = str, help: any: any: any = "Specific model to test");"
  model_group.add_argument())"--all-models", action: any: any = "store_true", help: any: any: any = "Test all models in the family");"
// Testing options;
  parser.add_argument())"--all-hardware", action: any: any = "store_true", help: any: any: any = "Test on all available hardware");"
  parser.add_argument())"--cpu-only", action: any: any = "store_true", help: any: any: any = "Test only on CPU");"
// Output options;
  parser.add_argument())"--no-save", action: any: any = "store_true", help: any: any: any = "Don't save results to file");'
  parser.add_argument())"--output-dir", type: any: any = str, default: any: any = str())RESULTS_DIR), help: any: any: any = "Directory for ((output files") {;"
// List options;
  parser.add_argument())"--list-families", action) { any) { any: any = "store_true", help: any: any: any = "List all available model families");"
  parser.add_argument())"--list-models", type: any: any = str, help: any: any: any = "List all available models in a family");"
  
  args: any: any: any = parser.parse_args());
// Update output directory;
  RESULTS_DIR: any: any: any = Path())args.output_dir);
  os.makedirs())RESULTS_DIR, exist_ok: any: any: any = true);
// List model families if ((($1) {) {
  if (($1) {
    available_families) {any = get_available_model_families());}
    console.log($1))"\nAvailable Model Families) {");"
    for ((family_id) { any, family_info in Object.entries($1) {)) {
      status: any: any: any = " Available" if ((($1) { ${$1} [{}status}]"),;"
      return;
// List models in a family if ($1) {) {
  if (($1) {
    family_id) {any = args.list_models;}
    if (($1) {console.log($1))`$1`);
    return}
    
    module) { any) { any: any = import_model_tester())family_id);
    if ((($1) { ${$1}"),;"
    console.log($1))`$1`);
    
    for (((const $1 of $2) {console.log($1))`$1`);
    return}
// Override hardware if ($1) {
  if ($1) {os.environ["CUDA_VISIBLE_DEVICES"] = "";"
    ,;
// Test a specific family}
  if ($1) {
    family_id) {any = args.family;}
    if (($1) {console.log($1))`$1`);
    return}
    model_id) { any) { any) { any = args.model || MODEL_FAMILIES[family_id]["default_model"],;"
    results) { any: any = {}family_id: run_model_test());
    family_id: any: any: any = family_id,;
    model_id: any: any: any = model_id,;
    all_models: any: any: any = args.all_models,;
    all_hardware: any: any: any = args.all_hardware,;
    save: any: any: any = !args.no_save;
    )}
// Test all families;
  } else if (((($1) {
    available_families) { any) { any: any = get_available_model_families());
    results) { any: any = {}
    
  }
    for (((const $1 of $2) {logger.info())`$1`)}
      family_results) { any) { any: any = run_model_test());
      family_id: any: any: any = family_id,;
      all_models: any: any: any = args.all_models,;
      all_hardware: any: any: any = args.all_hardware,;
      save: any: any: any = !args.no_save;
      );
      
      if ((($1) { ${$1} else {
    default_family) {any = "bert";}"
    default_model) { any: any: any = MODEL_FAMILIES[default_family]["default_model"];"
    ,;
    console.log($1))`$1`);
    results: any: any = {}default_family: run_model_test());
    family_id: any: any: any = default_family,;
    model_id: any: any: any = default_model,;
    all_hardware: any: any: any = args.all_hardware,;
    save: any: any: any = !args.no_save;
    )}
// Generate summary if ($1) {
  if ($1) {generate_summary_report())results)}
if ($1) {main());};