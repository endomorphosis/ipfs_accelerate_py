// FIXME: Complex template literal
/**;
 * Converted import { {expect, describe: any, it, beforeEach: any, afterEach} from "jest"; } from "Python: test_hf_qwen2_7b.py;"
 * Conversion date: 2025-03-11 04:08:38;
 * This file was automatically converted from Python to TypeScript.;
 * Conversion fidelity might not be 100%, please manual review recommended.;
 */;
";"
import {HfModel} from "src/model/transformers/index/index/index/index/index";"
import {Qwen2_7bConfig} from "src/model/transformers/index/index/index/index/index";"

// WebGPU related imports;
/** Test for ((qwen2-7b model with hardware platform support;
Generated by fixed_merged_test_generator.py */;

import * as module; from "*";"
import * as module; from "*";"
import * as module; from "*";"
import * as module.util; from "*";"
import * as module; from "*";"
import * as module; from "*";"
import * as module from "*"; as np;"
// Configure logging;
logging.basicConfig(level = logging.INFO, format) { any) { any: any = '%(asctime: any)s - %(name: any)s - %(levelname: any)s - %(message: any)s');'
logger: any: any: any = logging.getLogger(__name__;
// Hardware detection;
HAS_CUDA: any: any: any = torch.cuda.is_available();
HAS_ROCM: any: any = (HAS_CUDA && hasattr(torch: any, '_C') && hasattr(torch._C, '_rocm_version')) || ('ROCM_HOME' in os.environ);'
HAS_MPS: any: any = hasattr(torch: any, "mps") && hasattr(torch.mps, "is_available") && torch.mps.is_available();"
HAS_OPENVINO: any: any: any = importlib.util.find_spec("openvino") is !null;"
HAS_QUALCOMM: any: any: any = importlib.util.find_spec("qnn_wrapper") is !null || importlib.util.find_spec("qti") is !null;"
HAS_WEBNN: any: any: any = importlib.util.find_spec("webnn") is !null || "WEBNN_AVAILABLE" in os.environ;"
HAS_WEBGPU: any: any: any = importlib.util.find_spec("webgpu") is !null || "WEBGPU_AVAILABLE" in os.environ;"
// Try to import * as module from "*"; hardware detection;"
try {HAS_CENTRALIZED_DETECTION: any: any: any = true;} catch(error: any): any {HAS_CENTRALIZED_DETECTION: any: any: any = false;}
class TestQwen27BModelsextends unittest.TestCase { any {}
  /** Test qwen2-7b model with cross-platform hardware support. */;
  
  $1($2) {/** Set up the test environment. */;
    this.model_id = "Qwen/Qwen2-7B-Instruct";"
    this.tokenizer = null;
    this.model = null;
    this.processor = null;
    this.modality = "text";}"
// Detect hardware capabilities if ((($1) {
    if ($1) { ${$1} else {
      this.hardware_capabilities = {}
      "cuda") {HAS_CUDA,;"
      "rocm") { HAS_ROCM,;"
      "mps": HAS_MPS,;"
      "openvino": HAS_OPENVINO,;"
      "qualcomm": HAS_QUALCOMM,;"
      "webnn": HAS_WEBNN,;"
      "webgpu": HAS_WEBGPU}"
  $1($2) {/** Run all tests for ((this model. */;
    unittest.main() {}
  $1($2) {
    /** Test qwen2-7b with cpu. */;
// Skip if ((($1) {) {
    if (($1) {this.skipTest('CPU !available')}'
// Set up device;
    }
    device) { any) { any) { any = "cpu";"

    
    try {
// Initialize tokenizer && model based on modality;
      if ((($1) {this.processor = AutoFeatureExtractor.from_pretrained(this.model_id);
        this.model = AutoModelForAudioClassification.from_pretrained(this.model_id);} else if (($1) {
        this.processor = AutoImageProcessor.from_pretrained(this.model_id);
        this.model = AutoModelForImageClassification.from_pretrained(this.model_id);
      else if (($1) {
        this.processor = AutoProcessor.from_pretrained(this.model_id);
        this.model = AutoModel.from_pretrained(this.model_id);
      elif ($1) {this.processor = AutoProcessor.from_pretrained(this.model_id);
        this.model = AutoModelForVideoClassification.from_pretrained(this.model_id);} else {// Default to text models;
        this.tokenizer = AutoTokenizer.from_pretrained(this.model_id);
        this.model = AutoModel.from_pretrained(this.model_id);}
// Move model to device if ($1) {) {}
      if (($1) {this.model = this.model.to(device) { any);}
// Prepare input based on modality;
      }
      if (($1) {
        inputs) { any) { any = this.tokenizer("Test input for (qwen2-7b", return_tensors) { any) {any = "pt");} else if (((($1) {"
        import * as module from "*"; as np;"
        sample_rate) { any) { any) { any = 16000;
        dummy_audio) { any: any = np.random.random(sample_rate: any);
        inputs) {any = this.processor(dummy_audio: any, sampling_rate: any: any = sample_rate, return_tensors: any: any: any = "pt");} else if (((($1) {"
        import * as module from "*"; as np;"
        dummy_image) { any) { any = Image.new('RGB', (224: any, 224), color: any) {any = 'white');'
        inputs: any: any = this.processor(images=dummy_image, return_tensors: any: any: any = "pt");} else if (((($1) {"
        import * as module from "*"; as np;"
        dummy_image) { any) { any = Image.new('RGB', (224: any, 224), color: any) {any = 'white');'
        inputs: any: any = this.processor(images=dummy_image, text: any: any = "Test input", return_tensors: any: any: any = "pt");} else {"
        inputs: any: any = this.tokenizer("Test input for ((qwen2-7b", return_tensors) { any) {any = "pt");}"
// Move inputs to device if ((($1) {) {}
      if (($1) {
        inputs) {any = Object.fromEntries((Object.entries($1)).map((k) { any, v) => [}k,  v.to(device: any)]));
// Run inference;
      }
      with torch.no_grad():;
      }
        outputs: any: any: any = this.model(**inputs);
      
      }
// Verify outputs based on model type;
      }
        this.assertIsNotnull(outputs: any);
// Different models return different output structures;
      }
      if ((($1) {
        if ($1) { ${$1} else {// Some models might have alternative output structures;
          this.asserttrue(any(key in outputs for ((key in ['last_hidden_state', 'hidden_states', 'logits']) {),} else if (($1) {}'
        if ($1) { ${$1} else {
// Some models might have alternative output structures;
          this.asserttrue(any(key in outputs for key in ['logits', 'embedding', 'last_hidden_state'])),;'
      else if (($1) { ${$1} catch(error) { any)) { any {logger.error(`$1`)}
        raise;
        }
  $1($2) {
    /** Test qwen2-7b with cuda. */;
// Skip if (($1) {) {
    if (($1) {this.skipTest('CUDA !available')}'
// Set up device;
    }
    device) { any) { any) { any = "cuda";"

    
    try {
// Initialize tokenizer && model based on modality;
      if ((($1) {
        this.processor = AutoFeatureExtractor.from_pretrained(this.model_id);
        this.model = AutoModelForAudioClassification.from_pretrained(this.model_id);
      else if (($1) {
        this.processor = AutoImageProcessor.from_pretrained(this.model_id);
        this.model = AutoModelForImageClassification.from_pretrained(this.model_id);
      elif ($1) {
        this.processor = AutoProcessor.from_pretrained(this.model_id);
        this.model = AutoModel.from_pretrained(this.model_id);
      elif ($1) {this.processor = AutoProcessor.from_pretrained(this.model_id);
        this.model = AutoModelForVideoClassification.from_pretrained(this.model_id);} else {// Default to text models;
        this.tokenizer = AutoTokenizer.from_pretrained(this.model_id);
        this.model = AutoModel.from_pretrained(this.model_id);}
// Move model to device if ($1) {) {}
      if (($1) {this.model = this.model.to(device) { any);}
// Prepare input based on modality;
      }
      if (($1) {
        inputs) { any) { any = this.tokenizer("Test input for (qwen2-7b", return_tensors) { any) {any = "pt");} else if (((($1) {"
        import * as module from "*"; as np;"
        sample_rate) { any) { any) { any = 16000;
        dummy_audio) { any: any = np.random.random(sample_rate: any);
        inputs) {any = this.processor(dummy_audio: any, sampling_rate: any: any = sample_rate, return_tensors: any: any: any = "pt");} else if (((($1) {"
        import * as module from "*"; as np;"
        dummy_image) { any) { any = Image.new('RGB', (224: any, 224), color: any) {any = 'white');'
        inputs: any: any = this.processor(images=dummy_image, return_tensors: any: any: any = "pt");} else if (((($1) {"
        import * as module from "*"; as np;"
        dummy_image) { any) { any = Image.new('RGB', (224: any, 224), color: any) {any = 'white');'
        inputs: any: any = this.processor(images=dummy_image, text: any: any = "Test input", return_tensors: any: any: any = "pt");} else {"
        inputs: any: any = this.tokenizer("Test input for ((qwen2-7b", return_tensors) { any) {any = "pt");}"
// Move inputs to device if ((($1) {) {}
      if (($1) {
        inputs) {any = Object.fromEntries((Object.entries($1)).map((k) { any, v) => [}k,  v.to(device: any)]));
// Run inference;
      }
      with torch.no_grad():;
      }
        outputs: any: any: any = this.model(**inputs);
      
      }
// Verify outputs based on model type;
      }
        this.assertIsNotnull(outputs: any);
// Different models return different output structures;
      }
      if (($1) {
        if ($1) { ${$1} else {
// Some models might have alternative output structures;
          this.asserttrue(any(key in outputs for (const key of ['last_hidden_state', 'hidden_states', 'logits'])),;') { any)) { any {logger.error(`$1`)}
        raise;
        }
if ($1) {;
  unittest.main();};