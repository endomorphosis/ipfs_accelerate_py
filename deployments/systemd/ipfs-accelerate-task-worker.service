[Unit]
Description=ipfs_accelerate_py Task Worker (P2P + mDNS mesh)
After=network-online.target
Wants=network-online.target

[Service]
Type=simple
# Adjust to your checkout or installed location.
WorkingDirectory=/opt/ipfs_accelerate_py

# Load per-host settings (listen port, session tag, caches, etc.)
EnvironmentFile=-/etc/ipfs-accelerate/task-worker.env

# Enable docker task types by default (override in task-worker.env if needed).
Environment=IPFS_ACCELERATE_PY_TASK_WORKER_ENABLE_DOCKER=1
Environment=IPFS_DATASETS_PY_TASK_WORKER_ENABLE_DOCKER=1

# Run the TaskQueue worker daemon.
# Default behavior includes:
# - hosting the TaskQueue libp2p service
# - mDNS mesh draining
# - autoscaling by spawning/retiring child worker processes
#
# /etc/ipfs-accelerate/task-worker.env remains optional for per-host overrides
# (ports, session tags, queue path, max workers, disabling remote autoscale, etc.).
ExecStart=/opt/ipfs_accelerate_py/.venv/bin/python -m ipfs_accelerate_py.p2p_tasks.worker

Restart=always
RestartSec=2

# You almost certainly want a higher limit for model downloads.
LimitNOFILE=1048576

[Unit]
Description=IPFS Accelerate Task Worker (LEGACY)
After=network.target

# NOTE: This unit is intentionally kept as a legacy/manual option.
# The unified architecture runs orchestration (p2p service, mesh draining,
# worker scaling) inside the MCP service. Workers are spawned on-demand by
# the MCP orchestrator and should not be run as a standalone daemon.

[Service]
Type=simple
User=%i
WorkingDirectory=/opt/ipfs-accelerate-py
Environment=PYTHONUNBUFFERED=1
EnvironmentFile=-/etc/ipfs-accelerate/task-worker.env

# Thin executor only (no p2p service, no mesh, no autoscale).
ExecStart=/opt/ipfs-accelerate-py/.venv/bin/python -m ipfs_accelerate_py.p2p_tasks.worker --no-p2p-service --no-mesh --no-autoscale
Restart=always
RestartSec=5

[Install]
WantedBy=multi-user.target
