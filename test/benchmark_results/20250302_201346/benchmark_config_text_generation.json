{
  "batch_sizes": [
    1,
    4,
    8
  ],
  "warmup_iterations": 5,
  "benchmark_iterations": 20,
  "timeout": 600,
  "model_families": {
    "text_generation": [
      "TinyLlama/TinyLlama-1.1B-Chat-v1.0"
    ]
  },
  "hardware_types": [
    "cpu",
    "cuda",
    "openvino"
  ],
  "use_resource_pool": true,
  "parallel": true,
  "generate_plots": true
}