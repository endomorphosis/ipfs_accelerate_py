# Model Benchmark Report

Generated: 2025-03-02 20:13:49

## Summary

### Hardware Platforms

| Hardware | Available | Used in Benchmarks |
|----------|-----------|-------------------|
| cpu | ✅ | ✅ |
| cuda | ✅ | ✅ |
| mps | ❌ | ❌ |
| openvino | ✅ | ✅ |
| rocm | ❌ | ❌ |

### Models Tested

| Model Key | Full Name | Family | Size | Modality |
|-----------|-----------|--------|------|----------|
| clap | laion/clap-htsat-unfused | audio | base | audio |
| detr | facebook/detr-resnet-50 | vision | base | vision |
| llama | TinyLlama/TinyLlama-1.1B-Chat-v1.0 | text_generation | small | text |
| llava | llava-hf/llava-1.5-7b-hf | multimodal | base | multimodal |
| llava_next | llava-hf/llava-v1.6-mistral-7b | multimodal | base | multimodal |
| wav2vec2 | facebook/wav2vec2-base | audio | base | audio |

## Performance Benchmark Results

## Hardware Compatibility Matrix

### Model Family Compatibility

| Model Family | cpu | cuda | openvino |
|--------------|---|---|---|
| multimodal | ❌ | ❌ | ❌ |
| embedding | ❌ | ❌ | ❌ |
| audio | ❌ | ❌ | ❌ |
| text_generation | ❌ | ❌ | ❌ |
| vision | ❌ | ❌ | ❌ |

### Hardware-Specific Issues

No specific issues identified.

## Recommendations

### Hardware Selection


### Model Selection


### Performance Optimization

- Consider using smaller batch sizes for latency-sensitive applications
- Increase batch sizes for throughput-oriented workloads
- Enable model caching when running multiple inferences with the same model

### Compatibility Issues

- multimodal models are not compatible with: cpu, cuda, openvino
- embedding models are not compatible with: cpu, cuda, openvino
- audio models are not compatible with: cpu, cuda, openvino
- text_generation models are not compatible with: cpu, cuda, openvino
- vision models are not compatible with: cpu, cuda, openvino

## Next Steps

1. Run functionality verification tests
2. Perform detailed performance benchmarks
3. Update hardware compatibility matrix

---

Generated by Model Benchmark Runner on 2025-03-02 20:13:49
