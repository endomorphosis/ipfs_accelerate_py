
# ⚠️ SIMULATION WARNING ⚠️

**This report contains data from simulated hardware that may not reflect actual performance.**

The following hardware platforms were simulated:
- WEBGPU 
- WEBNN
- ROCM
- MPS
- QNN
- OPENVINO

Simulated results should be treated as approximations and not used for critical performance decisions without validation on actual hardware.

---


# ⚠️ WARNING: POTENTIALLY MISLEADING DATA ⚠️

**This report may contain simulated benchmark results that are presented as real hardware data.**

Issue: May contain simulation results presented as real data

*Marked as problematic by cleanup_stale_reports.py on 2025-03-06 19:14:42*

---

# Model Benchmark Report

Generated: 2025-03-02 20:13:49

## Summary

### Hardware Platforms

| Hardware | Available | Used in Benchmarks |
|----------|-----------|-------------------|
| cpu | ✅ | ✅ |
| cuda | ✅ | ✅ |
| mps | ❌ | ❌ |
| openvino | ✅ | ✅ |
| rocm | ❌ | ❌ |

### Models Tested

| Model Key | Full Name | Family | Size | Modality |
|-----------|-----------|--------|------|----------|
| clap | laion/clap-htsat-unfused | audio | base | audio |
| detr | facebook/detr-resnet-50 | vision | base | vision |
| llama | TinyLlama/TinyLlama-1.1B-Chat-v1.0 | text_generation | small | text |
| llava | llava-hf/llava-1.5-7b-hf | multimodal | base | multimodal |
| llava_next | llava-hf/llava-v1.6-mistral-7b | multimodal | base | multimodal |
| wav2vec2 | facebook/wav2vec2-base | audio | base | audio |

## Performance Benchmark Results

## Hardware Compatibility Matrix

### Model Family Compatibility

| Model Family | cpu | cuda | openvino |
|--------------|---|---|---|
| multimodal | ❌ | ❌ | ❌ |
| embedding | ❌ | ❌ | ❌ |
| audio | ❌ | ❌ | ❌ |
| text_generation | ❌ | ❌ | ❌ |
| vision | ❌ | ❌ | ❌ |

### Hardware-Specific Issues

No specific issues identified.

## Recommendations

### Hardware Selection


### Model Selection


### Performance Optimization

- Consider using smaller batch sizes for latency-sensitive applications
- Increase batch sizes for throughput-oriented workloads
- Enable model caching when running multiple inferences with the same model

### Compatibility Issues

- multimodal models are not compatible with: cpu, cuda, openvino
- embedding models are not compatible with: cpu, cuda, openvino
- audio models are not compatible with: cpu, cuda, openvino
- text_generation models are not compatible with: cpu, cuda, openvino
- vision models are not compatible with: cpu, cuda, openvino

## Next Steps

1. Run functionality verification tests
2. Perform detailed performance benchmarks
3. Update hardware compatibility matrix

---

Generated by Model Benchmark Runner on 2025-03-02 20:13:49
