{
  "models": [
    "prajjwal1/bert-tiny",
    "bert-base-uncased",
    "google/t5-efficient-tiny",
    "google/t5-small",
    "google/vit-base-patch16-224",
    "facebook/deit-tiny-patch16-224"
  ],
  "hardware": "cpu",
  "batch_sizes": "1",
  "timestamp": "2025-03-06T17:48:16.802295",
  "results": {
    "bert-base-uncased": {
      "model": "bert-base-uncased",
      "hardware": "cpu",
      "batch_sizes": "1",
      "command": "python run_direct_benchmark.py --model bert-base-uncased --hardware cpu --batch-sizes 1 --output-dir benchmark_results",
      "timestamp": "2025-03-06T17:48:16.810211",
      "success": true,
      "stdout": "\nBenchmark Summary:\nModel: bert-base-uncased\nHardware: cpu\n\nResults by Batch Size:\nBatch 1: Latency 164.53ms, Throughput 6.08 items/s, Memory 833.45MB\n",
      "stderr": "2025-03-06 17:48:19,573 - __main__ - INFO - Running direct benchmarks for bert-base-uncased on cpu\n2025-03-06 17:48:20,758 - __main__ - INFO - Loading model: bert-base-uncased\n2025-03-06 17:48:25,221 - __main__ - INFO - Benchmarks completed successfully\n",
      "benchmark_data": {
        "model": "bert-base-uncased",
        "hardware": "cpu",
        "success": true,
        "batch_results": {
          "1": {
            "success": true,
            "batch_size": 1,
            "avg_latency_ms": 164.52527046203613,
            "throughput_items_per_second": 6.078093639911371,
            "memory_mb": 833.44921875,
            "latencies_ms": [
              90.81053733825684,
              180.76801300048828,
              217.09084510803223,
              159.18827056884766,
              174.76868629455566
            ],
            "device": "cpu",
            "timestamp": "2025-03-06T17:48:25.199371"
          }
        },
        "timestamp": "2025-03-06T17:48:23.974325"
      },
      "output_file": "benchmark_results/direct_benchmark_bert-base-uncased_cpu_20250306_174825.json",
      "summary": {
        "1": {
          "latency_ms": 164.52527046203613,
          "throughput": 6.078093639911371,
          "memory_mb": 833.44921875
        }
      }
    },
    "google/t5-efficient-tiny": {
      "model": "google/t5-efficient-tiny",
      "hardware": "cpu",
      "batch_sizes": "1",
      "command": "python run_direct_benchmark.py --model google/t5-efficient-tiny --hardware cpu --batch-sizes 1 --output-dir benchmark_results",
      "timestamp": "2025-03-06T17:48:16.810792",
      "success": true,
      "stdout": "\nBenchmark Summary:\nModel: google/t5-efficient-tiny\nHardware: cpu\n\nResults by Batch Size:\nBatch 1: Latency 293.91ms, Throughput 3.40 items/s, Memory 535.17MB\n",
      "stderr": "2025-03-06 17:48:19,570 - __main__ - INFO - Running direct benchmarks for google/t5-efficient-tiny on cpu\n2025-03-06 17:48:20,670 - __main__ - INFO - Loading model: google/t5-efficient-tiny\nYou are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\nAsking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\nPassing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n2025-03-06 17:48:25,467 - __main__ - INFO - Benchmarks completed successfully\n",
      "benchmark_data": {
        "model": "google/t5-efficient-tiny",
        "hardware": "cpu",
        "success": true,
        "batch_results": {
          "1": {
            "success": true,
            "batch_size": 1,
            "avg_latency_ms": 293.91345977783203,
            "throughput_items_per_second": 3.4023620447865706,
            "memory_mb": 535.16640625,
            "latencies_ms": [
              24.453401565551758,
              1052.2279739379883,
              201.88403129577637,
              178.1289577484131,
              12.872934341430664
            ],
            "device": "cpu",
            "timestamp": "2025-03-06T17:48:25.456598"
          }
        },
        "timestamp": "2025-03-06T17:48:23.885579"
      },
      "output_file": "benchmark_results/direct_benchmark_google_t5-efficient-tiny_cpu_20250306_174825.json",
      "summary": {
        "1": {
          "latency_ms": 293.91345977783203,
          "throughput": 3.4023620447865706,
          "memory_mb": 535.16640625
        }
      }
    },
    "prajjwal1/bert-tiny": {
      "model": "prajjwal1/bert-tiny",
      "hardware": "cpu",
      "batch_sizes": "1",
      "command": "python run_direct_benchmark.py --model prajjwal1/bert-tiny --hardware cpu --batch-sizes 1 --output-dir benchmark_results",
      "timestamp": "2025-03-06T17:48:16.810173",
      "success": true,
      "stdout": "\nBenchmark Summary:\nModel: prajjwal1/bert-tiny\nHardware: cpu\n\nResults by Batch Size:\nBatch 1: Latency 21.83ms, Throughput 45.81 items/s, Memory 507.13MB\n",
      "stderr": "2025-03-06 17:48:19,717 - __main__ - INFO - Running direct benchmarks for prajjwal1/bert-tiny on cpu\n2025-03-06 17:48:20,867 - __main__ - INFO - Loading model: prajjwal1/bert-tiny\nAsking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n2025-03-06 17:48:25,409 - __main__ - INFO - Benchmarks completed successfully\n",
      "benchmark_data": {
        "model": "prajjwal1/bert-tiny",
        "hardware": "cpu",
        "success": true,
        "batch_results": {
          "1": {
            "success": true,
            "batch_size": 1,
            "avg_latency_ms": 21.828126907348633,
            "throughput_items_per_second": 45.81245125816733,
            "memory_mb": 507.12890625,
            "latencies_ms": [
              20.139455795288086,
              41.502952575683594,
              16.34836196899414,
              16.76034927368164,
              14.389514923095703
            ],
            "device": "cpu",
            "timestamp": "2025-03-06T17:48:25.402477"
          }
        },
        "timestamp": "2025-03-06T17:48:24.430152"
      },
      "output_file": "benchmark_results/direct_benchmark_prajjwal1_bert-tiny_cpu_20250306_174825.json",
      "summary": {
        "1": {
          "latency_ms": 21.828126907348633,
          "throughput": 45.81245125816733,
          "memory_mb": 507.12890625
        }
      }
    },
    "google/t5-small": {
      "model": "google/t5-small",
      "hardware": "cpu",
      "batch_sizes": "1",
      "command": "python run_direct_benchmark.py --model google/t5-small --hardware cpu --batch-sizes 1 --output-dir benchmark_results",
      "timestamp": "2025-03-06T17:48:26.597664",
      "success": false,
      "error": "Command failed with exit code 1",
      "stdout": "",
      "stderr": "2025-03-06 17:48:29,576 - __main__ - INFO - Running direct benchmarks for google/t5-small on cpu\n2025-03-06 17:48:30,520 - __main__ - INFO - Loading model: google/t5-small\n2025-03-06 17:48:33,368 - __main__ - ERROR - Error loading model google/t5-small: google/t5-small is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`\n2025-03-06 17:48:33,368 - __main__ - ERROR - Benchmarks failed: Failed to load model\n"
    },
    "google/vit-base-patch16-224": {
      "model": "google/vit-base-patch16-224",
      "hardware": "cpu",
      "batch_sizes": "1",
      "command": "python run_direct_benchmark.py --model google/vit-base-patch16-224 --hardware cpu --batch-sizes 1 --output-dir benchmark_results",
      "timestamp": "2025-03-06T17:48:26.814674",
      "success": true,
      "stdout": "\nBenchmark Summary:\nModel: google/vit-base-patch16-224\nHardware: cpu\n\nResults by Batch Size:\nBatch 1: Latency 487.27ms, Throughput 2.05 items/s, Memory 838.41MB\n",
      "stderr": "2025-03-06 17:48:29,730 - __main__ - INFO - Running direct benchmarks for google/vit-base-patch16-224 on cpu\n2025-03-06 17:48:30,831 - __main__ - INFO - Loading model: google/vit-base-patch16-224\nSome weights of ViTModel were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized: ['vit.pooler.dense.bias', 'vit.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/home/barberb/ipfs_accelerate_py/.venv/lib/python3.12/site-packages/transformers/models/vit/feature_extraction_vit.py:28: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n  warnings.warn(\nIt looks like you are trying to rescale already rescaled images. If the input images have pixel values between 0 and 1, set `do_rescale=False` to avoid rescaling them again.\n2025-03-06 17:48:38,389 - __main__ - INFO - Benchmarks completed successfully\n",
      "benchmark_data": {
        "model": "google/vit-base-patch16-224",
        "hardware": "cpu",
        "success": true,
        "batch_results": {
          "1": {
            "success": true,
            "batch_size": 1,
            "avg_latency_ms": 487.2713088989258,
            "throughput_items_per_second": 2.0522447797299495,
            "memory_mb": 838.41015625,
            "latencies_ms": [
              558.6695671081543,
              432.9493045806885,
              399.2350101470947,
              720.3285694122314,
              325.17409324645996
            ],
            "device": "cpu",
            "timestamp": "2025-03-06T17:48:38.372480"
          }
        },
        "timestamp": "2025-03-06T17:48:34.119175"
      },
      "output_file": "benchmark_results/direct_benchmark_google_vit-base-patch16-224_cpu_20250306_174838.json",
      "summary": {
        "1": {
          "latency_ms": 487.2713088989258,
          "throughput": 2.0522447797299495,
          "memory_mb": 838.41015625
        }
      }
    },
    "facebook/deit-tiny-patch16-224": {
      "model": "facebook/deit-tiny-patch16-224",
      "hardware": "cpu",
      "batch_sizes": "1",
      "command": "python run_direct_benchmark.py --model facebook/deit-tiny-patch16-224 --hardware cpu --batch-sizes 1 --output-dir benchmark_results",
      "timestamp": "2025-03-06T17:48:26.833992",
      "success": true,
      "stdout": "\nBenchmark Summary:\nModel: facebook/deit-tiny-patch16-224\nHardware: cpu\n\nResults by Batch Size:\nBatch 1: Failed - ViTModel.forward() got an unexpected keyword argument 'input_ids'\n",
      "stderr": "2025-03-06 17:48:30,097 - __main__ - INFO - Running direct benchmarks for facebook/deit-tiny-patch16-224 on cpu\n2025-03-06 17:48:30,995 - __main__ - INFO - Loading model: facebook/deit-tiny-patch16-224\n2025-03-06 17:48:30,995 - __main__ - WARNING - Unknown model type: facebook/deit-tiny-patch16-224, attempting generic loading\nSome weights of ViTModel were not initialized from the model checkpoint at facebook/deit-tiny-patch16-224 and are newly initialized: ['vit.pooler.dense.bias', 'vit.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/home/barberb/ipfs_accelerate_py/.venv/lib/python3.12/site-packages/transformers/models/vit/feature_extraction_vit.py:28: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n  warnings.warn(\n2025-03-06 17:48:37,250 - __main__ - WARNING - Unknown model type unknown, using generic input\n2025-03-06 17:48:37,255 - __main__ - ERROR - Error benchmarking batch size 1: ViTModel.forward() got an unexpected keyword argument 'input_ids'\n2025-03-06 17:48:37,269 - __main__ - INFO - Benchmarks completed successfully\n",
      "benchmark_data": {
        "model": "facebook/deit-tiny-patch16-224",
        "hardware": "cpu",
        "success": true,
        "batch_results": {
          "1": {
            "success": false,
            "error": "ViTModel.forward() got an unexpected keyword argument 'input_ids'"
          }
        },
        "timestamp": "2025-03-06T17:48:37.242096"
      },
      "output_file": "benchmark_results/direct_benchmark_facebook_deit-tiny-patch16-224_cpu_20250306_174837.json",
      "summary": {}
    }
  }
}