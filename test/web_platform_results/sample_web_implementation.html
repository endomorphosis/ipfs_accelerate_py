<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>IPFS Accelerate - Web Platform Demo</title>
    <style>
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Open Sans', 'Helvetica Neue', sans-serif;
            line-height: 1.6;
            color: #333;
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
        }
        h1, h2 {
            color: #1a73e8;
        }
        .container {
            display: flex;
            gap: 20px;
            margin-top: 20px;
        }
        .implementation {
            flex: 1;
            border: 1px solid #ddd;
            border-radius: 8px;
            padding: 20px;
            background-color: #f9f9f9;
        }
        .input-area {
            margin-bottom: 20px;
        }
        textarea {
            width: 100%;
            padding: 10px;
            border: 1px solid #ccc;
            border-radius: 4px;
            font-family: inherit;
            resize: vertical;
        }
        button {
            background-color: #1a73e8;
            color: white;
            border: none;
            padding: 10px 20px;
            border-radius: 4px;
            cursor: pointer;
            font-weight: bold;
        }
        button:hover {
            background-color: #0d47a1;
        }
        .results {
            margin-top: 20px;
            padding: 10px;
            border: 1px solid #ccc;
            border-radius: 4px;
            background-color: white;
            min-height: 100px;
        }
        pre {
            white-space: pre-wrap;
            word-wrap: break-word;
        }
        .status {
            margin-top: 10px;
            font-style: italic;
            color: #666;
        }
        .loader {
            border: 4px solid #f3f3f3;
            border-top: 4px solid #1a73e8;
            border-radius: 50%;
            width: 20px;
            height: 20px;
            animation: spin 2s linear infinite;
            display: inline-block;
            margin-left: 10px;
            vertical-align: middle;
        }
        @keyframes spin {
            0% { transform: rotate(0deg); }
            100% { transform: rotate(360deg); }
        }
        .hidden {
            display: none;
        }
        .perf-info {
            font-size: 0.9em;
            color: #666;
            margin-top: 5px;
        }
    </style>
</head>
<body>
    <h1>IPFS Accelerate - Web Platform Demo</h1>
    <p>This demo showcases two different browser-based ML implementations: WebNN and WebGPU (transformers.js)</p>
    
    <div class="container">
        <!-- WebNN Implementation -->
        <div class="implementation">
            <h2>WebNN Implementation</h2>
            <p>Using WebNN API with ONNX Runtime</p>
            
            <div class="input-area">
                <textarea id="webnn-input" rows="4" placeholder="Enter text to classify...">This movie is great! I really enjoyed watching it.</textarea>
                <div>
                    <button id="webnn-run">Run Classification</button>
                    <span id="webnn-loader" class="loader hidden"></span>
                </div>
                <div id="webnn-status" class="status">Model not loaded</div>
            </div>
            
            <div class="results">
                <h3>Results:</h3>
                <pre id="webnn-output">Classification results will appear here</pre>
                <div id="webnn-perf" class="perf-info"></div>
            </div>
        </div>
        
        <!-- WebGPU Implementation -->
        <div class="implementation">
            <h2>WebGPU Implementation</h2>
            <p>Using transformers.js with WebGPU acceleration</p>
            
            <div class="input-area">
                <textarea id="webgpu-input" rows="4" placeholder="Enter text to classify...">This movie is great! I really enjoyed watching it.</textarea>
                <div>
                    <button id="webgpu-run">Run Classification</button>
                    <span id="webgpu-loader" class="loader hidden"></span>
                </div>
                <div id="webgpu-status" class="status">Model not loaded</div>
            </div>
            
            <div class="results">
                <h3>Results:</h3>
                <pre id="webgpu-output">Classification results will appear here</pre>
                <div id="webgpu-perf" class="perf-info"></div>
            </div>
        </div>
    </div>

    <!-- Performance Comparison -->
    <div id="comparison" style="margin-top: 40px;">
        <h2>Performance Comparison</h2>
        <p>Run multiple tests to compare performance between implementations</p>
        
        <div style="margin-bottom: 20px;">
            <button id="run-comparison">Run Benchmark (10 iterations)</button>
            <span id="comparison-loader" class="loader hidden"></span>
        </div>
        
        <div class="results">
            <h3>Benchmark Results:</h3>
            <pre id="comparison-output">Benchmark results will appear here</pre>
        </div>
    </div>

    <!-- Load Required Libraries -->
    <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web@1.14.0/dist/ort.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@xenova/transformers@2.6.0"></script>

    <script>
        // Configure environment
        const { pipeline, env } = window.transformers;
        env.useBrowserCache = true;
        env.useWebGPU = true;
        
        // Global variables
        let webnnModel = null;
        let webgpuClassifier = null;
        let webnnVocab = null;
        
        // WebNN Implementation
        async function loadWebNNModel() {
            try {
                document.getElementById('webnn-status').textContent = "Loading model...";
                document.getElementById('webnn-loader').classList.remove('hidden');
                
                // For demo purposes, we're using onnxruntime-web instead of actual WebNN
                // In a real implementation, you would use the WebNN API if available
                const session = await ort.InferenceSession.create('/models/bert-base-uncased-sentiment.onnx', {
                    executionProviders: ['wasm'],
                    graphOptimizationLevel: 'all'
                });
                
                // Load tokenizer vocabulary
                const vocab = await fetch('/models/bert-vocabulary.json')
                    .then(response => response.json());
                
                webnnModel = session;
                webnnVocab = vocab;
                
                document.getElementById('webnn-status').textContent = "Model loaded successfully";
                document.getElementById('webnn-loader').classList.add('hidden');
                
                return { model: session, vocab: vocab };
            } catch (error) {
                console.error("Error loading WebNN model:", error);
                document.getElementById('webnn-status').textContent = `Error loading model: ${error.message}`;
                document.getElementById('webnn-loader').classList.add('hidden');
                throw error;
            }
        }
        
        // Tokenize input text for WebNN
        function tokenizeForWebNN(text, vocab, maxLength = 128) {
            // Basic tokenization (simplified for demo)
            const tokens = ['[CLS]', ...text.toLowerCase().split(/\s+/), '[SEP]'];
            
            // Convert tokens to ids using vocabulary
            const tokenIds = tokens.map(token => vocab[token] || vocab['[UNK]']);
            
            // Truncate or pad to maxLength
            const paddedIds = tokenIds.slice(0, maxLength);
            while (paddedIds.length < maxLength) {
                paddedIds.push(0); // Padding token
            }
            
            // Create attention mask (1 for real tokens, 0 for padding)
            const attentionMask = paddedIds.map(id => id > 0 ? 1 : 0);
            
            // Create token type ids (all 0 for single sentence)
            const tokenTypeIds = new Array(maxLength).fill(0);
            
            return {
                input_ids: paddedIds,
                attention_mask: attentionMask,
                token_type_ids: tokenTypeIds
            };
        }
        
        // Run inference with WebNN
        async function runWebNNInference(text) {
            try {
                if (!webnnModel) {
                    await loadWebNNModel();
                }
                
                const startTime = performance.now();
                
                // Tokenize input
                const tokenized = tokenizeForWebNN(text, webnnVocab);
                
                // Prepare inputs
                const feeds = {
                    'input_ids': new ort.Tensor('int64', new BigInt64Array(tokenized.input_ids.map(x => BigInt(x))), [1, tokenized.input_ids.length]),
                    'attention_mask': new ort.Tensor('int64', new BigInt64Array(tokenized.attention_mask.map(x => BigInt(x))), [1, tokenized.attention_mask.length]),
                    'token_type_ids': new ort.Tensor('int64', new BigInt64Array(tokenized.token_type_ids.map(x => BigInt(x))), [1, tokenized.token_type_ids.length])
                };
                
                // Run inference
                const results = await webnnModel.run(feeds);
                
                // Process results - get logits and convert to probabilities
                const logits = results.logits.data;
                const probabilities = softmax(Array.from(logits));
                
                const endTime = performance.now();
                const inferenceTime = endTime - startTime;
                
                // Map to sentiment labels (example for 5-class sentiment)
                const labels = ['1 star', '2 stars', '3 stars', '4 stars', '5 stars'];
                const sentiments = labels.map((label, i) => ({
                    label: label,
                    score: probabilities[i]
                })).sort((a, b) => b.score - a.score);
                
                return { 
                    results: sentiments,
                    performance: {
                        time_ms: inferenceTime
                    }
                };
            } catch (error) {
                console.error("WebNN inference error:", error);
                throw error;
            }
        }
        
        // Helper function to compute softmax
        function softmax(arr) {
            const max = Math.max(...arr);
            const exps = arr.map(x => Math.exp(x - max));
            const sumExps = exps.reduce((acc, val) => acc + val, 0);
            return exps.map(x => x / sumExps);
        }
        
        // WebGPU/transformers.js Implementation
        async function loadWebGPUModel() {
            try {
                document.getElementById('webgpu-status').textContent = "Loading model...";
                document.getElementById('webgpu-loader').classList.remove('hidden');
                
                // Create a sentiment analysis pipeline with transformers.js
                const classifier = await pipeline('sentiment-analysis', 'Xenova/bert-base-uncased-sentiment');
                
                webgpuClassifier = classifier;
                
                document.getElementById('webgpu-status').textContent = "Model loaded successfully";
                document.getElementById('webgpu-loader').classList.add('hidden');
                
                return classifier;
            } catch (error) {
                console.error("Error loading WebGPU model:", error);
                document.getElementById('webgpu-status').textContent = `Error loading model: ${error.message}`;
                document.getElementById('webgpu-loader').classList.add('hidden');
                throw error;
            }
        }
        
        // Run inference with WebGPU/transformers.js
        async function runWebGPUInference(text) {
            try {
                if (!webgpuClassifier) {
                    await loadWebGPUModel();
                }
                
                const startTime = performance.now();
                
                // Run classification
                const result = await webgpuClassifier(text);
                
                const endTime = performance.now();
                const inferenceTime = endTime - startTime;
                
                return { 
                    results: result,
                    performance: {
                        time_ms: inferenceTime,
                        backend: env.backends?.onnx?.wasm?.numThreads ? 'WASM' : 'WebGPU'
                    }
                };
            } catch (error) {
                console.error("WebGPU inference error:", error);
                throw error;
            }
        }
        
        // Run comparative benchmark
        async function runBenchmark(iterations = 10) {
            try {
                document.getElementById('comparison-loader').classList.remove('hidden');
                document.getElementById('comparison-output').textContent = "Running benchmark...";
                
                // Make sure models are loaded
                if (!webnnModel) await loadWebNNModel();
                if (!webgpuClassifier) await loadWebGPUModel();
                
                const testTexts = [
                    "This movie was amazing, I loved every minute of it!",
                    "The acting was terrible and the plot made no sense.",
                    "It was okay, nothing special but entertaining enough.",
                    "What a waste of time, one of the worst movies I've seen.",
                    "The cinematography was beautiful but the story was lacking."
                ];
                
                // Results storage
                const webnnTimes = [];
                const webgpuTimes = [];
                
                // Run tests
                for (let i = 0; i < iterations; i++) {
                    const textIndex = i % testTexts.length;
                    const text = testTexts[textIndex];
                    
                    // WebNN inference
                    const webnnResult = await runWebNNInference(text);
                    webnnTimes.push(webnnResult.performance.time_ms);
                    
                    // WebGPU inference
                    const webgpuResult = await runWebGPUInference(text);
                    webgpuTimes.push(webgpuResult.performance.time_ms);
                    
                    // Update progress
                    document.getElementById('comparison-output').textContent = 
                        `Running benchmark... ${i+1}/${iterations} complete`;
                }
                
                // Calculate statistics
                const webnnAvg = average(webnnTimes);
                const webgpuAvg = average(webgpuTimes);
                const speedup = webnnAvg / webgpuAvg;
                
                // Format results
                const results = {
                    iterations: iterations,
                    webnn: {
                        avg_time_ms: webnnAvg.toFixed(2),
                        min_time_ms: Math.min(...webnnTimes).toFixed(2),
                        max_time_ms: Math.max(...webnnTimes).toFixed(2)
                    },
                    webgpu: {
                        avg_time_ms: webgpuAvg.toFixed(2),
                        min_time_ms: Math.min(...webgpuTimes).toFixed(2),
                        max_time_ms: Math.max(...webgpuTimes).toFixed(2),
                        backend: env.backends?.onnx?.wasm?.numThreads ? 'WASM' : 'WebGPU'
                    },
                    comparison: {
                        speedup: speedup.toFixed(2),
                        faster_implementation: speedup > 1 ? "WebGPU" : "WebNN"
                    }
                };
                
                // Display results
                document.getElementById('comparison-output').textContent = 
                    JSON.stringify(results, null, 2);
                document.getElementById('comparison-loader').classList.add('hidden');
                
                return results;
            } catch (error) {
                console.error("Benchmark error:", error);
                document.getElementById('comparison-output').textContent = 
                    `Error running benchmark: ${error.message}`;
                document.getElementById('comparison-loader').classList.add('hidden');
                throw error;
            }
        }
        
        // Helper function to calculate average
        function average(arr) {
            return arr.reduce((sum, val) => sum + val, 0) / arr.length;
        }
        
        // Initialize the application
        async function init() {
            try {
                // Start loading models in the background
                loadWebNNModel();
                loadWebGPUModel();
                
                // Set up WebNN run button
                document.getElementById('webnn-run').addEventListener('click', async () => {
                    try {
                        const text = document.getElementById('webnn-input').value;
                        if (!text) {
                            alert("Please enter some text");
                            return;
                        }
                        
                        document.getElementById('webnn-output').textContent = "Running classification...";
                        document.getElementById('webnn-loader').classList.remove('hidden');
                        
                        const result = await runWebNNInference(text);
                        
                        document.getElementById('webnn-output').textContent = 
                            JSON.stringify(result.results, null, 2);
                        document.getElementById('webnn-perf').textContent = 
                            `Inference time: ${result.performance.time_ms.toFixed(2)}ms`;
                        document.getElementById('webnn-loader').classList.add('hidden');
                    } catch (error) {
                        document.getElementById('webnn-output').textContent = 
                            `Error: ${error.message}`;
                        document.getElementById('webnn-loader').classList.add('hidden');
                    }
                });
                
                // Set up WebGPU run button
                document.getElementById('webgpu-run').addEventListener('click', async () => {
                    try {
                        const text = document.getElementById('webgpu-input').value;
                        if (!text) {
                            alert("Please enter some text");
                            return;
                        }
                        
                        document.getElementById('webgpu-output').textContent = "Running classification...";
                        document.getElementById('webgpu-loader').classList.remove('hidden');
                        
                        const result = await runWebGPUInference(text);
                        
                        document.getElementById('webgpu-output').textContent = 
                            JSON.stringify(result.results, null, 2);
                        document.getElementById('webgpu-perf').textContent = 
                            `Inference time: ${result.performance.time_ms.toFixed(2)}ms | Backend: ${result.performance.backend}`;
                        document.getElementById('webgpu-loader').classList.add('hidden');
                    } catch (error) {
                        document.getElementById('webgpu-output').textContent = 
                            `Error: ${error.message}`;
                        document.getElementById('webgpu-loader').classList.add('hidden');
                    }
                });
                
                // Set up benchmark button
                document.getElementById('run-comparison').addEventListener('click', async () => {
                    await runBenchmark(10);
                });
                
            } catch (error) {
                console.error("Initialization error:", error);
            }
        }
        
        // Start the application when the page loads
        window.addEventListener('DOMContentLoaded', init);
    </script>
</body>
</html>