#!/usr/bin/env python3
"""
Implementation Generator

This module provides tools for generating model implementations based on test results
and implementation requirements. It uses the requirements generated by the 
TestResultCollector to create model implementations using Jinja2 templates.

The SkillsetImplementationGenerator class:
1. Loads implementation requirements from JSON files
2. Selects the appropriate template based on model type and capabilities
3. Generates implementation code with proper initialization, methods, and hardware support
4. Validates and formats the generated code

Usage:
  # Generate an implementation from requirements file
  generator = SkillsetImplementationGenerator()
  result = generator.generate_for_model('bert_requirements_20250302_123456.json')
  
  # Use with a specific template
  generator.generate_for_model('bert_requirements.json', template_name='text_model.py.jinja2')
  
  # Generate with custom template directory
  generator = SkillsetImplementationGenerator(template_dir='/path/to/templates')
  result = generator.generate_for_model('bert_requirements.json')
"""

import os
import sys
import json
import time
import ast
import logging
import traceback
from datetime import datetime
from typing import Dict, List, Any, Optional, Union, Tuple, Set

# Import hardware detection capabilities if available
try:
    from hardware_detection import (
        HAS_CUDA, HAS_ROCM, HAS_OPENVINO, HAS_MPS, HAS_WEBNN, HAS_WEBGPU,
        detect_all_hardware
    )
    HAS_HARDWARE_DETECTION = True
except ImportError:
    HAS_HARDWARE_DETECTION = False
    # We'll detect hardware manually if needed
    import importlib.util

try:
    import jinja2
    JINJA2_AVAILABLE = True
except ImportError:
    JINJA2_AVAILABLE = False
    print("Warning: jinja2 not available, template rendering will not work")

try:
    import autopep8
    AUTOPEP8_AVAILABLE = True
except ImportError:
    AUTOPEP8_AVAILABLE = False
    print("Warning: autopep8 not available, code formatting will be disabled")

# Setup logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# Constants
CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))
PROJECT_DIR = os.path.dirname(CURRENT_DIR)
REQUIREMENTS_DIR = os.path.join(CURRENT_DIR, "implementation_requirements")
TEMPLATES_DIR = os.path.join(CURRENT_DIR, "templates")
OUTPUT_DIR = os.path.join(CURRENT_DIR, "generated_implementations")

# Ensure directories exist
for directory in [REQUIREMENTS_DIR, TEMPLATES_DIR, OUTPUT_DIR]:
    os.makedirs(directory, exist_ok=True)

# Create basic template if templates directory is empty
if not os.listdir(TEMPLATES_DIR):
    # Write a basic template for text models
    TEXT_MODEL_TEMPLATE = """
# Template for {{ model_name }} implementation
# Generated: {{ generated_timestamp }}

class {{ class_name }}:
    """{{ model_name }} implementation.
    
    This class provides standardized interfaces for working with {{ model_name }} models
    across different hardware backends (CPU, CUDA, OpenVINO, MPS, etc.).
    """
    
    def __init__(self, resources=None, metadata=None):
        """Initialize the {{ model_name }} model.
        
        Args:
            resources (dict): Dictionary of shared resources (torch, transformers, etc.)
            metadata (dict): Configuration metadata
        """
        self.resources = resources if resources else {}
        self.metadata = metadata if metadata else {}
        
        # Import required libraries
        {% for import_name in initialization.required_imports %}
        if "{{ import_name }}" not in self.resources:
            try:
                import {{ import_name }}
                self.{{ import_name }} = {{ import_name }}
            except ImportError:
                self.{{ import_name }} = None
                print(f"Warning: {{ import_name }} not available")
        else:
            self.{{ import_name }} = self.resources["{{ import_name }}"]
        {% endfor %}
        
        # Initialize model
        self.model = None
        self.processor = None
        
        # Handler creation methods
        {% for method in methods.keys() %}
        self.create_cpu_{{ method }}_endpoint_handler = self.create_cpu_{{ method }}_endpoint_handler
        self.create_cuda_{{ method }}_endpoint_handler = self.create_cuda_{{ method }}_endpoint_handler
        self.create_openvino_{{ method }}_endpoint_handler = self.create_openvino_{{ method }}_endpoint_handler
        {% endfor %}
        
        # Initialization methods
        self.init = self.init
        self.init_cpu = self.init_cpu
        self.init_cuda = self.init_cuda
        self.init_openvino = self.init_openvino
        
        return None
        
    def init(self):
        """Initialize resources and dependencies."""
        # Implement initialization code
        return None
        
    def init_cpu(self, model_name=None, model_type="{{ model_name }}", **kwargs):
        """Initialize model for CPU inference."""
        # Implement CPU initialization
        pass
        
    def init_cuda(self, model_name=None, model_type="{{ model_name }}", **kwargs):
        """Initialize model for CUDA inference."""
        # Implement CUDA initialization
        pass
        
    def init_openvino(self, model_name=None, model_type="{{ model_name }}", **kwargs):
        """Initialize model for OpenVINO inference."""
        # Implement OpenVINO initialization
        pass
        
    {% for method_name, method_info in methods.items() %}
    def {{ method_name }}(self{% for param in method_info.required_parameters %}, {{ param }}{% endfor %}{% for param in method_info.optional_parameters %}, {{ param }}=None{% endfor %}):
        """{{ method_name.replace('_', ' ').title() }} implementation."""
        # Implement {{ method_name }} method
        pass
    
    def create_cpu_{{ method_name }}_endpoint_handler(self, endpoint_model, device, hardware_label, endpoint=None, processor=None):
        """Create handler for CPU-based {{ method_name }}."""
        # Implement CPU handler creation
        pass
        
    def create_cuda_{{ method_name }}_endpoint_handler(self, endpoint_model, device, hardware_label, endpoint=None, processor=None):
        """Create handler for CUDA-based {{ method_name }}."""
        # Implement CUDA handler creation
        pass
        
    def create_openvino_{{ method_name }}_endpoint_handler(self, endpoint_model, openvino_label, endpoint=None, processor=None):
        """Create handler for OpenVINO-based {{ method_name }}."""
        # Implement OpenVINO handler creation
        pass
    {% endfor %}
"""
    
    with open(os.path.join(TEMPLATES_DIR, "text_model.py.jinja2"), "w") as f:
        f.write(TEXT_MODEL_TEMPLATE)
    
    # Write a basic template for vision models
    VISION_MODEL_TEMPLATE = """
# Template for {{ model_name }} vision model implementation
# Generated: {{ generated_timestamp }}

class {{ class_name }}:
    """{{ model_name }} vision model implementation.
    
    This class provides standardized interfaces for working with {{ model_name }} vision models
    across different hardware backends (CPU, CUDA, OpenVINO, MPS, etc.).
    """
    
    def __init__(self, resources=None, metadata=None):
        """Initialize the {{ model_name }} model.
        
        Args:
            resources (dict): Dictionary of shared resources (torch, transformers, PIL, etc.)
            metadata (dict): Configuration metadata
        """
        self.resources = resources if resources else {}
        self.metadata = metadata if metadata else {}
        
        # Import required libraries
        {% for import_name in initialization.required_imports %}
        if "{{ import_name }}" not in self.resources:
            try:
                import {{ import_name }}
                self.{{ import_name }} = {{ import_name }}
            except ImportError:
                self.{{ import_name }} = None
                print(f"Warning: {{ import_name }} not available")
        else:
            self.{{ import_name }} = self.resources["{{ import_name }}"]
        {% endfor %}
        
        # Import PIL for image processing
        if "PIL" not in self.resources and "Image" not in self.resources:
            try:
                from PIL import Image
                self.Image = Image
            except ImportError:
                self.Image = None
                print("Warning: PIL not available")
        elif "PIL" in self.resources:
            self.Image = self.resources["PIL"].Image
        else:
            self.Image = self.resources["Image"]
        
        # Initialize model
        self.model = None
        self.processor = None
        
        # Handler creation methods
        {% for method in methods.keys() %}
        self.create_cpu_{{ method }}_endpoint_handler = self.create_cpu_{{ method }}_endpoint_handler
        self.create_cuda_{{ method }}_endpoint_handler = self.create_cuda_{{ method }}_endpoint_handler
        self.create_openvino_{{ method }}_endpoint_handler = self.create_openvino_{{ method }}_endpoint_handler
        {% endfor %}
        
        # Initialization methods
        self.init = self.init
        self.init_cpu = self.init_cpu
        self.init_cuda = self.init_cuda
        self.init_openvino = self.init_openvino
        
        return None
        
    def init(self):
        """Initialize resources and dependencies."""
        # Implement initialization code
        return None
        
    def init_cpu(self, model_name=None, model_type="{{ model_name }}", **kwargs):
        """Initialize model for CPU inference."""
        # Implement CPU initialization
        pass
        
    def init_cuda(self, model_name=None, model_type="{{ model_name }}", **kwargs):
        """Initialize model for CUDA inference."""
        # Implement CUDA initialization
        pass
        
    def init_openvino(self, model_name=None, model_type="{{ model_name }}", **kwargs):
        """Initialize model for OpenVINO inference."""
        # Implement OpenVINO initialization
        pass
        
    {% for method_name, method_info in methods.items() %}
    def {{ method_name }}(self{% for param in method_info.required_parameters %}, {{ param }}{% endfor %}{% for param in method_info.optional_parameters %}, {{ param }}=None{% endfor %}):
        """{{ method_name.replace('_', ' ').title() }} implementation."""
        # Implement {{ method_name }} method
        pass
    
    def create_cpu_{{ method_name }}_endpoint_handler(self, endpoint_model, device, hardware_label, endpoint=None, processor=None):
        """Create handler for CPU-based {{ method_name }}."""
        # Implement CPU handler creation
        pass
        
    def create_cuda_{{ method_name }}_endpoint_handler(self, endpoint_model, device, hardware_label, endpoint=None, processor=None):
        """Create handler for CUDA-based {{ method_name }}."""
        # Implement CUDA handler creation
        pass
        
    def create_openvino_{{ method_name }}_endpoint_handler(self, endpoint_model, openvino_label, endpoint=None, processor=None):
        """Create handler for OpenVINO-based {{ method_name }}."""
        # Implement OpenVINO handler creation
        pass
    {% endfor %}
"""
    
    with open(os.path.join(TEMPLATES_DIR, "vision_model.py.jinja2"), "w") as f:
        f.write(VISION_MODEL_TEMPLATE)
        
    # Write a basic template for audio models
    AUDIO_MODEL_TEMPLATE = """
# Template for {{ model_name }} audio model implementation
# Generated: {{ generated_timestamp }}

class {{ class_name }}:
    """{{ model_name }} audio model implementation.
    
    This class provides standardized interfaces for working with {{ model_name }} audio models
    across different hardware backends (CPU, CUDA, OpenVINO, MPS, etc.).
    """
    
    def __init__(self, resources=None, metadata=None):
        """Initialize the {{ model_name }} model.
        
        Args:
            resources (dict): Dictionary of shared resources (torch, transformers, librosa, etc.)
            metadata (dict): Configuration metadata
        """
        self.resources = resources if resources else {}
        self.metadata = metadata if metadata else {}
        
        # Import required libraries
        {% for import_name in initialization.required_imports %}
        if "{{ import_name }}" not in self.resources:
            try:
                import {{ import_name }}
                self.{{ import_name }} = {{ import_name }}
            except ImportError:
                self.{{ import_name }} = None
                print(f"Warning: {{ import_name }} not available")
        else:
            self.{{ import_name }} = self.resources["{{ import_name }}"]
        {% endfor %}
        
        # Import librosa for audio processing if needed
        if "librosa" not in self.resources:
            try:
                import librosa
                self.librosa = librosa
            except ImportError:
                self.librosa = None
                print("Warning: librosa not available")
        else:
            self.librosa = self.resources["librosa"]
        
        # Initialize model
        self.model = None
        self.processor = None
        
        # Handler creation methods
        {% for method in methods.keys() %}
        self.create_cpu_{{ method }}_endpoint_handler = self.create_cpu_{{ method }}_endpoint_handler
        self.create_cuda_{{ method }}_endpoint_handler = self.create_cuda_{{ method }}_endpoint_handler
        self.create_openvino_{{ method }}_endpoint_handler = self.create_openvino_{{ method }}_endpoint_handler
        {% endfor %}
        
        # Initialization methods
        self.init = self.init
        self.init_cpu = self.init_cpu
        self.init_cuda = self.init_cuda
        self.init_openvino = self.init_openvino
        
        return None
        
    def init(self):
        """Initialize resources and dependencies."""
        # Implement initialization code
        return None
        
    def init_cpu(self, model_name=None, model_type="{{ model_name }}", **kwargs):
        """Initialize model for CPU inference."""
        # Implement CPU initialization
        pass
        
    def init_cuda(self, model_name=None, model_type="{{ model_name }}", **kwargs):
        """Initialize model for CUDA inference."""
        # Implement CUDA initialization
        pass
        
    def init_openvino(self, model_name=None, model_type="{{ model_name }}", **kwargs):
        """Initialize model for OpenVINO inference."""
        # Implement OpenVINO initialization
        pass
        
    {% for method_name, method_info in methods.items() %}
    def {{ method_name }}(self{% for param in method_info.required_parameters %}, {{ param }}{% endfor %}{% for param in method_info.optional_parameters %}, {{ param }}=None{% endfor %}):
        """{{ method_name.replace('_', ' ').title() }} implementation."""
        # Implement {{ method_name }} method
        pass
    
    def create_cpu_{{ method_name }}_endpoint_handler(self, endpoint_model, device, hardware_label, endpoint=None, processor=None):
        """Create handler for CPU-based {{ method_name }}."""
        # Implement CPU handler creation
        pass
        
    def create_cuda_{{ method_name }}_endpoint_handler(self, endpoint_model, device, hardware_label, endpoint=None, processor=None):
        """Create handler for CUDA-based {{ method_name }}."""
        # Implement CUDA handler creation
        pass
        
    def create_openvino_{{ method_name }}_endpoint_handler(self, endpoint_model, openvino_label, endpoint=None, processor=None):
        """Create handler for OpenVINO-based {{ method_name }}."""
        # Implement OpenVINO handler creation
        pass
    {% endfor %}
"""
    
    with open(os.path.join(TEMPLATES_DIR, "audio_model.py.jinja2"), "w") as f:
        f.write(AUDIO_MODEL_TEMPLATE)
        
    # Write a basic template for multimodal models
    MULTIMODAL_MODEL_TEMPLATE = """
# Template for {{ model_name }} multimodal model implementation
# Generated: {{ generated_timestamp }}

class {{ class_name }}:
    """{{ model_name }} multimodal model implementation.
    
    This class provides standardized interfaces for working with {{ model_name }} multimodal models
    across different hardware backends (CPU, CUDA, OpenVINO, MPS, etc.).
    """
    
    def __init__(self, resources=None, metadata=None):
        """Initialize the {{ model_name }} model.
        
        Args:
            resources (dict): Dictionary of shared resources (torch, transformers, PIL, etc.)
            metadata (dict): Configuration metadata
        """
        self.resources = resources if resources else {}
        self.metadata = metadata if metadata else {}
        
        # Import required libraries
        {% for import_name in initialization.required_imports %}
        if "{{ import_name }}" not in self.resources:
            try:
                import {{ import_name }}
                self.{{ import_name }} = {{ import_name }}
            except ImportError:
                self.{{ import_name }} = None
                print(f"Warning: {{ import_name }} not available")
        else:
            self.{{ import_name }} = self.resources["{{ import_name }}"]
        {% endfor %}
        
        # Import PIL for image processing
        if "PIL" not in self.resources and "Image" not in self.resources:
            try:
                from PIL import Image
                self.Image = Image
            except ImportError:
                self.Image = None
                print("Warning: PIL not available")
        elif "PIL" in self.resources:
            self.Image = self.resources["PIL"].Image
        else:
            self.Image = self.resources["Image"]
        
        # Initialize model
        self.model = None
        self.processor = None
        
        # Handler creation methods
        {% for method in methods.keys() %}
        self.create_cpu_{{ method }}_endpoint_handler = self.create_cpu_{{ method }}_endpoint_handler
        self.create_cuda_{{ method }}_endpoint_handler = self.create_cuda_{{ method }}_endpoint_handler
        self.create_openvino_{{ method }}_endpoint_handler = self.create_openvino_{{ method }}_endpoint_handler
        {% endfor %}
        
        # Initialization methods
        self.init = self.init
        self.init_cpu = self.init_cpu
        self.init_cuda = self.init_cuda
        self.init_openvino = self.init_openvino
        
        return None
        
    def init(self):
        """Initialize resources and dependencies."""
        # Implement initialization code
        return None
        
    def init_cpu(self, model_name=None, model_type="{{ model_name }}", **kwargs):
        """Initialize model for CPU inference."""
        # Implement CPU initialization
        pass
        
    def init_cuda(self, model_name=None, model_type="{{ model_name }}", **kwargs):
        """Initialize model for CUDA inference."""
        # Implement CUDA initialization
        pass
        
    def init_openvino(self, model_name=None, model_type="{{ model_name }}", **kwargs):
        """Initialize model for OpenVINO inference."""
        # Implement OpenVINO initialization
        pass
        
    {% for method_name, method_info in methods.items() %}
    def {{ method_name }}(self{% for param in method_info.required_parameters %}, {{ param }}{% endfor %}{% for param in method_info.optional_parameters %}, {{ param }}=None{% endfor %}):
        """{{ method_name.replace('_', ' ').title() }} implementation."""
        # Implement {{ method_name }} method
        pass
    
    def create_cpu_{{ method_name }}_endpoint_handler(self, endpoint_model, device, hardware_label, endpoint=None, processor=None):
        """Create handler for CPU-based {{ method_name }}."""
        # Implement CPU handler creation
        pass
        
    def create_cuda_{{ method_name }}_endpoint_handler(self, endpoint_model, device, hardware_label, endpoint=None, processor=None):
        """Create handler for CUDA-based {{ method_name }}."""
        # Implement CUDA handler creation
        pass
        
    def create_openvino_{{ method_name }}_endpoint_handler(self, endpoint_model, openvino_label, endpoint=None, processor=None):
        """Create handler for OpenVINO-based {{ method_name }}."""
        # Implement OpenVINO handler creation
        pass
    {% endfor %}
"""
    
    with open(os.path.join(TEMPLATES_DIR, "multimodal_model.py.jinja2"), "w") as f:
        f.write(MULTIMODAL_MODEL_TEMPLATE)

class SkillsetImplementationGenerator:
    """
    Generate implementations based on test results and requirements.
    Uses templates from templates directory to create model skillset implementations.
    """
    
    def __init__(self, template_dir=None, output_dir=None):
        """
        Initialize the implementation generator.
        
        Args:
            template_dir: Directory containing templates. Defaults to "templates" in current dir.
            output_dir: Directory to save generated implementations. Defaults to "generated_implementations".
        """
        if not JINJA2_AVAILABLE:
            raise ImportError("Jinja2 is required for template rendering. Please install it with 'pip install jinja2'.")
            
        self.template_dir = template_dir or TEMPLATES_DIR
        self.output_dir = output_dir or OUTPUT_DIR
        
        # Ensure directories exist
        os.makedirs(self.template_dir, exist_ok=True)
        os.makedirs(self.output_dir, exist_ok=True)
        
        # Set up Jinja2 environment
        self.template_env = jinja2.Environment(
            loader=jinja2.FileSystemLoader(self.template_dir),
            trim_blocks=True,
            lstrip_blocks=True
        )
        
        # Register custom filters
        self.template_env.filters['title_case'] = lambda x: x.replace('_', ' ').title()
        self.template_env.filters['to_valid_python'] = self._convert_to_valid_python
        
        logger.info(f"Implementation generator initialized with templates from {self.template_dir}")
    
    def _convert_to_valid_python(self, name):
        """Convert a name to a valid Python identifier by replacing hyphens with underscores."""
        return name.replace('-', '_')
    
    def load_requirements(self, requirements_path):
        """
        Load implementation requirements from a JSON file.
        
        Args:
            requirements_path: Path to the requirements JSON file
            
        Returns:
            Dict with implementation requirements
        """
        try:
            with open(requirements_path, 'r') as f:
                requirements = json.load(f)
                
            # Convert hyphenated task names to use underscores to ensure valid Python syntax
            if "methods" in requirements:
                methods = {}
                for method_name, method_info in requirements["methods"].items():
                    valid_method_name = method_name.replace('-', '_')
                    methods[valid_method_name] = method_info
                requirements["methods"] = methods
                
            # Also sanitize primary task if present
            if "primary_task" in requirements:
                requirements["primary_task"] = requirements["primary_task"].replace('-', '_')
                
            return requirements
        except Exception as e:
            logger.error(f"Error loading requirements from {requirements_path}: {e}")
            raise
    
    def select_template(self, requirements):
        """
        Select an appropriate template based on the model requirements.
        
        Args:
            requirements: Dict with implementation requirements
            
        Returns:
            Name of the selected template file
        """
        # Check if the requirements have a specific template name
        if "template" in requirements.get("metadata", {}):
            template_name = requirements["metadata"]["template"]
            if os.path.exists(os.path.join(self.template_dir, template_name)):
                return template_name
        
        # Try to determine model type from methods or initialization
        methods = requirements.get("methods", {})
        init = requirements.get("initialization", {})
        
        # Check for vision-specific methods or imports
        if any(m in methods for m in ["image_classification", "object_detection", "image_segmentation", 
                                     "feature_extraction_vision", "process_image"]):
            return "vision_model.py.jinja2"
            
        # Check for audio-specific methods or imports
        if any(m in methods for m in ["speech_recognition", "audio_classification", 
                                     "speech_to_text", "process_audio"]):
            return "audio_model.py.jinja2"
            
        # Check for multimodal methods
        if any(m in methods for m in ["image_to_text", "text_to_image", "visual_question_answering",
                                     "process_multimodal"]):
            return "multimodal_model.py.jinja2"
            
        # Check for imports
        imports = init.get("required_imports", [])
        if "PIL" in imports or "Image" in imports:
            if "librosa" in imports or "soundfile" in imports:
                return "multimodal_model.py.jinja2"
            return "vision_model.py.jinja2"
            
        if "librosa" in imports or "soundfile" in imports:
            return "audio_model.py.jinja2"
        
        # Default to text model template
        return "text_model.py.jinja2"
    
    def generate_implementation(self, requirements, template_name=None):
        """
        Generate a skillset implementation based on requirements.
        
        Args:
            requirements: Dict with implementation requirements
            template_name: Optional template name to use. If None, will be auto-selected.
            
        Returns:
            Generated implementation code as a string
        """
        # Select template if not provided
        if template_name is None:
            template_name = self.select_template(requirements)
        
        try:
            # Load the template
            template = self.template_env.get_template(template_name)
            
            # Make sure primary task and all method names use valid Python syntax (no hyphens)
            if "primary_task" in requirements:
                requirements["primary_task"] = requirements["primary_task"].replace('-', '_')
                
            # Sanitize method names in requirements to use underscores instead of hyphens
            if "methods" in requirements:
                methods = {}
                for method_name, method_info in requirements["methods"].items():
                    valid_method_name = method_name.replace('-', '_')
                    methods[valid_method_name] = method_info
                requirements["methods"] = methods
            
            # Create the context for template rendering
            context = {
                "model_name": requirements["model_name"],
                "class_name": requirements["class_name"],
                "initialization": requirements["initialization"],
                "methods": requirements["methods"],
                "hardware_support": requirements["hardware_support"],
                "error_handling": requirements["error_handling"],
                "generated_timestamp": datetime.now().isoformat(),
                "generator_version": "1.0.0"
            }
            
            # Render the template
            implementation_code = template.render(**context)
            
            # Format the code with PEP 8 if autopep8 is available
            if AUTOPEP8_AVAILABLE:
                implementation_code = autopep8.fix_code(implementation_code)
            
            return implementation_code
            
        except jinja2.exceptions.TemplateNotFound:
            logger.error(f"Template {template_name} not found in {self.template_dir}")
            raise
        except Exception as e:
            logger.error(f"Error generating implementation: {e}")
            traceback.print_exc()
            raise
    
    def save_implementation(self, model_name, implementation_code):
        """
        Save the generated implementation to a file.
        
        Args:
            model_name: Name of the model
            implementation_code: Generated implementation code
            
        Returns:
            Path to the saved implementation file
        """
        # Normalize the model name for file naming
        normalized_name = model_name.replace('-', '_').replace('.', '_').lower()
        
        # Create file name
        filename = f"hf_{normalized_name}.py"
        filepath = os.path.join(self.output_dir, filename)
        
        # Save the implementation
        with open(filepath, 'w') as f:
            f.write(implementation_code)
        
        logger.info(f"Saved implementation to {filepath}")
        return filepath
    
    def validate_implementation(self, implementation_code):
        """
        Validate the generated implementation for syntax errors.
        
        Args:
            implementation_code: Generated implementation code
            
        Returns:
            Tuple of (valid, message)
        """
        try:
            ast.parse(implementation_code)
            return True, "Implementation is syntactically valid."
        except SyntaxError as e:
            error_msg = f"Syntax error in generated code: {str(e)}"
            logger.error(error_msg)
            return False, error_msg
    
    def generate_for_model(self, requirements_path, template_name=None):
        """
        Generate a complete implementation from requirements.
        
        Args:
            requirements_path: Path to requirements JSON file
            template_name: Optional template name to use
            
        Returns:
            Dict with generation results
        """
        try:
            # Load requirements
            requirements = self.load_requirements(requirements_path)
            
            # Extract model name
            model_name = requirements["model_name"]
            
            # Generate implementation
            implementation_code = self.generate_implementation(requirements, template_name)
            
            # Validate implementation
            valid, message = self.validate_implementation(implementation_code)
            if not valid:
                raise ValueError(f"Invalid implementation generated: {message}")
            
            # Save implementation
            filepath = self.save_implementation(model_name, implementation_code)
            
            # Return results
            return {
                "model_name": model_name,
                "filepath": filepath,
                "valid": valid,
                "validation_message": message
            }
            
        except Exception as e:
            logger.error(f"Error generating implementation for {requirements_path}: {e}")
            traceback.print_exc()
            return {
                "error": str(e),
                "traceback": traceback.format_exc()
            }
    
    def batch_generate(self, requirements_paths, template_map=None):
        """
        Generate implementations for multiple models.
        
        Args:
            requirements_paths: List of paths to requirements JSON files
            template_map: Optional dict mapping model names to template names
            
        Returns:
            Dict mapping model names to generation results
        """
        results = {}
        
        for req_path in requirements_paths:
            try:
                # Load requirements to get model name
                requirements = self.load_requirements(req_path)
                model_name = requirements["model_name"]
                
                # Get template name if provided in map
                template_name = None
                if template_map and model_name in template_map:
                    template_name = template_map[model_name]
                
                # Generate implementation
                result = self.generate_for_model(req_path, template_name)
                results[model_name] = result
                
            except Exception as e:
                logger.error(f"Error generating implementation for {req_path}: {e}")
                results[os.path.basename(req_path)] = {
                    "error": str(e),
                    "traceback": traceback.format_exc()
                }
        
        return results
    
    def list_templates(self):
        """
        List available templates in the template directory.
        
        Returns:
            List of template names
        """
        return [f for f in os.listdir(self.template_dir) if f.endswith('.jinja2')]
    
    def list_requirements(self):
        """
        List available requirements files.
        
        Returns:
            List of requirements file paths
        """
        return [os.path.join(REQUIREMENTS_DIR, f) for f in os.listdir(REQUIREMENTS_DIR) 
                if f.endswith('.json')]

# Example usage function
def generate_implementation_from_requirements(requirements_path, template_name=None, output_dir=None):
    """
    Example of how to use the SkillsetImplementationGenerator.
    
    Args:
        requirements_path: Path to requirements JSON file
        template_name: Optional template name to use
        output_dir: Optional output directory
        
    Returns:
        Dict with generation results
    """
    generator = SkillsetImplementationGenerator(output_dir=output_dir)
    result = generator.generate_for_model(requirements_path, template_name)
    return result

# Command-line interface
if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="Implementation Generator for creating model implementations")
    parser.add_argument("--requirements", type=str, help="Path to requirements JSON file")
    parser.add_argument("--list-requirements", action="store_true", help="List available requirements files")
    parser.add_argument("--list-templates", action="store_true", help="List available templates")
    parser.add_argument("--template", type=str, help="Template name to use")
    parser.add_argument("--output-dir", type=str, default=None, help="Output directory for generated implementations")
    parser.add_argument("--batch", action="store_true", help="Process all requirements files in batch")
    
    args = parser.parse_args()
    
    # Initialize generator
    generator = SkillsetImplementationGenerator(output_dir=args.output_dir)
    
    # List requirements or templates if requested
    if args.list_requirements:
        requirements = generator.list_requirements()
        print(f"Available requirements files ({len(requirements)}):")
        for req in requirements:
            print(f"  - {req}")
        sys.exit(0)
        
    if args.list_templates:
        templates = generator.list_templates()
        print(f"Available templates ({len(templates)}):")
        for tmpl in templates:
            print(f"  - {tmpl}")
        sys.exit(0)
    
    # Process batch if requested
    if args.batch:
        requirements = generator.list_requirements()
        if not requirements:
            print("No requirements files found. Generate requirements first with the TestResultCollector.")
            sys.exit(1)
            
        print(f"Processing {len(requirements)} requirements files...")
        results = generator.batch_generate(requirements)
        
        # Print summary
        success = 0
        failure = 0
        for model, result in results.items():
            if result.get('valid', False):
                success += 1
                print(f"✅ {model}: Generated successfully to {result.get('filepath')}")
            else:
                failure += 1
                print(f"❌ {model}: Failed - {result.get('error', 'Unknown error')}")
                
        print(f"\nSummary: {success} succeeded, {failure} failed")
        sys.exit(0)
    
    # Process single requirements file
    if args.requirements:
        result = generator.generate_for_model(args.requirements, args.template)
        
        if result.get('valid', False):
            print(f"✅ Generated implementation successfully to {result.get('filepath')}")
            print(f"Validation: {result.get('validation_message')}")
        else:
            print(f"❌ Failed to generate implementation: {result.get('error', 'Unknown error')}")
            if 'traceback' in result:
                print(f"\nError details:\n{result['traceback']}")
        
        sys.exit(0 if result.get('valid', False) else 1)
    
    # If no action specified, print help
    parser.print_help()