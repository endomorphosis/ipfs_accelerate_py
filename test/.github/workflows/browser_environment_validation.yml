name: Browser Environment Validation

on:
  push:
    branches: [ main ]
    paths:
      - 'fixed_web_platform/**'
      - 'check_browser_capabilities.py'
      - 'check_browser_webnn_webgpu.py'
      - '.github/workflows/browser_environment_validation.yml'
  pull_request:
    branches: [ main ]
    paths:
      - 'fixed_web_platform/**'
      - 'check_browser_capabilities.py'
      - 'check_browser_webnn_webgpu.py'
  workflow_dispatch:
    inputs:
      browser:
        description: 'Browser to test'
        required: false
        default: 'all'
        type: choice
        options:
          - all
          - chrome
          - firefox
          - edge
      platform:
        description: 'Platform to test'
        required: false
        default: 'all'
        type: choice
        options:
          - all
          - webnn
          - webgpu
      feature_flags:
        description: 'Feature flags to enable (comma-separated)'
        required: false
        default: 'none'
        type: string

jobs:
  validate-browser-environment:
    runs-on: ubuntu-latest
    outputs:
      test_results_path: ${{ steps.run_tests.outputs.test_results_path }}
      validation_timestamp: ${{ steps.timestamp.outputs.timestamp }}
      validation_run_id: ${{ steps.runid.outputs.run_id }}
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
          
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install selenium webdriver-manager websockets pytest pytest-asyncio
      
      - name: Get timestamp
        id: timestamp
        run: echo "timestamp=$(date -Iseconds)" >> $GITHUB_OUTPUT
        
      - name: Generate run ID
        id: runid
        run: echo "run_id=$(date +'%Y%m%d%H%M%S')" >> $GITHUB_OUTPUT
      
      - name: Set up Chrome
        uses: browser-actions/setup-chrome@latest
        
      - name: Set up Firefox
        uses: browser-actions/setup-firefox@latest

      - name: Set up Edge
        uses: browser-actions/setup-edge@latest
      
      - name: Set up test environment
        run: |
          mkdir -p browser_test_results
          mkdir -p validation_output
      
      - name: Parse feature flags
        id: parse_flags
        run: |
          FEATURE_FLAGS="${{ github.event.inputs.feature_flags || 'none' }}"
          COMPUTE_SHADERS="false"
          SHADER_PRECOMPILE="false"
          PARALLEL_LOADING="false"
          
          if [[ "$FEATURE_FLAGS" == *"compute_shaders"* ]]; then
            COMPUTE_SHADERS="true"
          fi
          
          if [[ "$FEATURE_FLAGS" == *"shader_precompile"* ]]; then
            SHADER_PRECOMPILE="true"
          fi
          
          if [[ "$FEATURE_FLAGS" == *"parallel_loading"* ]]; then
            PARALLEL_LOADING="true"
          fi
          
          echo "compute_shaders=$COMPUTE_SHADERS" >> $GITHUB_OUTPUT
          echo "shader_precompile=$SHADER_PRECOMPILE" >> $GITHUB_OUTPUT
          echo "parallel_loading=$PARALLEL_LOADING" >> $GITHUB_OUTPUT
      
      - name: Run automated browser tests
        id: run_tests
        continue-on-error: true
        run: |
          BROWSER="${{ github.event.inputs.browser || 'all' }}"
          PLATFORM="${{ github.event.inputs.platform || 'all' }}"
          
          echo "Running browser environment validation for browser: $BROWSER, platform: $PLATFORM"
          
          # Enable feature flags based on inputs
          if [[ "${{ steps.parse_flags.outputs.compute_shaders }}" == "true" ]]; then
            export WEBGPU_COMPUTE_SHADERS_ENABLED=1
            echo "Enabling compute shader optimization"
          fi
          
          if [[ "${{ steps.parse_flags.outputs.shader_precompile }}" == "true" ]]; then
            export WEBGPU_SHADER_PRECOMPILE_ENABLED=1
            echo "Enabling shader precompilation"
          fi
          
          if [[ "${{ steps.parse_flags.outputs.parallel_loading }}" == "true" ]]; then
            export WEB_PARALLEL_LOADING_ENABLED=1
            echo "Enabling parallel model loading"
          fi
          
          # Create test script that will run the checks
          cat > run_browser_validation.py << 'EOF'
import asyncio
import json
import sys
import os
import logging
from pathlib import Path
from datetime import datetime

# Set up logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger("browser_validation")

# Import the check functions
sys.path.append(str(Path.cwd()))
from check_browser_webnn_webgpu import check_browser_capabilities, check_all_browsers
from fixed_web_platform.browser_automation import BrowserAutomation

async def run_validation(browser, platform, output_dir, run_id, compute_shaders, shader_precompile, parallel_loading):
    """Run browser validation tests and save results."""
    
    results = {
        "run_id": run_id,
        "timestamp": datetime.now().isoformat(),
        "browsers": {},
        "feature_flags": {
            "compute_shaders": compute_shaders,
            "shader_precompilation": shader_precompile,
            "parallel_loading": parallel_loading
        }
    }
    
    # Set up output directory
    os.makedirs(output_dir, exist_ok=True)
    
    # Determine browsers to test
    browsers_to_test = []
    if browser == "all":
        browsers_to_test = ["chrome", "firefox", "edge"]
    else:
        browsers_to_test = [browser]
    
    # Determine platforms to test
    platforms_to_test = []
    if platform == "all":
        platforms_to_test = ["webnn", "webgpu"]
    else:
        platforms_to_test = [platform]
    
    # Run tests for each browser and platform
    for b in browsers_to_test:
        results["browsers"][b] = {}
        
        for p in platforms_to_test:
            logger.info(f"Testing {b} with {p}...")
            
            # Initialize browser automation
            automation = BrowserAutomation(
                platform=p,
                browser_name=b,
                headless=True,
                compute_shaders=(compute_shaders == "true"),
                precompile_shaders=(shader_precompile == "true"),
                parallel_loading=(parallel_loading == "true"),
                model_type="text"
            )
            
            try:
                # Launch browser
                success = await automation.launch(allow_simulation=True)
                
                if success:
                    # Run capabilities test
                    test_result = await automation.run_test("test-model", "validation test")
                    
                    results["browsers"][b][p] = {
                        "success": success,
                        "details": test_result,
                        "is_simulation": hasattr(automation, 'simulation_mode') and automation.simulation_mode,
                        "features": getattr(automation, 'features', {})
                    }
                else:
                    results["browsers"][b][p] = {
                        "success": False,
                        "error": "Failed to launch browser"
                    }
            except Exception as e:
                logger.error(f"Error testing {b} with {p}: {e}")
                results["browsers"][b][p] = {
                    "success": False,
                    "error": str(e)
                }
            finally:
                # Close browser
                try:
                    await automation.close()
                except:
                    pass
    
    # Save results
    with open(f"{output_dir}/validation_results_{run_id}.json", "w") as f:
        json.dump(results, f, indent=2)
    
    # Create summary markdown
    with open(f"{output_dir}/validation_summary_{run_id}.md", "w") as f:
        f.write(f"# Browser Environment Validation Summary\n\n")
        f.write(f"**Run ID:** {run_id}\n")
        f.write(f"**Timestamp:** {results['timestamp']}\n\n")
        
        f.write("## Feature Flags\n\n")
        f.write(f"- Compute Shaders: {results['feature_flags']['compute_shaders']}\n")
        f.write(f"- Shader Precompilation: {results['feature_flags']['shader_precompilation']}\n")
        f.write(f"- Parallel Loading: {results['feature_flags']['parallel_loading']}\n\n")
        
        f.write("## Results\n\n")
        
        for b in results["browsers"]:
            f.write(f"### {b.capitalize()}\n\n")
            
            for p in results["browsers"][b]:
                data = results["browsers"][b][p]
                success = data.get("success", False)
                
                if success:
                    details = data.get("details", {})
                    is_sim = data.get("is_simulation", True)
                    imp_type = details.get("implementation_type", "UNKNOWN")
                    
                    status = "✅ HARDWARE" if not is_sim else "⚠️ SIMULATION"
                    f.write(f"- **{p.upper()}**: {status}\n")
                    f.write(f"  - Implementation: {imp_type}\n")
                    
                    # Add feature details
                    if "features" in data:
                        features = data["features"]
                        if features:
                            f.write("  - Features:\n")
                            for k, v in features.items():
                                if isinstance(v, dict):
                                    f.write(f"    - {k}: {json.dumps(v)[:60]}...\n")
                                else:
                                    f.write(f"    - {k}: {v}\n")
                else:
                    error = data.get("error", "Unknown error")
                    f.write(f"- **{p.upper()}**: ❌ FAILED - {error}\n")
            
            f.write("\n")
    
    # Generate HTML report
    with open(f"{output_dir}/validation_report_{run_id}.html", "w") as f:
        f.write("""<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <title>Browser Environment Validation Report</title>
    <style>
        body { font-family: Arial, sans-serif; margin: 20px; }
        .success { color: green; }
        .warning { color: orange; }
        .error { color: red; }
        table { border-collapse: collapse; width: 100%; }
        th, td { border: 1px solid #ddd; padding: 8px; text-align: left; }
        th { background-color: #f2f2f2; }
        tr:nth-child(even) { background-color: #f9f9f9; }
        .details { margin-left: 20px; font-family: monospace; white-space: pre-wrap; }
    </style>
</head>
<body>
    <h1>Browser Environment Validation Report</h1>
    <p><strong>Run ID:</strong> """)
        f.write(run_id)
        f.write("</p><p><strong>Timestamp:</strong> ")
        f.write(results['timestamp'])
        f.write("</p>")
        
        f.write("""
    <h2>Feature Flags</h2>
    <ul>""")
        f.write(f"<li>Compute Shaders: {results['feature_flags']['compute_shaders']}</li>")
        f.write(f"<li>Shader Precompilation: {results['feature_flags']['shader_precompilation']}</li>")
        f.write(f"<li>Parallel Loading: {results['feature_flags']['parallel_loading']}</li>")
        f.write("</ul>")
        
        f.write("""
    <h2>Validation Results</h2>
    <table>
        <tr>
            <th>Browser</th>
            <th>Platform</th>
            <th>Status</th>
            <th>Implementation</th>
            <th>Details</th>
        </tr>""")
        
        for b in results["browsers"]:
            for p in results["browsers"][b]:
                data = results["browsers"][b][p]
                success = data.get("success", False)
                
                f.write("<tr>")
                f.write(f"<td>{b.capitalize()}</td>")
                f.write(f"<td>{p.upper()}</td>")
                
                if success:
                    details = data.get("details", {})
                    is_sim = data.get("is_simulation", True)
                    imp_type = details.get("implementation_type", "UNKNOWN")
                    
                    if not is_sim:
                        status = "<span class='success'>✅ HARDWARE</span>"
                    else:
                        status = "<span class='warning'>⚠️ SIMULATION</span>"
                    
                    f.write(f"<td>{status}</td>")
                    f.write(f"<td>{imp_type}</td>")
                    f.write(f"<td><div class='details'>{json.dumps(data.get('features', {}), indent=2)}</div></td>")
                else:
                    error = data.get("error", "Unknown error")
                    f.write(f"<td><span class='error'>❌ FAILED</span></td>")
                    f.write("<td>N/A</td>")
                    f.write(f"<td>{error}</td>")
                
                f.write("</tr>")
        
        f.write("""
    </table>
    
    <h2>Recommendations</h2>
    <ul>""")
        
        # Text models recommendation
        text_browsers = []
        for b in results["browsers"]:
            if "webnn" in results["browsers"][b] and results["browsers"][b]["webnn"].get("success", False):
                if not results["browsers"][b]["webnn"].get("is_simulation", True):
                    text_browsers.append(b)
        
        if text_browsers:
            f.write(f"<li><strong>For TEXT models:</strong> Use {', '.join(text_browsers)} (hardware-accelerated WebNN)</li>")
        else:
            text_gpu_browsers = []
            for b in results["browsers"]:
                if "webgpu" in results["browsers"][b] and results["browsers"][b]["webgpu"].get("success", False):
                    if not results["browsers"][b]["webgpu"].get("is_simulation", True):
                        text_gpu_browsers.append(b)
            
            if text_gpu_browsers:
                f.write(f"<li><strong>For TEXT models:</strong> Use {', '.join(text_gpu_browsers)} (hardware-accelerated WebGPU)</li>")
            else:
                f.write("<li><strong>For TEXT models:</strong> No hardware acceleration available</li>")
        
        # Vision models recommendation
        vision_browsers = []
        for b in results["browsers"]:
            if "webgpu" in results["browsers"][b] and results["browsers"][b]["webgpu"].get("success", False):
                if not results["browsers"][b]["webgpu"].get("is_simulation", True):
                    vision_browsers.append(b)
        
        if vision_browsers:
            f.write(f"<li><strong>For VISION models:</strong> Use {', '.join(vision_browsers)} (hardware-accelerated WebGPU)</li>")
        else:
            f.write("<li><strong>For VISION models:</strong> No hardware acceleration available</li>")
        
        # Audio models recommendation
        firefox_webgpu = False
        for b in results["browsers"]:
            if b == "firefox" and "webgpu" in results["browsers"][b] and results["browsers"][b]["webgpu"].get("success", False):
                if not results["browsers"][b]["webgpu"].get("is_simulation", True):
                    firefox_webgpu = True
        
        if firefox_webgpu:
            f.write("<li><strong>For AUDIO models:</strong> Use Firefox (hardware-accelerated WebGPU with compute shader optimization)</li>")
        elif vision_browsers:
            f.write(f"<li><strong>For AUDIO models:</strong> Use {', '.join(vision_browsers)} (hardware-accelerated WebGPU)</li>")
        else:
            f.write("<li><strong>For AUDIO models:</strong> No hardware acceleration available</li>")
        
        f.write("""
    </ul>
</body>
</html>
        """)
    
    return {
        "output_dir": output_dir,
        "run_id": run_id,
        "success": True
    }

if __name__ == "__main__":
    # Get parameters from environment
    browser = os.environ.get("TEST_BROWSER", "all")
    platform = os.environ.get("TEST_PLATFORM", "all")
    output_dir = os.environ.get("OUTPUT_DIR", "browser_test_results")
    run_id = os.environ.get("RUN_ID", datetime.now().strftime("%Y%m%d%H%M%S"))
    compute_shaders = os.environ.get("COMPUTE_SHADERS", "false")
    shader_precompile = os.environ.get("SHADER_PRECOMPILE", "false")
    parallel_loading = os.environ.get("PARALLEL_LOADING", "false")
    
    # Run validation
    result = asyncio.run(run_validation(
        browser=browser,
        platform=platform,
        output_dir=output_dir,
        run_id=run_id,
        compute_shaders=compute_shaders,
        shader_precompile=shader_precompile,
        parallel_loading=parallel_loading
    ))
    
    # Log summary
    logger.info(f"Validation complete. Results saved to {output_dir}/validation_results_{run_id}.json")
    logger.info(f"Summary report saved to {output_dir}/validation_summary_{run_id}.md")
    logger.info(f"HTML report saved to {output_dir}/validation_report_{run_id}.html")
    
    # Write outputs for GitHub Actions
    with open(os.environ.get("GITHUB_OUTPUT", "/dev/null"), "a") as f:
        f.write(f"output_dir={output_dir}\n")
        f.write(f"run_id={run_id}\n")
EOF
          
          # Run the validation script
          export TEST_BROWSER="$BROWSER"
          export TEST_PLATFORM="$PLATFORM"
          export OUTPUT_DIR="browser_test_results"
          export RUN_ID="${{ steps.runid.outputs.run_id }}"
          export COMPUTE_SHADERS="${{ steps.parse_flags.outputs.compute_shaders }}"
          export SHADER_PRECOMPILE="${{ steps.parse_flags.outputs.shader_precompile }}"
          export PARALLEL_LOADING="${{ steps.parse_flags.outputs.parallel_loading }}"
          
          # Run the validation
          python run_browser_validation.py
          
          # Save outputs for GitHub Actions
          echo "test_results_path=browser_test_results" >> $GITHUB_OUTPUT
      
      - name: Upload test results
        uses: actions/upload-artifact@v4
        with:
          name: browser-test-results
          path: browser_test_results/
      
      - name: Create environment summary
        run: |
          echo "### Browser Environment Validation Summary" >> $GITHUB_STEP_SUMMARY
          cat browser_test_results/validation_summary_${{ steps.runid.outputs.run_id }}.md >> $GITHUB_STEP_SUMMARY
          
          echo -e "\n## CI Job Information" >> $GITHUB_STEP_SUMMARY
          echo "- **Run ID:** ${{ steps.runid.outputs.run_id }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Timestamp:** ${{ steps.timestamp.outputs.timestamp }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Workflow:** ${{ github.workflow }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Job:** ${{ github.job }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Run URL:** ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}" >> $GITHUB_STEP_SUMMARY

  create-dashboard:
    needs: validate-browser-environment
    runs-on: ubuntu-latest
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
          
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install plotly pandas jinja2
      
      - name: Download test results
        uses: actions/download-artifact@v3
        with:
          name: browser-test-results
          path: browser_test_results/
      
      - name: Generate dashboard
        run: |
          # Create script to generate dashboard from test results
          cat > generate_dashboard.py << 'EOF'
import os
import json
import glob
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime

# Find all result files
result_files = glob.glob("browser_test_results/validation_results_*.json")
results_data = []

for file_path in result_files:
    with open(file_path, 'r') as f:
        data = json.load(f)
        # Get run details
        run_id = data.get('run_id')
        timestamp = data.get('timestamp')
        
        # Process browser results
        for browser_name, platforms in data.get('browsers', {}).items():
            for platform_name, platform_data in platforms.items():
                # Extract key metrics
                success = platform_data.get('success', False)
                is_simulation = platform_data.get('is_simulation', True)
                implementation_type = 'SIMULATION' if is_simulation else 'HARDWARE'
                
                # Get details if available
                details = platform_data.get('details', {})
                error = platform_data.get('error', None)
                features = platform_data.get('features', {})
                
                # Append to results list
                results_data.append({
                    'run_id': run_id,
                    'timestamp': timestamp,
                    'browser': browser_name,
                    'platform': platform_name,
                    'success': success,
                    'implementation_type': implementation_type,
                    'is_simulation': is_simulation,
                    'error': error,
                    'features': json.dumps(features)[:100] + '...' if features else None
                })

# Create DataFrame
df = pd.DataFrame(results_data)

if not df.empty:
    # Convert timestamp to datetime
    df['timestamp'] = pd.to_datetime(df['timestamp'])
    
    # Create status column for better visualization
    df['status'] = 'Error'
    df.loc[df['success'] & ~df['is_simulation'], 'status'] = 'Hardware Accelerated'
    df.loc[df['success'] & df['is_simulation'], 'status'] = 'Simulation'
    
    # Create output directory
    os.makedirs('dashboard', exist_ok=True)
    
    # Generate heatmap of browser capabilities
    fig = px.imshow(
        df.pivot_table(
            index='browser', 
            columns='platform', 
            values='is_simulation',
            aggfunc=lambda x: 1 if all(x) else 0 if not any(x) else 0.5
        ),
        labels=dict(x="Platform", y="Browser", color="Status"),
        color_continuous_scale=["green", "orange", "red"],
        title="Browser Acceleration Capabilities"
    )
    
    fig.update_layout(
        height=500,
        width=800
    )
    
    fig.write_html("dashboard/browser_capabilities.html")
    
    # Generate status counts by browser
    status_counts = df.groupby(['browser', 'status']).size().reset_index(name='count')
    
    fig = px.bar(
        status_counts,
        x='browser',
        y='count',
        color='status',
        title="Browser Support Status",
        labels={'count': 'Count', 'browser': 'Browser', 'status': 'Status'},
        color_discrete_map={
            'Hardware Accelerated': 'green',
            'Simulation': 'orange',
            'Error': 'red'
        }
    )
    
    fig.write_html("dashboard/browser_status.html")
    
    # Generate status counts by platform
    platform_status = df.groupby(['platform', 'status']).size().reset_index(name='count')
    
    fig = px.bar(
        platform_status,
        x='platform',
        y='count',
        color='status',
        title="Platform Support Status",
        labels={'count': 'Count', 'platform': 'Platform', 'status': 'Status'},
        color_discrete_map={
            'Hardware Accelerated': 'green',
            'Simulation': 'orange',
            'Error': 'red'
        }
    )
    
    fig.write_html("dashboard/platform_status.html")
    
    # Create index.html
    with open('dashboard/index.html', 'w') as f:
        f.write("""<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <title>Browser Environment Validation Dashboard</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 0;
            padding: 20px;
            background-color: #f5f5f5;
        }
        .container {
            max-width: 1200px;
            margin: 0 auto;
            background-color: white;
            padding: 20px;
            border-radius: 8px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }
        h1, h2, h3 {
            color: #333;
        }
        .charts {
            display: flex;
            flex-direction: column;
            gap: 20px;
            margin-top: 20px;
        }
        .chart-container {
            width: 100%;
            height: 500px;
            border: 1px solid #ddd;
            border-radius: 4px;
            overflow: hidden;
        }
        iframe {
            width: 100%;
            height: 100%;
            border: none;
        }
        .card {
            background-color: white;
            border-radius: 4px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
            padding: 15px;
            margin-bottom: 20px;
        }
        .results-table {
            width: 100%;
            border-collapse: collapse;
        }
        .results-table th, .results-table td {
            border: 1px solid #ddd;
            padding: 8px;
            text-align: left;
        }
        .results-table th {
            background-color: #f2f2f2;
        }
        .results-table tr:nth-child(even) {
            background-color: #f9f9f9;
        }
        .success { color: green; }
        .warning { color: orange; }
        .error { color: red; }
    </style>
</head>
<body>
    <div class="container">
        <h1>Browser Environment Validation Dashboard</h1>
        <p>This dashboard shows the results of browser environment validation tests for WebNN and WebGPU.</p>
        
        <div class="card">
            <h2>Recommendations</h2>
            <h3>For TEXT models:</h3>
            <ul>""")
        
        # Add recommendations based on analysis
        hardware_browsers = df[(df['success'] == True) & (df['is_simulation'] == False)]
        
        # For text models (WebNN preferred)
        webnn_hardware = hardware_browsers[hardware_browsers['platform'] == 'webnn']
        if not webnn_hardware.empty:
            webnn_browsers = webnn_hardware['browser'].tolist()
            f.write(f"<li>Use <strong>{', '.join(webnn_browsers)}</strong> with WebNN for best performance</li>")
        else:
            # Fallback to WebGPU
            webgpu_hardware = hardware_browsers[hardware_browsers['platform'] == 'webgpu']
            if not webgpu_hardware.empty:
                webgpu_browsers = webgpu_hardware['browser'].tolist()
                f.write(f"<li>Use <strong>{', '.join(webgpu_browsers)}</strong> with WebGPU (WebNN not available with hardware acceleration)</li>")
            else:
                f.write("<li>No hardware-accelerated browsers available for text models</li>")
        
        f.write("""</ul>
            <h3>For VISION models:</h3>
            <ul>""")
        
        # For vision models (WebGPU preferred)
        webgpu_hardware = hardware_browsers[hardware_browsers['platform'] == 'webgpu']
        if not webgpu_hardware.empty:
            webgpu_browsers = webgpu_hardware['browser'].tolist()
            f.write(f"<li>Use <strong>{', '.join(webgpu_browsers)}</strong> with WebGPU for best performance</li>")
        else:
            f.write("<li>No hardware-accelerated browsers available for vision models</li>")
        
        f.write("""</ul>
            <h3>For AUDIO models:</h3>
            <ul>""")
        
        # For audio models (Firefox with WebGPU preferred)
        firefox_webgpu = hardware_browsers[(hardware_browsers['platform'] == 'webgpu') & (hardware_browsers['browser'] == 'firefox')]
        if not firefox_webgpu.empty:
            f.write("<li>Use <strong>Firefox</strong> with WebGPU for best audio model performance (best compute shader support)</li>")
        elif not webgpu_hardware.empty:
            webgpu_browsers = webgpu_hardware['browser'].tolist()
            f.write(f"<li>Use <strong>{', '.join(webgpu_browsers)}</strong> with WebGPU</li>")
        else:
            f.write("<li>No hardware-accelerated browsers available for audio models</li>")
        
        f.write("""</ul>
        </div>
        
        <div class="charts">
            <h2>Browser Capabilities Overview</h2>
            <div class="chart-container">
                <iframe src="browser_capabilities.html"></iframe>
            </div>
            
            <h2>Browser Support Status</h2>
            <div class="chart-container">
                <iframe src="browser_status.html"></iframe>
            </div>
            
            <h2>Platform Support Status</h2>
            <div class="chart-container">
                <iframe src="platform_status.html"></iframe>
            </div>
        </div>
        
        <div class="card">
            <h2>Latest Test Results</h2>
            <table class="results-table">
                <tr>
                    <th>Browser</th>
                    <th>Platform</th>
                    <th>Status</th>
                    <th>Implementation</th>
                </tr>""")
        
        # Add rows for each browser/platform combination
        for _, row in df.sort_values(['browser', 'platform']).iterrows():
            status_class = 'success' if row['success'] and not row['is_simulation'] else 'warning' if row['success'] else 'error'
            status_text = '✅ HARDWARE' if row['success'] and not row['is_simulation'] else '⚠️ SIMULATION' if row['success'] else '❌ ERROR'
            
            f.write(f"""
                <tr>
                    <td>{row['browser'].capitalize()}</td>
                    <td>{row['platform'].upper()}</td>
                    <td class="{status_class}">{status_text}</td>
                    <td>{row['implementation_type']}</td>
                </tr>""")
        
        f.write("""
            </table>
        </div>
        
        <footer>
            <p>Last updated: """)
        
        f.write(datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
        
        f.write("""</p>
            <p>Generated by CI/CD workflow</p>
        </footer>
    </div>
</body>
</html>""")

print("Dashboard generated successfully!")
EOF
          
          # Generate dashboard
          python generate_dashboard.py
      
      - name: Deploy to GitHub Pages
        uses: JamesIves/github-pages-deploy-action@v4
        with:
          folder: dashboard
          target-folder: browser-validation
          
      - name: Add dashboard link to summary
        run: |
          echo "### Browser Environment Validation Dashboard" >> $GITHUB_STEP_SUMMARY
          echo "The dashboard has been deployed to GitHub Pages and is available at:" >> $GITHUB_STEP_SUMMARY
          echo "[${{ github.server_url }}/${{ github.repository }}/browser-validation](${{ github.server_url }}/${{ github.repository }}/browser-validation)" >> $GITHUB_STEP_SUMMARY