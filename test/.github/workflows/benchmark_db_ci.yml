name: Benchmark Database CI

on:
  push:
    branches: [ main ]
    paths:
      - 'test/**'
      - '.github/workflows/benchmark_db_ci.yml'
  pull_request:
    branches: [ main ]
    paths:
      - 'test/**'
  workflow_dispatch:
    inputs:
      test_model:
        description: 'Model to test'
        required: false
        default: 'all'
      hardware:
        description: 'Hardware to test on'
        required: false
        default: 'cpu'
        type: choice
        options:
          - cpu
          - cuda
          - all
      batch_size:
        description: 'Batch sizes to test'
        required: false
        default: '1,2,4,8'

jobs:
  setup_database:
    runs-on: ubuntu-latest
    outputs:
      db_path: ${{ steps.setup_db.outputs.db_path }}
      today_date: ${{ steps.date.outputs.date }}
      run_id: ${{ steps.runid.outputs.run_id }}
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
          
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r duckdb_api/scripts/requirements_db.txt
      
      - name: Get date
        id: date
        run: echo "::set-output name=date::$(date +'%Y%m%d')"
        
      - name: Generate run ID
        id: runid
        run: echo "::set-output name=run_id::$(date +'%Y%m%d%H%M%S')"
      
      - name: Set up database
        id: setup_db
        run: |
          mkdir -p benchmark_db
          echo "::set-output name=db_path::benchmark_db/ci_benchmark_${{ steps.runid.outputs.run_id }}.duckdb"
          python duckdb_api/scripts/create_benchmark_schema.py --output benchmark_db/ci_benchmark_${{ steps.runid.outputs.run_id }}.duckdb --sample-data
      
      - name: Generate CI metadata
        run: |
          cat > ci_metadata.json << EOF
          {
            "workflow_id": "${{ github.run_id }}",
            "workflow_name": "${{ github.workflow }}",
            "run_id": "${{ steps.runid.outputs.run_id }}",
            "github_ref": "${{ github.ref }}",
            "github_repository": "${{ github.repository }}",
            "github_actor": "${{ github.actor }}",
            "trigger_event": "${{ github.event_name }}"
          }
          EOF
          
      - name: Upload database
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-db
          path: benchmark_db/ci_benchmark_${{ steps.runid.outputs.run_id }}.duckdb
          
      - name: Upload CI metadata
        uses: actions/upload-artifact@v4
        with:
          name: ci-metadata
          path: ci_metadata.json
          
  run_benchmarks:
    needs: setup_database
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-latest]
        model:
          - ${{ github.event.inputs.test_model == 'all' && 'bert-base-uncased' || github.event.inputs.test_model }}
          - ${{ github.event.inputs.test_model == 'all' && 't5-small' || '' }}
          - ${{ github.event.inputs.test_model == 'all' && 'vit-base' || '' }}
        hardware:
          - ${{ github.event.inputs.hardware == 'all' && 'cpu' || github.event.inputs.hardware }}
          - ${{ github.event.inputs.hardware == 'all' && 'cuda' || '' }}
        exclude:
          - model: ""
          - hardware: ""
        
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
          
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r duckdb_api/scripts/requirements_db.txt
          pip install -r requirements.txt
          
      - name: Download database
        uses: actions/download-artifact@v3
        with:
          name: benchmark-db
          path: benchmark_db
          
      - name: Download CI metadata
        uses: actions/download-artifact@v3
        with:
          name: ci-metadata
          path: .
          
      - name: Get git info
        id: git_info
        run: |
          echo "::set-output name=commit::$(git rev-parse HEAD)"
          echo "::set-output name=branch::$(git rev-parse --abbrev-ref HEAD)"
          
      - name: Run benchmark with database
        run: |
          DB_FILE=$(find benchmark_db -name "*.duckdb" | head -n 1)
          python duckdb_api/core/run_benchmark_with_db.py \
            --db $DB_FILE \
            --model ${{ matrix.model }} \
            --hardware ${{ matrix.hardware }} \
            --batch-sizes ${{ github.event.inputs.batch_size || '1,2,4,8' }} \
            --commit ${{ steps.git_info.outputs.commit }} \
            --branch ${{ steps.git_info.outputs.branch }} \
            --iterations 20 \
            --warmup 5 \
            --test-name "ci_benchmark_${{ matrix.model }}_${{ matrix.hardware }}_${{ needs.setup_database.outputs.run_id }}"
            
      - name: Generate result JSON
        run: |
          mkdir -p benchmark_results
          cat > benchmark_results/benchmark_${{ matrix.model }}_${{ matrix.hardware }}.json << EOF
          {
            "model_name": "${{ matrix.model }}",
            "hardware_type": "${{ matrix.hardware }}",
            "batch_sizes": "${{ github.event.inputs.batch_size || '1,2,4,8' }}",
            "git_commit": "${{ steps.git_info.outputs.commit }}",
            "git_branch": "${{ steps.git_info.outputs.branch }}",
            "ci_run_id": "${{ needs.setup_database.outputs.run_id }}",
            "timestamp": "$(date -Iseconds)",
            "test_name": "ci_benchmark_${{ matrix.model }}_${{ matrix.hardware }}_${{ needs.setup_database.outputs.run_id }}"
          }
          EOF
            
      - name: Upload updated database
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-db-updated-${{ matrix.model }}-${{ matrix.hardware }}
          path: benchmark_db
          
      - name: Upload benchmark results
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-results-${{ matrix.model }}-${{ matrix.hardware }}
          path: benchmark_results
          
  consolidate_results:
    needs: [setup_database, run_benchmarks]
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
          
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r duckdb_api/scripts/requirements_db.txt
          pip install requests pandas numpy
          
      - name: Download all artifacts
        uses: actions/download-artifact@v3
        with:
          path: artifacts
          
      - name: List downloaded artifacts
        run: |
          find artifacts -type f | sort
          
      - name: Process CI artifacts with integrator
        run: |
          python duckdb_api/scripts/ci_benchmark_integrator.py \
            --artifacts-dir ./artifacts \
            --db ./consolidated_db.duckdb \
            --ci-metadata ./artifacts/ci-metadata/ci_metadata.json \
            --commit ${{ github.sha }} \
            --branch ${{ github.ref_name }} \
            --build-id ${{ needs.setup_database.outputs.run_id }} \
            --ci-platform "github" \
            --archive-artifacts \
            --archive-dir ./archived_artifacts
          
      - name: Generate reports
        run: |
          # Generate performance report
          python duckdb_api/core/benchmark_db_query.py \
            --db ./consolidated_db.duckdb \
            --report performance \
            --format html \
            --output performance_report_${{ needs.setup_database.outputs.today_date }}.html
            
          # Generate compatibility matrix
          python duckdb_api/core/benchmark_db_query.py \
            --db ./consolidated_db.duckdb \
            --compatibility-matrix \
            --format html \
            --output compatibility_matrix_${{ needs.setup_database.outputs.today_date }}.html
            
          # Generate hardware comparison chart
          python duckdb_api/core/benchmark_db_query.py \
            --db ./consolidated_db.duckdb \
            --hardware-comparison-chart \
            --metric throughput \
            --output hardware_comparison_${{ needs.setup_database.outputs.today_date }}.png
            
          # Generate summary JSON
          python duckdb_api/core/benchmark_db_query.py \
            --db ./consolidated_db.duckdb \
            --summary \
            --format json \
            --output benchmark_summary_${{ needs.setup_database.outputs.today_date }}.json
      
      - name: Detect performance regressions
        id: regression
        run: |
          python duckdb_api/analysis/benchmark_regression_detector.py \
            --db ./consolidated_db.duckdb \
            --run-id "${{ needs.setup_database.outputs.run_id }}" \
            --threshold 0.1 \
            --window 5 \
            --metrics "throughput,latency,memory_peak" \
            --output regression_report_${{ needs.setup_database.outputs.today_date }}.html \
            --format html
          
          # Additionally create markdown report for GitHub issues
          python duckdb_api/analysis/benchmark_regression_detector.py \
            --db ./consolidated_db.duckdb \
            --run-id "${{ needs.setup_database.outputs.run_id }}" \
            --threshold 0.1 \
            --window 5 \
            --output regression_report_${{ needs.setup_database.outputs.today_date }}.md \
            --format markdown
            
          # Check for high severity regressions to be notified in the workflow summary
          HIGH_SEVERITY=$(python duckdb_api/analysis/benchmark_regression_detector.py \
            --db ./consolidated_db.duckdb \
            --run-id "${{ needs.setup_database.outputs.run_id }}" \
            --threshold 0.2 | grep -c '"severity": "high"' || echo "0")
            
          MEDIUM_SEVERITY=$(python duckdb_api/analysis/benchmark_regression_detector.py \
            --db ./consolidated_db.duckdb \
            --run-id "${{ needs.setup_database.outputs.run_id }}" \
            --threshold 0.1 | grep -c '"severity": "medium"' || echo "0")
            
          echo "::set-output name=high_severity::${HIGH_SEVERITY}"
          echo "::set-output name=medium_severity::${MEDIUM_SEVERITY}"
          
      - name: Create GitHub issue for severe regressions
        if: ${{ steps.regression.outputs.high_severity > 0 || steps.regression.outputs.medium_severity > 0 }}
        run: |
          python duckdb_api/analysis/benchmark_regression_detector.py \
            --db ./consolidated_db.duckdb \
            --run-id "${{ needs.setup_database.outputs.run_id }}" \
            --threshold 0.1 \
            --create-issues \
            --github-token ${{ secrets.GITHUB_TOKEN }} \
            --github-repo ${{ github.repository }}
      
      - name: Integrate with hardware model predictor
        run: |
          python predictive_performance/hardware_model_predictor.py \
            --validate-predictions \
            --database ./consolidated_db.duckdb \
            --output hardware_prediction_accuracy.json
            
          # Train updated prediction models based on new benchmark data
          python predictive_performance/model_performance_predictor.py \
            --train \
            --database ./consolidated_db.duckdb \
            --output-dir ./prediction_models
      
      - name: Upload consolidated database
        uses: actions/upload-artifact@v4
        with:
          name: consolidated-benchmark-db
          path: consolidated_db.duckdb
          
      - name: Upload reports
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-reports
          path: |
            performance_report_*.html
            compatibility_matrix_*.html
            hardware_comparison_*.png
            benchmark_summary_*.json
            regression_report_*.html
            regression_report_*.md
            hardware_prediction_accuracy.json

  publish_results:
    needs: [setup_database, consolidate_results]
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r duckdb_api/scripts/requirements_db.txt
          
      - name: Download reports
        uses: actions/download-artifact@v3
        with:
          name: benchmark-reports
          path: reports
          
      - name: Download consolidated database
        uses: actions/download-artifact@v3
        with:
          name: consolidated-benchmark-db
          path: db
          
      - name: Create report index
        run: |
          # Generate HTML index file for reports
          cat > reports/index.html << EOF
          <!DOCTYPE html>
          <html>
          <head>
              <title>Hardware Benchmark Reports</title>
              <meta charset="utf-8">
              <meta name="viewport" content="width=device-width, initial-scale=1">
              <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0-alpha1/dist/css/bootstrap.min.css" rel="stylesheet">
          </head>
          <body>
              <div class="container mt-4">
                  <h1>Hardware Benchmark Reports</h1>
                  <p>Latest benchmark run: ${{ needs.setup_database.outputs.today_date }}</p>
                  
                  <h2>Latest Reports</h2>
                  <ul>
                      <li><a href="performance_report_${{ needs.setup_database.outputs.today_date }}.html">Performance Report</a></li>
                      <li><a href="compatibility_matrix_${{ needs.setup_database.outputs.today_date }}.html">Compatibility Matrix</a></li>
                      <li><a href="hardware_comparison_${{ needs.setup_database.outputs.today_date }}.png">Hardware Comparison Chart</a></li>
                      <li><a href="regression_report_${{ needs.setup_database.outputs.today_date }}.html">Performance Regression Analysis</a></li>
                      <li><a href="benchmark_summary_${{ needs.setup_database.outputs.today_date }}.json">Benchmark Summary (JSON)</a></li>
                  </ul>
                  
                  <h2>Performance Prediction</h2>
                  <p>The benchmark system now includes machine learning-based performance prediction for hardware-model combinations:</p>
                  <ul>
                      <li><a href="hardware_prediction_accuracy.json">Latest Prediction Accuracy Report</a></li>
                  </ul>
                  
                  <h2>CI/CD Integration</h2>
                  <p>
                    This benchmark report was automatically generated by the CI/CD system.
                    The system includes performance regression detection, prediction model training,
                    and automatic notification for significant regressions.
                  </p>
                  <p>
                    <a href="https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}" class="btn btn-primary">
                      View CI Run
                    </a>
                  </p>
              </div>
          </body>
          </html>
          EOF
          
      - name: Publish to GitHub Pages
        uses: peaceiris/actions-gh-pages@v3
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_dir: ./reports
          destination_dir: benchmark-reports
          
      - name: Create historical database copy
        run: |
          mkdir -p historical_db
          cp db/consolidated_db.duckdb historical_db/benchmark_${{ needs.setup_database.outputs.today_date }}.duckdb
          
      - name: Upload historical database
        uses: actions/upload-artifact@v4
        with:
          name: historical-benchmark-db
          path: historical_db/