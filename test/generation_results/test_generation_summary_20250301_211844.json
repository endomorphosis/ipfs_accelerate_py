{
  "timestamp": "20250301_211844",
  "total_skillset_modules": 13,
  "total_model_types": 299,
  "models_tested": [
    "bert",
    "clap",
    "clip",
    "detr",
    "llama",
    "llava",
    "llava_next",
    "qwen2",
    "t5",
    "vit",
    "wav2vec2",
    "whisper",
    "xclip"
  ],
  "missing_from_official_list": [],
  "generation_stats": {
    "total": 13,
    "successful": 1,
    "failed": 12,
    "success_rate": 0.07692307692307693
  },
  "execution_stats": {
    "total": 1,
    "successful": 1,
    "failed": 0,
    "success_rate": 1.0
  },
  "generation_results": [
    {
      "model_type": "bert",
      "success": true,
      "return_code": 0,
      "output_file": "/home/barberb/ipfs_accelerate_py/test/generated_skills/test_hf_bert.py",
      "elapsed_time": 0.06563687324523926,
      "stdout": "Generating tests for models: bert\nTest file already exists for bert, skipping\nSuccessfully generated 0 out of 1 requested models\n",
      "stderr": "2025-03-01 21:18:44,967 - INFO - Found 320 existing test implementations\n"
    },
    {
      "model_type": "clap",
      "success": false,
      "return_code": 0,
      "output_file": null,
      "elapsed_time": 0.09904742240905762,
      "stdout": "Generating tests for models: clap\nError: Model family 'clap' not found in registry\nSuccessfully generated 0 out of 1 requested models\n",
      "stderr": "2025-03-01 21:18:51,539 - INFO - Found 320 existing test implementations\n"
    },
    {
      "model_type": "clip",
      "success": false,
      "return_code": 0,
      "output_file": null,
      "elapsed_time": 0.0666649341583252,
      "stdout": "Generating tests for models: clip\nError: Model family 'clip' not found in registry\nSuccessfully generated 0 out of 1 requested models\n",
      "stderr": "2025-03-01 21:18:51,611 - INFO - Found 320 existing test implementations\n"
    },
    {
      "model_type": "detr",
      "success": false,
      "return_code": 0,
      "output_file": null,
      "elapsed_time": 0.06752395629882812,
      "stdout": "Generating tests for models: detr\nError: Model family 'detr' not found in registry\nSuccessfully generated 0 out of 1 requested models\n",
      "stderr": "2025-03-01 21:18:51,678 - INFO - Found 320 existing test implementations\n"
    },
    {
      "model_type": "llama",
      "success": false,
      "return_code": 0,
      "output_file": null,
      "elapsed_time": 0.06334400177001953,
      "stdout": "Generating tests for models: llama\nError: Model family 'llama' not found in registry\nSuccessfully generated 0 out of 1 requested models\n",
      "stderr": "2025-03-01 21:18:51,742 - INFO - Found 320 existing test implementations\n"
    },
    {
      "model_type": "llava",
      "success": false,
      "return_code": 0,
      "output_file": null,
      "elapsed_time": 0.07382893562316895,
      "stdout": "Generating tests for models: llava\nError: Model family 'llava' not found in registry\nSuccessfully generated 0 out of 1 requested models\n",
      "stderr": "2025-03-01 21:18:51,813 - INFO - Found 320 existing test implementations\n"
    },
    {
      "model_type": "llava_next",
      "success": false,
      "return_code": 0,
      "output_file": null,
      "elapsed_time": 0.06139707565307617,
      "stdout": "Generating tests for models: llava_next\nError: Model family 'llava_next' not found in registry\nSuccessfully generated 0 out of 1 requested models\n",
      "stderr": "2025-03-01 21:18:51,876 - INFO - Found 320 existing test implementations\n"
    },
    {
      "model_type": "qwen2",
      "success": false,
      "return_code": 0,
      "output_file": null,
      "elapsed_time": 0.06950211524963379,
      "stdout": "Generating tests for models: qwen2\nError: Model family 'qwen2' not found in registry\nSuccessfully generated 0 out of 1 requested models\n",
      "stderr": "2025-03-01 21:18:51,946 - INFO - Found 320 existing test implementations\n"
    },
    {
      "model_type": "t5",
      "success": false,
      "return_code": 0,
      "output_file": null,
      "elapsed_time": 0.06540751457214355,
      "stdout": "Generating tests for models: t5\nError: Model family 't5' not found in registry\nSuccessfully generated 0 out of 1 requested models\n",
      "stderr": "2025-03-01 21:18:52,011 - INFO - Found 320 existing test implementations\n"
    },
    {
      "model_type": "vit",
      "success": false,
      "return_code": 0,
      "output_file": null,
      "elapsed_time": 0.07770776748657227,
      "stdout": "Generating tests for models: vit\nError: Model family 'vit' not found in registry\nSuccessfully generated 0 out of 1 requested models\n",
      "stderr": "2025-03-01 21:18:52,081 - INFO - Found 320 existing test implementations\n"
    },
    {
      "model_type": "wav2vec2",
      "success": false,
      "return_code": 0,
      "output_file": null,
      "elapsed_time": 0.06768560409545898,
      "stdout": "Generating tests for models: wav2vec2\nError: Model family 'wav2vec2' not found in registry\nSuccessfully generated 0 out of 1 requested models\n",
      "stderr": "2025-03-01 21:18:52,154 - INFO - Found 320 existing test implementations\n"
    },
    {
      "model_type": "whisper",
      "success": false,
      "return_code": 0,
      "output_file": null,
      "elapsed_time": 0.05960559844970703,
      "stdout": "Generating tests for models: whisper\nError: Model family 'whisper' not found in registry\nSuccessfully generated 0 out of 1 requested models\n",
      "stderr": "2025-03-01 21:18:52,216 - INFO - Found 320 existing test implementations\n"
    },
    {
      "model_type": "xclip",
      "success": false,
      "return_code": 0,
      "output_file": null,
      "elapsed_time": 0.06851720809936523,
      "stdout": "Generating tests for models: xclip\nError: Model family 'xclip' not found in registry\nSuccessfully generated 0 out of 1 requested models\n",
      "stderr": "2025-03-01 21:18:52,283 - INFO - Found 320 existing test implementations\n"
    }
  ],
  "execution_results": [
    {
      "test_file": "/home/barberb/ipfs_accelerate_py/test/generated_skills/test_hf_bert.py",
      "success": true,
      "return_code": 0,
      "elapsed_time": 6.4769885540008545,
      "stdout": "Warning: test utils not available, using mock implementation\nTesting the model on CPU...\nLoading distilroberta-base for CPU inference...\nError loading model: RobertaModel.__init__() got an unexpected keyword argument 'return_dict'\nFalling back to mock implementation\n(MOCK) Created mock BERT tokenizer\n(MOCK) Created mock BERT endpoint for distilroberta-base on cpu\nTesting batch inference on CPU with batch size: 0\nTesting the model on CUDA...\nCUDA utilities imported successfully\nUsing CUDA device: Quadro P4000 (index 0)\nCUDA memory: 7.76GB free / 7.92GB total\nLoading distilroberta-base for CUDA inference on cuda:0...\nDynamic batch size based on available memory: 15\nFailed to load model: RobertaModel.__init__() got an unexpected keyword argument 'return_dict'\nTraceback: Traceback (most recent call last):\n  File \"/home/barberb/ipfs_accelerate_py/ipfs_accelerate_py/worker/skillset/hf_bert.py\", line 397, in init_cuda\n    endpoint = self.transformers.AutoModel.from_pretrained(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/barberb/ipfs_accelerate_py/.venv/lib/python3.12/site-packages/transformers/models/auto/auto_factory.py\", line 564, in from_pretrained\n    return model_class.from_pretrained(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/barberb/ipfs_accelerate_py/.venv/lib/python3.12/site-packages/transformers/modeling_utils.py\", line 4096, in from_pretrained\n    model = cls(config, *model_args, **model_kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nTypeError: RobertaModel.__init__() got an unexpected keyword argument 'return_dict'\n\nFalling back to mock implementation\nCUDA utilities imported successfully for handler\nProcessing string input with 1 items\nOpenVINO is installed\nTesting the model on OPENVINO...\nError in OPENVINO tests: hf_bert.init_openvino() missing 1 required positional argument: 'openvino_label'\nSaved collected results to /home/barberb/ipfs_accelerate_py/test/generated_skills/collected_results/hf_bert_test_results.json\nTest results differ from expected results!\n- Key 'cpu_batch_speedup' differs: Expected '2.29x', got '3.58x'\n\nWould you like to update the expected results? (y/n)\nError comparing results with /home/barberb/ipfs_accelerate_py/test/generated_skills/expected_results/hf_bert_test_results.json: EOF when reading a line\nCreating new expected results file.\nTest completed successfully\n",
      "stderr": "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nTraceback (most recent call last):\n  File \"/home/barberb/ipfs_accelerate_py/test/generated_skills/test_hf_bert.py\", line 846, in _run_platform_test\n    endpoint, processor, handler, queue, batch_size = init_method(\n                                                      ^^^^^^^^^^^^\nTypeError: hf_bert.init_openvino() missing 1 required positional argument: 'openvino_label'\n"
    }
  ]
}