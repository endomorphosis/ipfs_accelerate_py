Code Quality Report - Sun Jun 29 12:20:01 PM PDT 2025
=
error: cannot format /home/barberb/ipfs_accelerate_py/src/backends/modular_backend.py: Cannot parse for target version Python 3.13: 603:0: </final_file_content>
--- final_mcp_server.py	2025-06-29 18:43:40.688070+00:00
+++ final_mcp_server.py	2025-06-29 19:20:04.396875+00:00
@@ -32,16 +32,18 @@
 import re
 
 # --- Handle multihash.FuncReg error ---
 try:
     import multihash
-    if not hasattr(multihash, 'FuncReg'):
+
+    if not hasattr(multihash, "FuncReg"):
         # Create a mock FuncReg object
         class MockFuncReg:
             @staticmethod
             def register(*args, **kwargs):
                 pass
+
         multihash.FuncReg = MockFuncReg()
 except ImportError:
     # Create a mock multihash module with FuncReg
     class MockFuncReg:
         @staticmethod
@@ -49,29 +51,34 @@
             pass
 
     class MockMultihash:
         FuncReg = MockFuncReg()
 
-    sys.modules['multihash'] = MockMultihash()
+    sys.modules["multihash"] = MockMultihash()
 
 # --- Early Setup: Logging and Path ---
 # Configure logging
 logging.basicConfig(
     level=logging.INFO,
-    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
+    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
     handlers=[
-        logging.FileHandler("final_mcp_server.log", mode='w'), # Ensure log is overwritten per run
-        logging.StreamHandler()
-    ]
+        logging.FileHandler(
+            "final_mcp_server.log", mode="w"
+        ),  # Ensure log is overwritten per run
+        logging.StreamHandler(),
+    ],
 )
 logger = logging.getLogger("final-mcp")
 
 # --- BEGIN MCP SERVER DIAGNOSTIC LOGGING ---
 logger.info(f"MCP Server sys.path at start: {sys.path}")
 try:
     import transformers
-    logger.info(f"MCP Server: Successfully imported 'transformers' module. Version: {getattr(transformers, '__version__', 'unknown')}")
+
+    logger.info(
+        f"MCP Server: Successfully imported 'transformers' module. Version: {getattr(transformers, '__version__', 'unknown')}"
+    )
 except ImportError as e:
     logger.error(f"MCP Server: FAILED to import 'transformers' module. Error: {e}")
 # --- END MCP SERVER DIAGNOSTIC LOGGING ---
 
 
@@ -95,84 +102,115 @@
 IPFS_FS_BRIDGE_AVAILABLE = False
 MULTI_BACKEND_FS_AVAILABLE = False
 
 try:
     import uvicorn
-    from fastapi import FastAPI, Request, Response, HTTPException, BackgroundTasks, WebSocket, WebSocketDisconnect
+    from fastapi import (
+        FastAPI,
+        Request,
+        Response,
+        HTTPException,
+        BackgroundTasks,
+        WebSocket,
+        WebSocketDisconnect,
+    )
     from fastapi.responses import JSONResponse, StreamingResponse
     from fastapi.middleware.cors import CORSMiddleware
     from fastapi.staticfiles import StaticFiles
     from starlette.responses import Response as StarletteResponse
     from starlette.background import BackgroundTask as StarletteBackgroundTask
 except ImportError as e:
     logger.error(f"Failed to import FastAPI components: {e}")
-    logger.info("Please install required dependencies with: pip install fastapi uvicorn[standard]")
+    logger.info(
+        "Please install required dependencies with: pip install fastapi uvicorn[standard]"
+    )
     sys.exit(1)
 
 try:
     import jsonrpcserver
     from jsonrpcserver import dispatch, Success, Error
-    from jsonrpcserver import method as jsonrpc_method # Use this decorator
+    from jsonrpcserver import method as jsonrpc_method  # Use this decorator
 except ImportError as e:
     logger.error(f"Failed to import JSON-RPC components: {e}")
     logger.info("Please install required dependencies with: pip install jsonrpcserver")
     sys.exit(1)
 
+
 # --- Dynamic Imports Check ---
 def check_module_availability():
     global VFS_AVAILABLE, FS_JOURNAL_AVAILABLE
     global IPFS_FS_BRIDGE_AVAILABLE, MULTI_BACKEND_FS_AVAILABLE
 
     try:
         import mcp_vfs_config
+
         VFS_AVAILABLE = True
         logger.info("✅ Virtual filesystem module available (mcp_vfs_config)")
     except ImportError:
         logger.warning("⚠️ mcp_vfs_config module not available")
 
     try:
         import fs_journal_tools
+
         FS_JOURNAL_AVAILABLE = True
         logger.info("✅ Filesystem journal module available (fs_journal_tools)")
     except ImportError:
         logger.warning("⚠️ fs_journal_tools module not available")
 
     try:
         import ipfs_mcp_fs_integration
+
         IPFS_FS_BRIDGE_AVAILABLE = True
         logger.info("✅ IPFS-FS bridge module available (ipfs_mcp_fs_integration)")
     except ImportError:
         logger.warning("⚠️ ipfs_mcp_fs_integration module not available")
 
     try:
         import multi_backend_fs_integration
+
         MULTI_BACKEND_FS_AVAILABLE = True
-        logger.info("✅ Multi-backend filesystem module available (multi_backend_fs_integration)")
+        logger.info(
+            "✅ Multi-backend filesystem module available (multi_backend_fs_integration)"
+        )
     except ImportError:
         logger.warning("⚠️ multi_backend_fs_integration module not available")
 
     try:
         import integrate_vfs_to_final_mcp
+
         logger.info("✅ VFS integration module available (integrate_vfs_to_final_mcp)")
     except ImportError:
         logger.warning("⚠️ integrate_vfs_to_final_mcp module not available")
+
 
 # --- MCP Server Class Definition ---
 class MCPServer:
     def __init__(self):
         self.tools = {}
         self.resources = {}
         self.tool_descriptions = {}
         self.parameter_descriptions = {}
 
-    def tool(self, name: str, description: str = "", parameter_descriptions: Optional[Dict[str, str]] = None):
+    def tool(
+        self,
+        name: str,
+        description: str = "",
+        parameter_descriptions: Optional[Dict[str, str]] = None,
+    ):
         def decorator(func):
             self.register_tool(name, func, description, parameter_descriptions)
             return func
+
         return decorator
 
-    def register_tool(self, name: str, func: Callable, description: str = "", parameter_descriptions: Optional[Dict[str, Any]] = None):
+    def register_tool(
+        self,
+        name: str,
+        func: Callable,
+        description: str = "",
+        parameter_descriptions: Optional[Dict[str, Any]] = None,
+    ):
         """Register a tool with the server"""
         if name in self.tools:
             logger.warning(f"Tool {name} already registered, overwriting")
 
         # Store the tool
@@ -191,72 +229,103 @@
             logger.warning(f"Resource {name} already registered, overwriting")
 
         # Store the resource getter
         self.resources[name] = {"description": description, "getter": getter}
 
-    async def execute_tool(self, tool_name: str, arguments: Dict[str, Any] = None, context: Optional[Dict[str, Any]] = None):
+    async def execute_tool(
+        self,
+        tool_name: str,
+        arguments: Dict[str, Any] = None,
+        context: Optional[Dict[str, Any]] = None,
+    ):
         arguments = arguments or {}
         context_obj = SimpleContext(context or {})
-        logger.debug(f"Attempting to execute tool: {tool_name} with arguments: {arguments}")
+        logger.debug(
+            f"Attempting to execute tool: {tool_name} with arguments: {arguments}"
+        )
         if tool_name not in self.tools:
             logger.error(f"Tool {tool_name} not found")
             return {"error": f"Tool {tool_name} not found"}
         tool = self.tools[tool_name]
         try:
             import inspect
+
             if isinstance(tool, dict) and "function" in tool:
                 func = tool["function"]
             else:
                 func = tool  # Tool is the function itself
             sig = inspect.signature(func)
             logger.debug(f"Calling tool function: {tool_name}")
             if "ctx" in sig.parameters or "context" in sig.parameters:
                 logger.debug(f"Executing tool {tool_name} with context object.")
-                result = await func(context_obj, **arguments) if asyncio.iscoroutinefunction(func) else func(context_obj, **arguments)
+                result = (
+                    await func(context_obj, **arguments)
+                    if asyncio.iscoroutinefunction(func)
+                    else func(context_obj, **arguments)
+                )
             else:
                 logger.debug(f"Executing tool {tool_name} without context object.")
-                result = await func(**arguments) if asyncio.iscoroutinefunction(func) else func(**arguments)
+                result = (
+                    await func(**arguments)
+                    if asyncio.iscoroutinefunction(func)
+                    else func(**arguments)
+                )
             logger.debug(f"Tool function {tool_name} returned.")
-            logger.debug(f"Tool {tool_name} execution completed. Result type: {type(result)}")
+            logger.debug(
+                f"Tool {tool_name} execution completed. Result type: {type(result)}"
+            )
             return result
         except Exception as e:
-            logger.error(f"Error executing tool {tool_name}: {e}\n{traceback.format_exc()}")
+            logger.error(
+                f"Error executing tool {tool_name}: {e}\n{traceback.format_exc()}"
+            )
             return {"error": str(e)}
 
+
 class SimpleContext:
-    def __init__(self, data: Optional[Dict[str, Any]] = None): 
+    def __init__(self, data: Optional[Dict[str, Any]] = None):
         self.data = data or {}
-    async def info(self, message: str): 
+
+    async def info(self, message: str):
         logger.info(message)
-    async def error(self, message: str): 
+
+    async def error(self, message: str):
         logger.error(message)
-    async def warn(self, message: str): 
+
+    async def warn(self, message: str):
         logger.warning(message)
-    async def debug(self, message: str): 
+
+    async def debug(self, message: str):
         logger.debug(message)
+
 
 # --- Tool Registration Functions ---
 def register_hardware_tools(server_instance: MCPServer, accel: Any):
     """Register hardware-related tools."""
+
     # Mock implementation for now
     def get_hardware_info():
         """Get hardware information."""
         logger.info("Executing mock get_hardware_info tool")
         return {
             "cpu": "Mock CPU",
             "gpu": "Mock GPU",
             "memory": "Mock Memory",
             "storage": "Mock Storage",
             "network": "Mock Network",
-            "success": True
+            "success": True,
         }
 
-    server_instance.register_tool("get_hardware_info", get_hardware_info, "Get hardware information")
+    server_instance.register_tool(
+        "get_hardware_info", get_hardware_info, "Get hardware information"
+    )
     logger.info("Registered hardware tools")
+
 
 def register_ipfs_tools(server_instance: MCPServer, accel: Any):
     """Register IPFS-related tools."""
+
     # Example IPFS tool registration (using the accel instance)
     def ipfs_add_file(path: str):
         """Add a file to IPFS."""
         logger.info(f"Executing ipfs_add_file tool for path: {path}")
         try:
@@ -264,17 +333,22 @@
             return result
         except Exception as e:
             logger.error(f"Error in ipfs_add_file: {str(e)}")
             return {"error": str(e), "success": False}
 
-    server_instance.register_tool("ipfs_add_file", ipfs_add_file, "Add a file to IPFS", {
-        "type": "object",
-        "properties": {
-            "path": {"type": "string", "description": "Path to the file to add"}
+    server_instance.register_tool(
+        "ipfs_add_file",
+        ipfs_add_file,
+        "Add a file to IPFS",
+        {
+            "type": "object",
+            "properties": {
+                "path": {"type": "string", "description": "Path to the file to add"}
+            },
+            "required": ["path"],
         },
-        "required": ["path"]
-    })
+    )
 
     def ipfs_cat(cid: str):
         """Get the content of a file from IPFS."""
         logger.info(f"Executing ipfs_cat tool for CID: {cid}")
         try:
@@ -282,17 +356,22 @@
             return result
         except Exception as e:
             logger.error(f"Error in ipfs_cat: {str(e)}")
             return {"error": str(e), "success": False}
 
-    server_instance.register_tool("ipfs_cat", ipfs_cat, "Get the content of a file from IPFS", {
-        "type": "object",
-        "properties": {
-            "cid": {"type": "string", "description": "CID of the file to retrieve"}
+    server_instance.register_tool(
+        "ipfs_cat",
+        ipfs_cat,
+        "Get the content of a file from IPFS",
+        {
+            "type": "object",
+            "properties": {
+                "cid": {"type": "string", "description": "CID of the file to retrieve"}
+            },
+            "required": ["cid"],
         },
-        "required": ["cid"]
-    })
+    )
 
     def ipfs_get(cid: str, output_path: str):
         """Get a file from IPFS and save it to a local path."""
         logger.info(f"Executing ipfs_get tool for CID: {cid} to path: {output_path}")
         try:
@@ -300,42 +379,63 @@
             return result
         except Exception as e:
             logger.error(f"Error in ipfs_get: {str(e)}")
             return {"error": str(e), "success": False}
 
-    server_instance.register_tool("ipfs_get", ipfs_get, "Get a file from IPFS and save it to a local path", {
-        "type": "object",
-        "properties": {
-            "cid": {"type": "string", "description": "CID of the file to retrieve"},
-            "output_path": {"type": "string", "description": "Local path to save the file"}
+    server_instance.register_tool(
+        "ipfs_get",
+        ipfs_get,
+        "Get a file from IPFS and save it to a local path",
+        {
+            "type": "object",
+            "properties": {
+                "cid": {"type": "string", "description": "CID of the file to retrieve"},
+                "output_path": {
+                    "type": "string",
+                    "description": "Local path to save the file",
+                },
+            },
+            "required": ["cid", "output_path"],
         },
-        "required": ["cid", "output_path"]
-    })
+    )
 
     logger.info("Registered IPFS tools")
+
 
 def register_model_tools(server_instance: MCPServer, accel: Any):
     """Register model-related tools."""
+
     # Mock implementation for now
     def process_data(model_name: str, input_data: Any):
         """Process data using a model."""
         logger.info(f"Executing mock process_data tool for model: {model_name}")
         return {
             "model": model_name,
             "input": str(input_data)[:100] if input_data else "",
             "output": "This is a mock response from the model.",
-            "status": "success"
+            "status": "success",
         }
 
-    server_instance.register_tool("process_data", process_data, "Process data using a model", {
-        "type": "object",
-        "properties": {
-            "model_name": {"type": "string", "description": "Name of the model to use"},
-            "input_data": {"type": "any", "description": "Input data for the model"}
+    server_instance.register_tool(
+        "process_data",
+        process_data,
+        "Process data using a model",
+        {
+            "type": "object",
+            "properties": {
+                "model_name": {
+                    "type": "string",
+                    "description": "Name of the model to use",
+                },
+                "input_data": {
+                    "type": "any",
+                    "description": "Input data for the model",
+                },
+            },
+            "required": ["model_name", "input_data"],
         },
-        "required": ["model_name", "input_data"]
-    })
+    )
 
     async def init_endpoints(models: List[str]) -> Dict[str, Any]:
         """Initialize endpoints for models."""
         try:
             logger.info(f"Executing init_endpoints tool for models: {models}")
@@ -344,65 +444,93 @@
             return result
         except Exception as e:
             logger.error(f"Error in init_endpoints: {str(e)}")
             return {"error": str(e)}
 
-    server_instance.register_tool("init_endpoints", init_endpoints, "Initialize endpoints for models", {
-        "type": "object",
-        "properties": {
-            "models": {"type": "array", "items": {"type": "string"}, "description": "List of models to initialize"}
+    server_instance.register_tool(
+        "init_endpoints",
+        init_endpoints,
+        "Initialize endpoints for models",
+        {
+            "type": "object",
+            "properties": {
+                "models": {
+                    "type": "array",
+                    "items": {"type": "string"},
+                    "description": "List of models to initialize",
+                }
+            },
+            "required": ["models"],
         },
-        "required": ["models"]
-    })
+    )
 
     logger.info("Registered model tools")
+
 
 def register_modular_tools(server_instance: MCPServer, accel: Any):
     """Register Modular/MAX/Mojo-related tools."""
-    
-    async def compile_to_mojo(model_id: str, optimization_level: str = "O2") -> Dict[str, Any]:
+
+    async def compile_to_mojo(
+        model_id: str, optimization_level: str = "O2"
+    ) -> Dict[str, Any]:
         """Compile model to Mojo for maximum performance."""
-        logger.info(f"Compiling {model_id} to Mojo with optimization {optimization_level}")
+        logger.info(
+            f"Compiling {model_id} to Mojo with optimization {optimization_level}"
+        )
         try:
             # Mock implementation for now - will be replaced with actual Mojo compilation
             result = {
                 "model_id": model_id,
                 "optimization_level": optimization_level,
                 "status": "compilation_started",
                 "compiled_path": f"mock_mojo_{model_id}.bin",
                 "compilation_time": 45.2,
-                "optimization_applied": ["vectorization", "loop_unrolling", "simd_optimization"],
-                "success": True
+                "optimization_applied": [
+                    "vectorization",
+                    "loop_unrolling",
+                    "simd_optimization",
+                ],
+                "success": True,
             }
             logger.info(f"Mock Mojo compilation initiated for {model_id}")
             return result
         except Exception as e:
             logger.error(f"Mojo compilation failed: {e}")
             return {"error": str(e), "success": False}
-    
-    async def compile_to_max(model_id: str, target_device: str = "auto") -> Dict[str, Any]:
+
+    async def compile_to_max(
+        model_id: str, target_device: str = "auto"
+    ) -> Dict[str, Any]:
         """Compile model to MAX intermediate representation."""
-        logger.info(f"Executing compile_to_max tool for model: {model_id} on device: {target_device}")
+        logger.info(
+            f"Executing compile_to_max tool for model: {model_id} on device: {target_device}"
+        )
         try:
             # Mock implementation for now
             # In a real scenario, this would involve calling MAX compilation tools
             result = {
                 "model_id": model_id,
                 "target_device": target_device,
                 "status": "compilation_started",
                 "output_ir": f"mock_max_ir_{model_id}.max",
-                "graph_optimizations": ["operator_fusion", "memory_layout_optimization", "constant_folding"],
+                "graph_optimizations": [
+                    "operator_fusion",
+                    "memory_layout_optimization",
+                    "constant_folding",
+                ],
                 "estimated_speedup": "2.3x",
-                "success": True
+                "success": True,
             }
             logger.info(f"Mock MAX compilation initiated for {model_id}")
             return result
         except Exception as e:
             logger.error(f"Error compiling to MAX: {str(e)}")
             return {"error": str(e), "success": False}
 
-    async def deploy_max_engine(model_id: str, target_hardware: str = "auto") -> Dict[str, Any]:
+    async def deploy_max_engine(
+        model_id: str, target_hardware: str = "auto"
+    ) -> Dict[str, Any]:
         """Deploy model using MAX Engine for optimized inference."""
         logger.info(f"Deploying {model_id} on MAX Engine targeting {target_hardware}")
         try:
             # Mock implementation for now
             result = {
@@ -411,72 +539,74 @@
                 "status": "serving_started",
                 "endpoint_url": f"http://localhost:8000/v1/models/{model_id}/infer",
                 "serving_backend": "max_engine",
                 "allocated_memory_mb": 2048,
                 "concurrent_requests": 8,
-                "success": True
+                "success": True,
             }
             logger.info(f"Mock MAX Engine deployment initiated for {model_id}")
             return result
         except Exception as e:
             logger.error(f"MAX deployment failed: {e}")
             return {"error": str(e), "success": False}
 
     async def serve_max_model(model_id: str, port: int = 8000) -> Dict[str, Any]:
         """Serve a MAX model via an OpenAI-compatible endpoint."""
-        logger.info(f"Executing serve_max_model tool for model: {model_id} on port: {port}")
+        logger.info(
+            f"Executing serve_max_model tool for model: {model_id} on port: {port}"
+        )
         try:
             # Mock implementation for now
             # In a real scenario, this would involve starting a MAX serving process
             result = {
                 "model_id": model_id,
                 "port": port,
                 "status": "serving_started",
                 "endpoint_url": f"http://localhost:{port}/v1/chat/completions",
                 "openai_compatible": True,
                 "max_concurrent_requests": 16,
-                "success": True
+                "success": True,
             }
             logger.info(f"Mock MAX serving initiated for {model_id} on port {port}")
             return result
         except Exception as e:
             logger.error(f"Error serving MAX model: {str(e)}")
             return {"error": str(e), "success": False}
-    
-    async def benchmark_modular_performance(model_id: str, workload_type: str = "inference") -> Dict[str, Any]:
+
+    async def benchmark_modular_performance(
+        model_id: str, workload_type: str = "inference"
+    ) -> Dict[str, Any]:
         """Benchmark model performance on Modular hardware."""
         logger.info(f"Benchmarking {model_id} for {workload_type} on Modular hardware")
         try:
             # Mock implementation for now
             result = {
                 "model_id": model_id,
                 "workload_type": workload_type,
                 "benchmark_results": {
                     "throughput_tokens_per_sec": 1250.5,
-                    "latency_ms": {
-                        "p50": 12.3,
-                        "p95": 18.7,
-                        "p99": 25.1
-                    },
+                    "latency_ms": {"p50": 12.3, "p95": 18.7, "p99": 25.1},
                     "memory_usage_mb": 1024,
                     "energy_consumption_watts": 45.2,
-                    "compute_utilization_percent": 87.5
+                    "compute_utilization_percent": 87.5,
                 },
                 "comparison_vs_baseline": {
                     "speedup": "2.1x",
                     "memory_reduction": "35%",
-                    "energy_efficiency": "40% better"
-                },
-                "success": True
+                    "energy_efficiency": "40% better",
+                },
+                "success": True,
             }
             logger.info(f"Mock Modular benchmarking completed for {model_id}")
             return result
         except Exception as e:
             logger.error(f"Modular benchmarking failed: {e}")
             return {"error": str(e), "success": False}
-    
-    async def detect_modular_hardware(include_capabilities: bool = True) -> Dict[str, Any]:
+
+    async def detect_modular_hardware(
+        include_capabilities: bool = True,
+    ) -> Dict[str, Any]:
         """Detect available Modular hardware and capabilities."""
         logger.info("Detecting Modular hardware capabilities")
         try:
             # Mock implementation for now
             result = {
@@ -487,93 +617,162 @@
                     {
                         "type": "cpu",
                         "name": "Intel Xeon E5-2690 v4",
                         "cores": 16,
                         "simd_width": 8,
-                        "supported_dtypes": ["float32", "float16", "int8"]
+                        "supported_dtypes": ["float32", "float16", "int8"],
                     },
                     {
-                        "type": "gpu", 
+                        "type": "gpu",
                         "name": "NVIDIA A100",
                         "memory_gb": 80,
                         "compute_capability": "8.0",
-                        "supported_dtypes": ["float32", "float16", "bfloat16", "int8", "int4"]
+                        "supported_dtypes": [
+                            "float32",
+                            "float16",
+                            "bfloat16",
+                            "int8",
+                            "int4",
+                        ],
+                    },
+                ],
+                "capabilities": (
+                    {
+                        "vectorization": True,
+                        "graph_optimization": True,
+                        "kernel_fusion": True,
+                        "mixed_precision": True,
+                        "dynamic_batching": True,
                     }
-                ],
-                "capabilities": {
-                    "vectorization": True,
-                    "graph_optimization": True,
-                    "kernel_fusion": True,
-                    "mixed_precision": True,
-                    "dynamic_batching": True
-                } if include_capabilities else {},
-                "success": True
+                    if include_capabilities
+                    else {}
+                ),
+                "success": True,
             }
             logger.info("Mock Modular hardware detection completed")
             return result
         except Exception as e:
             logger.error(f"Hardware detection failed: {e}")
             return {"error": str(e), "success": False}
 
     # Register tools with proper schemas
-    server_instance.register_tool("compile_to_mojo", compile_to_mojo, 
-        "Compile model to Mojo for maximum performance", {
+    server_instance.register_tool(
+        "compile_to_mojo",
+        compile_to_mojo,
+        "Compile model to Mojo for maximum performance",
+        {
             "type": "object",
             "properties": {
                 "model_id": {"type": "string", "description": "Model identifier"},
-                "optimization_level": {"type": "string", "enum": ["O0", "O1", "O2", "O3"], "default": "O2", "description": "Optimization level (O0=none, O1=basic, O2=default, O3=aggressive)"}
+                "optimization_level": {
+                    "type": "string",
+                    "enum": ["O0", "O1", "O2", "O3"],
+                    "default": "O2",
+                    "description": "Optimization level (O0=none, O1=basic, O2=default, O3=aggressive)",
+                },
             },
-            "required": ["model_id"]
-        })
-
-    server_instance.register_tool("compile_to_max", compile_to_max, "Compile model to MAX intermediate representation", {
-        "type": "object",
-        "properties": {
-            "model_id": {"type": "string", "description": "ID of the model to compile"},
-            "target_device": {"type": "string", "description": "Target device for compilation (e.g., 'cpu', 'gpu', 'auto')", "default": "auto"}
+            "required": ["model_id"],
         },
-        "required": ["model_id"]
-    })
-    
-    server_instance.register_tool("deploy_max_engine", deploy_max_engine,
-        "Deploy model using MAX Engine for optimized inference", {
-            "type": "object", 
+    )
+
+    server_instance.register_tool(
+        "compile_to_max",
+        compile_to_max,
+        "Compile model to MAX intermediate representation",
+        {
+            "type": "object",
             "properties": {
-                "model_id": {"type": "string", "description": "Model identifier"},
-                "target_hardware": {"type": "string", "description": "Target hardware (cpu, gpu, auto)", "default": "auto"}
+                "model_id": {
+                    "type": "string",
+                    "description": "ID of the model to compile",
+                },
+                "target_device": {
+                    "type": "string",
+                    "description": "Target device for compilation (e.g., 'cpu', 'gpu', 'auto')",
+                    "default": "auto",
+                },
             },
-            "required": ["model_id"]
-        })
-
-    server_instance.register_tool("serve_max_model", serve_max_model, "Serve a MAX model via an OpenAI-compatible endpoint", {
-        "type": "object",
-        "properties": {
-            "model_id": {"type": "string", "description": "ID of the MAX model to serve"},
-            "port": {"type": "integer", "description": "Port to serve the model on", "default": 8000}
+            "required": ["model_id"],
         },
-        "required": ["model_id"]
-    })
-    
-    server_instance.register_tool("benchmark_modular_performance", benchmark_modular_performance,
-        "Benchmark model performance on Modular hardware", {
+    )
+
+    server_instance.register_tool(
+        "deploy_max_engine",
+        deploy_max_engine,
+        "Deploy model using MAX Engine for optimized inference",
+        {
             "type": "object",
             "properties": {
                 "model_id": {"type": "string", "description": "Model identifier"},
-                "workload_type": {"type": "string", "enum": ["inference", "training", "mixed"], "default": "inference", "description": "Type of workload to benchmark"}
+                "target_hardware": {
+                    "type": "string",
+                    "description": "Target hardware (cpu, gpu, auto)",
+                    "default": "auto",
+                },
             },
-            "required": ["model_id"]
-        })
-    
-    server_instance.register_tool("detect_modular_hardware", detect_modular_hardware,
-        "Detect available Modular hardware and capabilities", {
+            "required": ["model_id"],
+        },
+    )
+
+    server_instance.register_tool(
+        "serve_max_model",
+        serve_max_model,
+        "Serve a MAX model via an OpenAI-compatible endpoint",
+        {
             "type": "object",
             "properties": {
-                "include_capabilities": {"type": "boolean", "default": True, "description": "Include detailed capability information"}
-            }
-        })
-    
+                "model_id": {
+                    "type": "string",
+                    "description": "ID of the MAX model to serve",
+                },
+                "port": {
+                    "type": "integer",
+                    "description": "Port to serve the model on",
+                    "default": 8000,
+                },
+            },
+            "required": ["model_id"],
+        },
+    )
+
+    server_instance.register_tool(
+        "benchmark_modular_performance",
+        benchmark_modular_performance,
+        "Benchmark model performance on Modular hardware",
+        {
+            "type": "object",
+            "properties": {
+                "model_id": {"type": "string", "description": "Model identifier"},
+                "workload_type": {
+                    "type": "string",
+                    "enum": ["inference", "training", "mixed"],
+                    "default": "inference",
+                    "description": "Type of workload to benchmark",
+                },
+            },
+            "required": ["model_id"],
+        },
+    )
+
+    server_instance.register_tool(
+        "detect_modular_hardware",
+        detect_modular_hardware,
+        "Detect available Modular hardware and capabilities",
+        {
+            "type": "object",
+            "properties": {
+                "include_capabilities": {
+                    "type": "boolean",
+                    "default": True,
+                    "description": "Include detailed capability information",
+                }
+            },
+        },
+    )
+
     logger.info("Registered Modular/MAX/Mojo tools")
+
 
 def register_vfs_tools(server_instance: MCPServer, accel: Any):
     """Register virtual filesystem tools."""
     # These are basic implementations since we don't have the actual VFS implementation
 
@@ -583,24 +782,33 @@
         try:
             # Mock implementation
             return {
                 "path": path,
                 "items": ["file1.txt", "file2.txt", "dir1/"],
-                "success": True
+                "success": True,
             }
         except Exception as e:
             logger.error(f"Error in vfs_list: {str(e)}")
             return {"error": str(e), "success": False}
 
-    server_instance.register_tool("vfs_list", vfs_list, "List items in the virtual filesystem", {
-        "type": "object",
-        "properties": {
-            "path": {"type": "string", "description": "Path in the virtual filesystem"}
-        }
-    })
+    server_instance.register_tool(
+        "vfs_list",
+        vfs_list,
+        "List items in the virtual filesystem",
+        {
+            "type": "object",
+            "properties": {
+                "path": {
+                    "type": "string",
+                    "description": "Path in the virtual filesystem",
+                }
+            },
+        },
+    )
 
     logger.info("Registered VFS tools")
+
 
 def register_storage_tools(server_instance: MCPServer, accel: Any):
     """Register storage-related tools."""
     # These are basic implementations since we don't have the actual storage implementation
 
@@ -611,76 +819,98 @@
             # Mock implementation
             return {
                 "name": name,
                 "size": size,
                 "id": f"storage-{name}-{size}",
-                "success": True
+                "success": True,
             }
         except Exception as e:
             logger.error(f"Error in create_storage: {str(e)}")
             return {"error": str(e), "success": False}
 
-    server_instance.register_tool("create_storage", create_storage, "Create a new storage volume", {
-        "type": "object",
-        "properties": {
-            "name": {"type": "string", "description": "Name of the storage volume"},
-            "size": {"type": "number", "description": "Size of the storage volume in GB"}
+    server_instance.register_tool(
+        "create_storage",
+        create_storage,
+        "Create a new storage volume",
+        {
+            "type": "object",
+            "properties": {
+                "name": {"type": "string", "description": "Name of the storage volume"},
+                "size": {
+                    "type": "number",
+                    "description": "Size of the storage volume in GB",
+                },
+            },
+            "required": ["name", "size"],
         },
-        "required": ["name", "size"]
-    })
+    )
 
     logger.info("Registered storage tools")
+
 
 def register_all_tools(server_instance: MCPServer, accel: Any):
     """Register all available tools with the server instance."""
     logger.info("Registering all tools...")
     try:
         register_hardware_tools(server_instance, accel)
         register_ipfs_tools(server_instance, accel)
         register_model_tools(server_instance, accel)
-        register_modular_tools(server_instance, accel) # Call the new Modular/MAX/Mojo tool registration
+        register_modular_tools(
+            server_instance, accel
+        )  # Call the new Modular/MAX/Mojo tool registration
         register_vfs_tools(server_instance, accel)
         register_storage_tools(server_instance, accel)
         logger.info(f"Total tools registered: {len(server_instance.tools)}")
         return True
     except Exception as e:
         logger.error(f"Error during tool registration: {e}\n{traceback.format_exc()}")
         return False
 
+
 # --- End Tool Registration Functions ---
 
 
 from contextlib import asynccontextmanager
+
 
 @asynccontextmanager
 async def lifespan(app_instance: FastAPI):
     # Startup code
     logger.info("MCP Server startup_event triggered in lifespan.")
     check_module_availability()
     if not setup_jsonrpc():
-        logger.critical("CRITICAL: Failed to set up JSON-RPC methods. Server may not function correctly.")
-    
+        logger.critical(
+            "CRITICAL: Failed to set up JSON-RPC methods. Server may not function correctly."
+        )
+
     # Import IPFS Accelerate module (or mock)
     accel = import_ipfs_accelerate_py()
 
-    if not register_all_tools(server, accel): # Pass server instance and accel
-        logger.critical("CRITICAL: Failed to register tools. Server will have limited functionality.")
-    
+    if not register_all_tools(server, accel):  # Pass server instance and accel
+        logger.critical(
+            "CRITICAL: Failed to register tools. Server will have limited functionality."
+        )
+
     logger.info("MCP Server initialization sequence complete.")
 
     # Add routes programmatically after tools are registered
     app_instance.add_api_route("/", root, methods=["GET"])
     app_instance.add_api_route("/health", health, methods=["GET"])
     app_instance.add_api_route("/jsonrpc", jsonrpc_endpoint, methods=["POST"])
     app_instance.add_api_route("/initialize", initialize_endpoint, methods=["POST"])
     app_instance.add_api_route("/mcp/manifest", get_mcp_manifest, methods=["GET"])
     app_instance.add_api_route("/tools", list_tools_endpoint, methods=["GET"])
-    app_instance.add_api_route("/tools-with-metadata", list_tools_with_metadata_endpoint, methods=["GET"])
-    app_instance.add_api_route("/tools/{tool_name}", execute_tool_endpoint, methods=["POST"])
+    app_instance.add_api_route(
+        "/tools-with-metadata", list_tools_with_metadata_endpoint, methods=["GET"]
+    )
+    app_instance.add_api_route(
+        "/tools/{tool_name}", execute_tool_endpoint, methods=["POST"]
+    )
 
     yield
     # Shutdown code here
+
 
 # Define and initialize app globally
 app = FastAPI(lifespan=lifespan)
 
 
@@ -690,249 +920,248 @@
 
 def handle_sigterm(signum, frame):
     logger.info("Received SIGTERM, shutting down")
     sys.exit(0)
 
+
 def handle_sigint(signum, frame):
     logger.info("Received SIGINT, shutting down")
     sys.exit(0)
+
 
 def handle_timeout():
     """Handle server timeout by gracefully shutting down."""
     logger.info("Server timeout reached, shutting down gracefully")
     sys.exit(0)
+
 
 def setup_timeout(timeout_seconds):
     """Setup a timeout timer that will shutdown the server after specified seconds."""
     if timeout_seconds > 0:
         logger.info(f"Setting up auto-shutdown timeout for {timeout_seconds} seconds")
         import threading
+
         timer = threading.Timer(timeout_seconds, handle_timeout)
         timer.daemon = True
         timer.start()
         return timer
     return None
 
+
 server = MCPServer()
+
 
 # Import from the ipfs_accelerate_py module
 class IPFSAccelerateBridge:
     """Bridge adapter to provide consistent interface for IPFS operations."""
-    
+
     def __init__(self, real_instance=None):
         self.real_instance = real_instance
         self.files = {}  # For mock storage
-    
+
     def add_file(self, path):
         """Add a file to IPFS."""
         if not path:
             return {"error": "Path is required", "success": False}
-        
+
         if not os.path.exists(path):
             return {"error": "File not found", "success": False}
-        
+
         try:
             with open(path, "rb") as f:
                 content = f.read()
                 # Create a mock CID using a short hash of the content
                 hash_obj = hashlib.sha256(content)
                 cid = f"QmPy{hash_obj.hexdigest()[:16]}"
-                
+
                 # Store the file content
                 self.files[cid] = content
-                
-                return {
-                    "cid": cid,
-                    "size": len(content),
-                    "path": path,
-                    "success": True
-                }
+
+                return {"cid": cid, "size": len(content), "path": path, "success": True}
         except Exception as e:
             return {"error": str(e), "success": False}
-    
+
     def cat(self, cid):
         """Retrieve content from IPFS."""
         if not cid:
             return {"error": "CID is required", "success": False}
-        
+
         if cid in self.files:
             content = self.files[cid]
             try:
                 # Try to decode as text
-                text_content = content.decode('utf-8')
-                return {
-                    "content": text_content,
-                    "cid": cid,
-                    "success": True
-                }
+                text_content = content.decode("utf-8")
+                return {"content": text_content, "cid": cid, "success": True}
             except UnicodeDecodeError:
                 # Return binary content info
                 return {
                     "content": f"<Binary content: {len(content)} bytes>",
                     "cid": cid,
                     "success": True,
-                    "binary": True
+                    "binary": True,
                 }
         else:
             return {"error": f"CID {cid} not found", "success": False}
-    
+
     def get(self, cid, output_path):
         """Get a file from IPFS and save to output path."""
         if not cid:
             return {"error": "CID is required", "success": False}
-        
+
         if not output_path:
             return {"error": "Output path is required", "success": False}
-        
+
         if cid in self.files:
             try:
                 content = self.files[cid]
                 with open(output_path, "wb") as f:
                     f.write(content)
-                
+
                 return {
                     "cid": cid,
                     "output_path": output_path,
                     "size": len(content),
-                    "success": True
+                    "success": True,
                 }
             except Exception as e:
                 return {"error": str(e), "success": False}
         else:
             return {"error": f"CID {cid} not found", "success": False}
 
+
 def import_ipfs_accelerate_py():
     """Import the IPFS Accelerate Python module and wrap in bridge."""
     try:
         sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
         from ipfs_accelerate_py import ipfs_accelerate_py
+
         logger.info("Imported ipfs_accelerate_py")
         real_instance = ipfs_accelerate_py()
         # Wrap the real instance in our bridge
         return IPFSAccelerateBridge(real_instance)
     except ImportError:
         logger.warning("Failed to import ipfs_accelerate_py directly")
-    
+
     # Try alternative methods if direct import fails
     try:
         # Try to find the module in the local directory
         module_path = os.path.join(os.path.dirname(__file__), "ipfs_accelerate_py.py")
         if os.path.exists(module_path):
-            spec = importlib.util.spec_from_file_location("ipfs_accelerate_py", module_path)
+            spec = importlib.util.spec_from_file_location(
+                "ipfs_accelerate_py", module_path
+            )
             module = importlib.util.module_from_spec(spec)
             spec.loader.exec_module(module)
             logger.info("Imported ipfs_accelerate_py from local file")
             real_instance = module.ipfs_accelerate_py()
             # Wrap the real instance in our bridge
             return IPFSAccelerateBridge(real_instance)
     except Exception as e:
         logger.error(f"Failed to import ipfs_accelerate_py: {e}")
-    
+
     # If all fails, return a bridge with no real instance (mock mode)
     logger.warning("Using bridge in mock mode for ipfs_accelerate_py")
     return IPFSAccelerateBridge()
 
+
 class MockIPFSAccelerate:
     """Mock implementation of the IPFS Accelerate class for testing."""
-    
+
     def __init__(self):
         self.files = {}
         self.endpoints = {
             "local_endpoints": {"gpt2": {}, "bert": {}},
             "api_endpoints": {"openai": {}, "huggingface": {}},
-            "libp2p_endpoints": {}
+            "libp2p_endpoints": {},
         }
-    
+
     def add_file(self, path: str) -> Dict[str, Any]:
         """Add a file to IPFS."""
         import hashlib
         import random
-        
+
         try:
             if not os.path.exists(path):
                 return {"error": "File not found", "success": False}
-            
+
             # Generate a mock CID
-            with open(path, 'rb') as f:
+            with open(path, "rb") as f:
                 content = f.read()
                 hash_obj = hashlib.sha256(content)
                 cid = f"QmPy{hash_obj.hexdigest()[:16]}"
-                
+
             # Store the file
-            self.files[cid] = {
-                "path": path,
-                "size": len(content),
-                "content": content
-            }
-            
-            return {
-                "cid": cid,
-                "size": len(content),
-                "path": path,
-                "success": True
-            }
+            self.files[cid] = {"path": path, "size": len(content), "content": content}
+
+            return {"cid": cid, "size": len(content), "path": path, "success": True}
         except Exception as e:
             logger.error(f"Error in ipfs_add_file: {str(e)}")
             return {"error": str(e), "success": False}
-    
+
     def cat(self, cid: str) -> Dict[str, Any]:
         """Get the content of a file from IPFS."""
         if cid not in self.files:
             return {"error": "CID not found", "success": False}
-        
+
         return {
-            "content": self.files[cid]["content"].decode('utf-8', errors='replace'),
+            "content": self.files[cid]["content"].decode("utf-8", errors="replace"),
             "size": self.files[cid]["size"],
-            "success": True
+            "success": True,
         }
-    
+
     def get(self, cid: str, output_path: str) -> Dict[str, Any]:
         """Get a file from IPFS and save it to a local path."""
         if cid not in self.files:
             return {"error": "CID not found", "success": False}
-        
-        try:
-            with open(output_path, 'wb') as f:
+
+        try:
+            with open(output_path, "wb") as f:
                 f.write(self.files[cid]["content"])
-            
+
             return {
                 "path": output_path,
                 "size": self.files[cid]["size"],
-                "success": True
+                "success": True,
             }
         except Exception as e:
             logger.error(f"Error in ipfs_get: {str(e)}")
             return {"error": str(e), "success": False}
-    
-    def process(self, model_name: str, input_data: Any, endpoint_type: Optional[str] = None) -> Dict[str, Any]:
+
+    def process(
+        self, model_name: str, input_data: Any, endpoint_type: Optional[str] = None
+    ) -> Dict[str, Any]:
         """Process data using a model."""
         return {
             "model": model_name,
             "input": str(input_data)[:100] if input_data else "",
             "endpoint_type": endpoint_type,
             "output": "This is a mock response from the model.",
-            "status": "success"
+            "status": "success",
         }
-    
+
     async def init_endpoints(self, models: List[str]) -> Dict[str, Any]:
         """Initialize endpoints for models."""
         try:
             # Mock implementation for endpoint initialization
             result = {
                 "models": models,
                 "endpoints_initialized": len(models),
-                "local_endpoints": {model: f"http://localhost:800{i}" for i, model in enumerate(models, 1)},
+                "local_endpoints": {
+                    model: f"http://localhost:800{i}"
+                    for i, model in enumerate(models, 1)
+                },
                 "status": "initialized",
-                "success": True
+                "success": True,
             }
             logger.info(f"Mock endpoints initialized for models: {models}")
             return result
         except Exception as e:
             logger.error(f"Error in init_endpoints: {str(e)}")
             return {"error": str(e), "success": False}
-    
+
     logger.info("Registered model tools")
+
 
 # --- End Tool Registration Functions ---
 
 
 def setup_jsonrpc():
@@ -954,65 +1183,88 @@
         try:
             parsed_req = json.loads(request_text)
             method = parsed_req.get("method")
             req_id = parsed_req.get("id")
             params = parsed_req.get("params", {})
-            logger.debug(f"JSON-RPC method: {method}, id: {req_id}, params: {params}") # Added logging
+            logger.debug(
+                f"JSON-RPC method: {method}, id: {req_id}, params: {params}"
+            )  # Added logging
         except json.JSONDecodeError:
             logger.error(f"Invalid JSON in request: {request_text}")
             return JSONResponse(
-                content={"jsonrpc": "2.0", "error": {"code": -32700, "message": "Parse error"}, "id": None},
-                status_code=400
+                content={
+                    "jsonrpc": "2.0",
+                    "error": {"code": -32700, "message": "Parse error"},
+                    "id": None,
+                },
+                status_code=400,
             )
 
         # Special handling for common methods
         if method == "ping":
             # Direct handling for ping to ensure consistent and fast response
             return JSONResponse(
                 content={"jsonrpc": "2.0", "result": "pong", "id": req_id},
-                status_code=200
+                status_code=200,
             )
         elif method == "get_tools" or method == "list_tools" or method == "tools/list":
-        # Direct handling for get_tools, list_tools, and tools/list (aliases)
+            # Direct handling for get_tools, list_tools, and tools/list (aliases)
             # Return a flat array of tools for VS Code compatibility
             tool_list = []
             for name, tool in server.tools.items():
                 # Check if tool is a dictionary with description and parameters
-                if isinstance(tool, dict) and "description" in tool and "parameters" in tool:
-                     tool_list.append({"name": name, "description": tool["description"], "parameters": tool["parameters"]})
+                if (
+                    isinstance(tool, dict)
+                    and "description" in tool
+                    and "parameters" in tool
+                ):
+                    tool_list.append(
+                        {
+                            "name": name,
+                            "description": tool["description"],
+                            "parameters": tool["parameters"],
+                        }
+                    )
                 # Check if tool is a function and get info from server attributes
                 elif callable(tool):
                     description = server.tool_descriptions.get(name, "")
                     parameters = server.parameter_descriptions.get(name, {})
-                    tool_list.append({"name": name, "description": description, "parameters": parameters})
+                    tool_list.append(
+                        {
+                            "name": name,
+                            "description": description,
+                            "parameters": parameters,
+                        }
+                    )
                 else:
                     logger.warning(f"Tool '{name}' has unexpected format: {type(tool)}")
 
-
             return JSONResponse(
                 content={"jsonrpc": "2.0", "result": tool_list, "id": req_id},
-                status_code=200
+                status_code=200,
             )
         elif method == "get_server_info":
             # Direct handling for get_server_info
             uptime = datetime.now() - server_start_time
             info = {
                 "version": __version__,
                 "uptime_seconds": uptime.total_seconds(),
                 "port": PORT,
                 "registered_tools": len(server.tools),
-                "registered_tool_categories": list(registered_tool_categories)
+                "registered_tool_categories": list(registered_tool_categories),
             }
             return JSONResponse(
                 content={"jsonrpc": "2.0", "result": info, "id": req_id},
-                status_code=200
+                status_code=200,
             )
         elif method == "initialize":
             # Special handling for initialize
             global server_initialized
             client_info = params.get("clientInfo", {})
-            logger.info(f"Received HTTP initialize request: {client_info}") # Log as HTTP initialize for clarity
+            logger.info(
+                f"Received HTTP initialize request: {client_info}"
+            )  # Log as HTTP initialize for clarity
 
             # Mark server as initialized
             server_initialized = True
             initialization_event.set()
 
@@ -1027,66 +1279,90 @@
                         "capabilities": {
                             "streaming": True,
                             "jsonrpc": True,
                             "tools": True,
                             "completion": False,
-                            "chat": False
-                        }
+                            "chat": False,
+                        },
                     },
-                    "id": req_id
-                },
-                status_code=200
+                    "id": req_id,
+                },
+                status_code=200,
             )
         elif method == "use_tool":
             # Special handling for use_tool since it's asynchronous
             try:
                 tool_name = params.get("tool_name")
                 arguments = params.get("arguments", {})
                 context = params.get("context", {})
 
                 if not tool_name:
                     return JSONResponse(
-                        content={"jsonrpc": "2.0", "error": {"code": -32602, "message": "Invalid params: tool_name is required"}, "id": req_id},
-                        status_code=400
+                        content={
+                            "jsonrpc": "2.0",
+                            "error": {
+                                "code": -32602,
+                                "message": "Invalid params: tool_name is required",
+                            },
+                            "id": req_id,
+                        },
+                        status_code=400,
                     )
 
                 # Execute the tool
                 result = await server.execute_tool(tool_name, arguments, context)
                 return JSONResponse(
                     content={"jsonrpc": "2.0", "result": result, "id": req_id},
-                    status_code=200
+                    status_code=200,
                 )
             except Exception as e:
                 logger.error(f"Error executing tool {tool_name}: {e}")
                 return JSONResponse(
-                    content={"jsonrpc": "2.0", "error": {"code": -32603, "message": f"Tool execution error: {str(e)}"}, "id": req_id},
-                    status_code=500
+                    content={
+                        "jsonrpc": "2.0",
+                        "error": {
+                            "code": -32603,
+                            "message": f"Tool execution error: {str(e)}",
+                        },
+                        "id": req_id,
+                    },
+                    status_code=500,
                 )
         elif method == "execute":
             # Direct handling for execute
             tool_name = params.get("name")
             tool_params = params.get("parameters", {})
 
             if not tool_name:
                 return JSONResponse(
-                    content={"jsonrpc": "2.0", "error": {"code": -32602, "message": "Tool name is required"}, "id": req_id},
-                    status_code=400
+                    content={
+                        "jsonrpc": "2.0",
+                        "error": {"code": -32602, "message": "Tool name is required"},
+                        "id": req_id,
+                    },
+                    status_code=400,
                 )
 
             try:
                 # Execute the tool
                 result = await server.execute_tool(tool_name, tool_params)
                 return JSONResponse(
                     content={"jsonrpc": "2.0", "result": result, "id": req_id},
-                    status_code=200
+                    status_code=200,
                 )
             except Exception as e:
-                logger.error(f"Error executing tool {tool_name}: {e}\n{traceback.format_exc()}")
+                logger.error(
+                    f"Error executing tool {tool_name}: {e}\n{traceback.format_exc()}"
+                )
                 return JSONResponse(
-                    content={"jsonrpc": "2.0", "error": {"code": -32603, "message": str(e)}, "id": req_id},
-                    status_code=500
-            )
+                    content={
+                        "jsonrpc": "2.0",
+                        "error": {"code": -32603, "message": str(e)},
+                        "id": req_id,
+                    },
+                    status_code=500,
+                )
 
         # For all other methods, route through server.execute_tool
         try:
             tool_name = method
             arguments = params
@@ -1095,54 +1371,98 @@
             result = await server.execute_tool(tool_name, arguments)
 
             # Wrap the result in a JSON-RPC response format
             return JSONResponse(
                 content={"jsonrpc": "2.0", "result": result, "id": req_id},
-                status_code=200
+                status_code=200,
             )
         except Exception as e:
-            logger.error(f"Error executing tool {method}: {e}\n{traceback.format_exc()}")
+            logger.error(
+                f"Error executing tool {method}: {e}\n{traceback.format_exc()}"
+            )
             return JSONResponse(
-                content={"jsonrpc": "2.0", "error": {"code": -32603, "message": f"Tool execution error: {str(e)}"}, "id": req_id},
-                status_code=500
+                content={
+                    "jsonrpc": "2.0",
+                    "error": {
+                        "code": -32603,
+                        "message": f"Tool execution error: {str(e)}",
+                    },
+                    "id": req_id,
+                },
+                status_code=500,
             )
 
     except json.JSONDecodeError as e:
-        logger.error(f"JSONDecodeError in handle_jsonrpc: {e}. Request body: '{request_text}'")
-        return JSONResponse({"jsonrpc": "2.0", "error": {"code": -32700, "message": "Parse error"}, "id": None}, status_code=400)
+        logger.error(
+            f"JSONDecodeError in handle_jsonrpc: {e}. Request body: '{request_text}'"
+        )
+        return JSONResponse(
+            {
+                "jsonrpc": "2.0",
+                "error": {"code": -32700, "message": "Parse error"},
+                "id": None,
+            },
+            status_code=400,
+        )
     except Exception as e:
-        logger.error(f"Error handling JSON-RPC request in handle_jsonrpc: {e}\n{traceback.format_exc()}")
+        logger.error(
+            f"Error handling JSON-RPC request in handle_jsonrpc: {e}\n{traceback.format_exc()}"
+        )
         req_id = None
         try:
             # Try to parse request_text to get id if it's valid JSON
             if request_text:
                 parsed_req = json.loads(request_text)
                 req_id = parsed_req.get("id")
-        except: # pylint: disable=bare-except
+        except:  # pylint: disable=bare-except
             pass
-        return JSONResponse({"jsonrpc": "2.0", "error": {"code": -32603, "message": f"Internal server error: {str(e)}"}, "id": req_id}, status_code=500)
+        return JSONResponse(
+            {
+                "jsonrpc": "2.0",
+                "error": {
+                    "code": -32603,
+                    "message": f"Internal server error: {str(e)}",
+                },
+                "id": req_id,
+            },
+            status_code=500,
+        )
+
 
 @app.get("/")
-async def root(): return {"message": "MCP Server", "version": __version__, "tools": len(server.tools)}
+async def root():
+    return {"message": "MCP Server", "version": __version__, "tools": len(server.tools)}
+
 
 @app.get("/health")
 async def health():
     uptime = datetime.now() - server_start_time
-    return {"status": "ok", "version": __version__, "uptime_seconds": uptime.total_seconds(),
-            "tools_count": len(server.tools), "registered_tool_categories": list(registered_tool_categories)}
-
-async def jsonrpc_endpoint(request: Request): return await handle_jsonrpc(request)
+    return {
+        "status": "ok",
+        "version": __version__,
+        "uptime_seconds": uptime.total_seconds(),
+        "tools_count": len(server.tools),
+        "registered_tool_categories": list(registered_tool_categories),
+    }
+
+
+async def jsonrpc_endpoint(request: Request):
+    return await handle_jsonrpc(request)
+
 
 async def initialize_endpoint(request: Request):
     """Initialize endpoint for clients that use HTTP instead of JSON-RPC."""
     global server_initialized
 
     try:
         # Parse the request body as JSON if it exists
         client_info = {}
         req_id = None  # Default value for request ID
-        if request.headers.get("content-length") and int(request.headers.get("content-length", "0")) > 0:
+        if (
+            request.headers.get("content-length")
+            and int(request.headers.get("content-length", "0")) > 0
+        ):
             body = await request.json()
             client_info = body.get("clientInfo", body)  # Handle both formats
             req_id = body.get("id")  # Extract ID if present
 
         logger.info(f"Received HTTP initialize request: {client_info}")
@@ -1151,61 +1471,82 @@
         server_initialized = True
         initialization_event.set()
 
         # Return server capabilities
         return JSONResponse(
-                content={
-                    "jsonrpc": "2.0",
-                    "result": {
-                        "server": "final-mcp-server",
-                        "version": __version__,
-                        "supported_models": ["default"],
-                        "capabilities": {
-                            "streaming": True,
-                            "jsonrpc": True,
-                            "tools": True,
-                            "completion": False,
-                            "chat": False
-                        }
+            content={
+                "jsonrpc": "2.0",
+                "result": {
+                    "server": "final-mcp-server",
+                    "version": __version__,
+                    "supported_models": ["default"],
+                    "capabilities": {
+                        "streaming": True,
+                        "jsonrpc": True,
+                        "tools": True,
+                        "completion": False,
+                        "chat": False,
                     },
-                    "id": req_id
-                },
-                status_code=200
-            )
+                },
+                "id": req_id,
+            },
+            status_code=200,
+        )
     except Exception as e:
         logger.error(f"Error in initialize endpoint: {e}\n{traceback.format_exc()}")
-        return JSONResponse(
-            content={"error": str(e)},
-            status_code=500
-        )
+        return JSONResponse(content={"error": str(e)}, status_code=500)
+
 
 async def get_mcp_manifest():
     """Return the MCP manifest."""
     logger.info("Fetching MCP manifest...")
     logger.debug("Starting manifest data construction.")
     manifest_data = {
         "server": "final-mcp-server",
         "version": __version__,
-        "tools": list(server.tools.keys()), # List of tool names
-        "resources": list(server.resources.keys()), # List of resource names
-        "tool_details": [{"name": n, "description": server.tool_descriptions.get(n, ""), "parameters": server.parameter_descriptions.get(n, {})} for n in server.tools.keys()],
-        "resource_details": [{"name": n, "description": r["description"]} for n, r in server.resources.items()],
-        "registered_tool_categories": list(registered_tool_categories)
+        "tools": list(server.tools.keys()),  # List of tool names
+        "resources": list(server.resources.keys()),  # List of resource names
+        "tool_details": [
+            {
+                "name": n,
+                "description": server.tool_descriptions.get(n, ""),
+                "parameters": server.parameter_descriptions.get(n, {}),
+            }
+            for n in server.tools.keys()
+        ],
+        "resource_details": [
+            {"name": n, "description": r["description"]}
+            for n, r in server.resources.items()
+        ],
+        "registered_tool_categories": list(registered_tool_categories),
     }
     logger.debug(f"Manifest data constructed: {manifest_data}")
     logger.info(f"Manifest data: {manifest_data}")
     logger.debug("Returning manifest data.")
     return manifest_data
 
+
 async def list_tools_endpoint():
     # Return a flat array of tool names for compatibility
     return list(server.tools.keys())
 
+
 async def list_tools_with_metadata_endpoint():
     # Return the original format with metadata for test runners
-    return {"tools": [{"name": n, "description": server.tool_descriptions.get(n, ""), "parameters": server.parameter_descriptions.get(n, {})} for n in server.tools.keys()],
-            "count": len(server.tools), "categories": list(registered_tool_categories)}
+    return {
+        "tools": [
+            {
+                "name": n,
+                "description": server.tool_descriptions.get(n, ""),
+                "parameters": server.parameter_descriptions.get(n, {}),
+            }
+            for n in server.tools.keys()
+        ],
+        "count": len(server.tools),
+        "categories": list(registered_tool_categories),
+    }
+
 
 async def execute_tool_endpoint(tool_name: str, request: Request):
     """Execute a tool directly via HTTP POST."""
     try:
         # Parse the request body as JSON
@@ -1216,52 +1557,64 @@
 
         # Return the result
         return result
     except Exception as e:
         logger.error(f"Error executing tool {tool_name}: {e}\n{traceback.format_exc()}")
-        return JSONResponse(
-            content={"error": str(e)},
-            status_code=500
-        )
+        return JSONResponse(content={"error": str(e)}, status_code=500)
+
 
 server_start_time = datetime.now()
 
 if __name__ == "__main__":
     print("Starting server")
     signal.signal(signal.SIGTERM, handle_sigterm)
     signal.signal(signal.SIGINT, handle_sigint)
 
     parser = argparse.ArgumentParser(description="Final MCP Server")
-    parser.add_argument("--port", type=int, default=PORT, help=f"Port (default: {PORT})")
-    parser.add_argument("--host", type=str, default="0.0.0.0", help="Host (default: 0.0.0.0)")
+    parser.add_argument(
+        "--port", type=int, default=PORT, help=f"Port (default: {PORT})"
+    )
+    parser.add_argument(
+        "--host", type=str, default="0.0.0.0", help="Host (default: 0.0.0.0)"
+    )
     parser.add_argument("--debug", action="store_true", help="Enable debug mode")
-    parser.add_argument("--timeout", type=int, default=0, help="Auto-shutdown timeout in seconds (0 = no timeout)")
+    parser.add_argument(
+        "--timeout",
+        type=int,
+        default=0,
+        help="Auto-shutdown timeout in seconds (0 = no timeout)",
+    )
     args = parser.parse_args()
 
     PORT = args.port
 
     # Check if port is already in use to avoid bind errors
     import socket
+
     s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
     try:
         s.bind((args.host, args.port))
         s.close()
     except socket.error as e:
         if e.errno == 98:  # Address already in use
-            logger.error(f"Port {args.port} is already in use. Please use a different port.")
+            logger.error(
+                f"Port {args.port} is already in use. Please use a different port."
+            )
             sys.exit(1)
         else:
             logger.error(f"Socket error: {e}")
             sys.exit(1)
 
     pid_file = Path("final_mcp_server.pid")
     timeout_timer = None
     try:
         with open(pid_file, "w") as f:
             f.write(str(os.getpid()))
-        logger.info(f"Starting server on {args.host}:{args.port}, debug={args.debug}, PID: {os.getpid()}")
-        
+        logger.info(
+            f"Starting server on {args.host}:{args.port}, debug={args.debug}, PID: {os.getpid()}"
+        )
+
         # Setup timeout if specified
         if args.timeout > 0:
             timeout_timer = setup_timeout(args.timeout)
 
         # Set timeouts to prevent hanging during initialization
@@ -1269,11 +1622,11 @@
             app,
             host=args.host,
             port=args.port,
             log_level="debug" if args.debug else "info",
             timeout_keep_alive=30,
-            timeout_graceful_shutdown=10
+            timeout_graceful_shutdown=10,
         )
     except Exception as e:
         logger.error(f"Server failed to start or run: {e}\n{traceback.format_exc()}")
     finally:
         # Cancel timeout timer if it exists
would reformat final_mcp_server.py

Oh no! 💥 💔 💥
1 file would be reformatted, 1 file would fail to reformat.
⚠️ Black formatting: NEEDS FIXING
final_mcp_server.py:30:1: F401 'typing.Union' imported but unused
final_mcp_server.py:31:1: F401 'shutil' imported but unused
final_mcp_server.py:32:1: F401 're' imported but unused
final_mcp_server.py:62:63: E261 at least two spaces before inline comment
final_mcp_server.py:72:101: E501 line too long (135 > 100 characters)
final_mcp_server.py:100:5: F401 'fastapi.Response' imported but unused
final_mcp_server.py:100:5: F401 'fastapi.HTTPException' imported but unused
final_mcp_server.py:100:5: F401 'fastapi.BackgroundTasks' imported but unused
final_mcp_server.py:100:5: F401 'fastapi.WebSocket' imported but unused
final_mcp_server.py:100:5: F401 'fastapi.WebSocketDisconnect' imported but unused
final_mcp_server.py:100:101: E501 line too long (114 > 100 characters)
final_mcp_server.py:101:5: F401 'fastapi.responses.StreamingResponse' imported but unused
final_mcp_server.py:102:5: F401 'fastapi.middleware.cors.CORSMiddleware' imported but unused
final_mcp_server.py:103:5: F401 'fastapi.staticfiles.StaticFiles' imported but unused
final_mcp_server.py:104:5: F401 'starlette.responses.Response as StarletteResponse' imported but unused
final_mcp_server.py:105:5: F401 'starlette.background.BackgroundTask as StarletteBackgroundTask' imported but unused
final_mcp_server.py:112:5: F401 'jsonrpcserver' imported but unused
final_mcp_server.py:113:5: F401 'jsonrpcserver.dispatch' imported but unused
final_mcp_server.py:113:5: F401 'jsonrpcserver.Success' imported but unused
final_mcp_server.py:113:5: F401 'jsonrpcserver.Error' imported but unused
final_mcp_server.py:114:5: F401 'jsonrpcserver.method as jsonrpc_method' imported but unused
final_mcp_server.py:114:55: E261 at least two spaces before inline comment
final_mcp_server.py:121:1: E302 expected 2 blank lines, found 1
final_mcp_server.py:126:9: F401 'mcp_vfs_config' imported but unused
final_mcp_server.py:133:9: F401 'fs_journal_tools' imported but unused
final_mcp_server.py:140:9: F401 'ipfs_mcp_fs_integration' imported but unused
final_mcp_server.py:147:9: F401 'multi_backend_fs_integration' imported but unused
final_mcp_server.py:154:9: F401 'integrate_vfs_to_final_mcp' imported but unused
final_mcp_server.py:160:1: E302 expected 2 blank lines, found 1
final_mcp_server.py:167:101: E501 line too long (110 > 100 characters)
final_mcp_server.py:173:101: E501 line too long (135 > 100 characters)
final_mcp_server.py:196:101: E501 line too long (125 > 100 characters)
final_mcp_server.py:214:101: E501 line too long (134 > 100 characters)
final_mcp_server.py:217:101: E501 line too long (108 > 100 characters)
final_mcp_server.py:225:1: E302 expected 2 blank lines, found 1
final_mcp_server.py:226:63: W291 trailing whitespace
final_mcp_server.py:228:5: E301 expected 1 blank line, found 0
final_mcp_server.py:228:40: W291 trailing whitespace
final_mcp_server.py:230:5: E301 expected 1 blank line, found 0
final_mcp_server.py:230:41: W291 trailing whitespace
final_mcp_server.py:232:5: E301 expected 1 blank line, found 0
final_mcp_server.py:232:40: W291 trailing whitespace
final_mcp_server.py:234:5: E301 expected 1 blank line, found 0
final_mcp_server.py:234:41: W291 trailing whitespace
final_mcp_server.py:238:1: E302 expected 2 blank lines, found 1
final_mcp_server.py:253:101: E501 line too long (101 > 100 characters)
final_mcp_server.py:256:1: E302 expected 2 blank lines, found 1
final_mcp_server.py:305:101: E501 line too long (109 > 100 characters)
final_mcp_server.py:316:1: E302 expected 2 blank lines, found 1
final_mcp_server.py:349:101: E501 line too long (104 > 100 characters)
final_mcp_server.py:352:101: E501 line too long (115 > 100 characters)
final_mcp_server.py:359:1: E302 expected 2 blank lines, found 1
final_mcp_server.py:361:1: W293 blank line contains whitespace
final_mcp_server.py:381:1: W293 blank line contains whitespace
final_mcp_server.py:384:101: E501 line too long (102 > 100 characters)
final_mcp_server.py:393:101: E501 line too long (109 > 100 characters)
final_mcp_server.py:444:1: W293 blank line contains whitespace
final_mcp_server.py:445:101: E501 line too long (111 > 100 characters)
final_mcp_server.py:476:1: W293 blank line contains whitespace
final_mcp_server.py:495:39: W291 trailing whitespace
final_mcp_server.py:518:70: W291 trailing whitespace
final_mcp_server.py:519:9: E128 continuation line under-indented for visual indent
final_mcp_server.py:523:101: E501 line too long (191 > 100 characters)
final_mcp_server.py:528:101: E501 line too long (121 > 100 characters)
final_mcp_server.py:532:101: E501 line too long (143 > 100 characters)
final_mcp_server.py:536:1: W293 blank line contains whitespace
final_mcp_server.py:538:9: E128 continuation line under-indented for visual indent
final_mcp_server.py:539:30: W291 trailing whitespace
final_mcp_server.py:542:101: E501 line too long (123 > 100 characters)
final_mcp_server.py:547:101: E501 line too long (126 > 100 characters)
final_mcp_server.py:551:101: E501 line too long (101 > 100 characters)
final_mcp_server.py:555:1: W293 blank line contains whitespace
final_mcp_server.py:557:9: E128 continuation line under-indented for visual indent
final_mcp_server.py:561:101: E501 line too long (167 > 100 characters)
final_mcp_server.py:565:1: W293 blank line contains whitespace
final_mcp_server.py:567:9: E128 continuation line under-indented for visual indent
final_mcp_server.py:570:101: E501 line too long (134 > 100 characters)
final_mcp_server.py:573:1: W293 blank line contains whitespace
final_mcp_server.py:576:1: E302 expected 2 blank lines, found 1
final_mcp_server.py:603:1: E302 expected 2 blank lines, found 1
final_mcp_server.py:633:1: E302 expected 2 blank lines, found 1
final_mcp_server.py:640:55: E261 at least two spaces before inline comment
final_mcp_server.py:640:101: E501 line too long (104 > 100 characters)
final_mcp_server.py:652:1: E402 module level import not at top of file
final_mcp_server.py:654:1: E302 expected 2 blank lines, found 1
final_mcp_server.py:660:101: E501 line too long (106 > 100 characters)
final_mcp_server.py:661:1: W293 blank line contains whitespace
final_mcp_server.py:665:46: E261 at least two spaces before inline comment
final_mcp_server.py:666:101: E501 line too long (102 > 100 characters)
final_mcp_server.py:667:1: W293 blank line contains whitespace
final_mcp_server.py:677:101: E501 line too long (106 > 100 characters)
final_mcp_server.py:688:101: E501 line too long (102 > 100 characters)
final_mcp_server.py:695:1: E302 expected 2 blank lines, found 1
final_mcp_server.py:699:1: E302 expected 2 blank lines, found 1
final_mcp_server.py:704:1: E302 expected 2 blank lines, found 1
final_mcp_server.py:715:1: E305 expected 2 blank lines after class or function definition, found 1
final_mcp_server.py:718:1: E302 expected 2 blank lines, found 1
final_mcp_server.py:720:1: W293 blank line contains whitespace
final_mcp_server.py:724:1: W293 blank line contains whitespace
final_mcp_server.py:729:1: W293 blank line contains whitespace
final_mcp_server.py:732:1: W293 blank line contains whitespace
final_mcp_server.py:739:1: W293 blank line contains whitespace
final_mcp_server.py:742:1: W293 blank line contains whitespace
final_mcp_server.py:751:1: W293 blank line contains whitespace
final_mcp_server.py:756:1: W293 blank line contains whitespace
final_mcp_server.py:777:1: W293 blank line contains whitespace
final_mcp_server.py:782:1: W293 blank line contains whitespace
final_mcp_server.py:785:1: W293 blank line contains whitespace
final_mcp_server.py:791:1: W293 blank line contains whitespace
final_mcp_server.py:803:1: E302 expected 2 blank lines, found 1
final_mcp_server.py:814:1: W293 blank line contains whitespace
final_mcp_server.py:829:1: W293 blank line contains whitespace
final_mcp_server.py:834:1: E302 expected 2 blank lines, found 1
final_mcp_server.py:836:1: W293 blank line contains whitespace
final_mcp_server.py:844:1: W293 blank line contains whitespace
final_mcp_server.py:848:9: F401 'random' imported but unused
final_mcp_server.py:849:1: W293 blank line contains whitespace
final_mcp_server.py:853:1: W293 blank line contains whitespace
final_mcp_server.py:859:1: W293 blank line contains whitespace
final_mcp_server.py:866:1: W293 blank line contains whitespace
final_mcp_server.py:876:1: W293 blank line contains whitespace
final_mcp_server.py:881:1: W293 blank line contains whitespace
final_mcp_server.py:887:1: W293 blank line contains whitespace
final_mcp_server.py:892:1: W293 blank line contains whitespace
final_mcp_server.py:896:1: W293 blank line contains whitespace
final_mcp_server.py:905:1: W293 blank line contains whitespace
final_mcp_server.py:906:101: E501 line too long (111 > 100 characters)
final_mcp_server.py:915:1: W293 blank line contains whitespace
final_mcp_server.py:923:101: E501 line too long (108 > 100 characters)
final_mcp_server.py:932:1: W293 blank line contains whitespace
final_mcp_server.py:959:87: E261 at least two spaces before inline comment
final_mcp_server.py:959:101: E501 line too long (102 > 100 characters)
final_mcp_server.py:963:101: E501 line too long (108 > 100 characters)
final_mcp_server.py:975:9: E115 expected an indented block (comment)
final_mcp_server.py:981:22: E111 indentation is not a multiple of 4
final_mcp_server.py:981:22: E117 over-indented
final_mcp_server.py:981:101: E501 line too long (123 > 100 characters)
final_mcp_server.py:986:101: E501 line too long (106 > 100 characters)
final_mcp_server.py:991:13: E303 too many blank lines (2)
final_mcp_server.py:1013:76: E261 at least two spaces before inline comment
final_mcp_server.py:1013:101: E501 line too long (112 > 100 characters)
final_mcp_server.py:1048:101: E501 line too long (144 > 100 characters)
final_mcp_server.py:1061:101: E501 line too long (134 > 100 characters)
final_mcp_server.py:1071:101: E501 line too long (124 > 100 characters)
final_mcp_server.py:1085:101: E501 line too long (107 > 100 characters)
final_mcp_server.py:1087:13: E122 continuation line missing indentation or outdented
final_mcp_server.py:1105:101: E501 line too long (130 > 100 characters)
final_mcp_server.py:1111:101: E501 line too long (129 > 100 characters)
final_mcp_server.py:1113:101: E501 line too long (105 > 100 characters)
final_mcp_server.py:1120:9: E722 do not use bare 'except'
final_mcp_server.py:1120:16: E261 at least two spaces before inline comment
final_mcp_server.py:1122:101: E501 line too long (152 > 100 characters)
final_mcp_server.py:1124:1: E302 expected 2 blank lines, found 1
final_mcp_server.py:1125:101: E501 line too long (102 > 100 characters)
final_mcp_server.py:1127:1: E302 expected 2 blank lines, found 1
final_mcp_server.py:1131:101: E501 line too long (109 > 100 characters)
final_mcp_server.py:1133:1: E302 expected 2 blank lines, found 1
final_mcp_server.py:1135:1: E302 expected 2 blank lines, found 1
final_mcp_server.py:1143:101: E501 line too long (105 > 100 characters)
final_mcp_server.py:1181:1: E302 expected 2 blank lines, found 1
final_mcp_server.py:1188:44: E261 at least two spaces before inline comment
final_mcp_server.py:1189:52: E261 at least two spaces before inline comment
final_mcp_server.py:1190:101: E501 line too long (175 > 100 characters)
final_mcp_server.py:1191:101: E501 line too long (112 > 100 characters)
final_mcp_server.py:1199:1: E302 expected 2 blank lines, found 1
final_mcp_server.py:1203:1: E302 expected 2 blank lines, found 1
final_mcp_server.py:1205:101: E501 line too long (172 > 100 characters)
final_mcp_server.py:1208:1: E302 expected 2 blank lines, found 1
final_mcp_server.py:1237:101: E501 line too long (115 > 100 characters)
final_mcp_server.py:1261:101: E501 line too long (106 > 100 characters)
final_mcp_server.py:1262:1: W293 blank line contains whitespace
src/backends/modular_backend.py:607:29: E999 SyntaxError: leading zeros in decimal integer literals are not permitted; use an 0o prefix for octal integers
⚠️ Flake8 linting: ISSUES FOUND
src/backends/modular_backend.py:607: error: leading zeros in decimal integer literals are not permitted; use an 0o prefix for octal integers  [syntax]
Found 1 error in 1 file (errors prevented further checking)
⚠️ MyPy type checking: ISSUES FOUND
[main]	INFO	profile include tests: None
[main]	INFO	profile exclude tests: None
[main]	INFO	cli include tests: None
[main]	INFO	cli exclude tests: None
[main]	INFO	running on Python 3.12.3
Run started:2025-06-29 19:20:06.322486

Test results:
>> Issue: [B110:try_except_pass] Try, Except, Pass detected.
   Severity: Low   Confidence: High
   CWE: CWE-703 (https://cwe.mitre.org/data/definitions/703.html)
   More Info: https://bandit.readthedocs.io/en/1.8.5/plugins/b110_try_except_pass.html
   Location: ./final_mcp_server.py:1120:8
1119	                req_id = parsed_req.get("id")
1120	        except: # pylint: disable=bare-except
1121	            pass
1122	        return JSONResponse({"jsonrpc": "2.0", "error": {"code": -32603, "message": f"Internal server error: {str(e)}"}, "id": req_id}, status_code=500)

--------------------------------------------------
>> Issue: [B104:hardcoded_bind_all_interfaces] Possible binding to all interfaces.
   Severity: Medium   Confidence: Medium
   CWE: CWE-605 (https://cwe.mitre.org/data/definitions/605.html)
   More Info: https://bandit.readthedocs.io/en/1.8.5/plugins/b104_hardcoded_bind_all_interfaces.html
   Location: ./final_mcp_server.py:1235:52
1234	    parser.add_argument("--port", type=int, default=PORT, help=f"Port (default: {PORT})")
1235	    parser.add_argument("--host", type=str, default="0.0.0.0", help="Host (default: 0.0.0.0)")
1236	    parser.add_argument("--debug", action="store_true", help="Enable debug mode")

--------------------------------------------------

Code scanned:
	Total lines of code: 1696
	Total lines skipped (#nosec): 0
	Total potential issues skipped due to specifically being disabled (e.g., #nosec BXXX): 0

Run metrics:
	Total issues (by severity):
		Undefined: 0
		Low: 1
		Medium: 1
		High: 0
	Total issues (by confidence):
		Undefined: 0
		Low: 0
		Medium: 1
		High: 1
Files skipped (1):
	src/backends/modular_backend.py (syntax error while parsing AST from file)
⚠️ Bandit security: ISSUES FOUND
