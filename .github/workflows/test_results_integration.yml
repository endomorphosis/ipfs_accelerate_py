name: Test Results Integration

on:
  # Run on schedule (daily)
  schedule:
    - cron: '0 1 * * *'  # Run at 1 AM UTC every day
  
  # Run on push to specific paths
  push:
    branches:
      - main
    paths:
      - 'generators/**'
      - 'duckdb_api/**'
      - 'fixed_web_platform/**'
      - '.github/workflows/test_results_integration.yml'
  
  # Run on pull request to specific paths
  pull_request:
    branches:
      - main
    paths:
      - 'generators/**'
      - 'duckdb_api/**'
      - 'fixed_web_platform/**'
  
  # Allow manual trigger with parameters
  workflow_dispatch:
    inputs:
      models:
        description: 'Models to test (comma-separated)'
        required: false
        default: 'prajjwal1/bert-tiny,BAAI/bge-small-en-v1.5'
      hardware:
        description: 'Hardware platforms to test (comma-separated)'
        required: false
        default: 'cpu'
      include_web:
        description: 'Include web platform tests'
        required: false
        default: false
        type: boolean

env:
  BENCHMARK_DB_PATH: ./benchmark_db_ci.duckdb
  DEPRECATE_JSON_OUTPUT: 1
  PYTHONPATH: ${{ github.workspace }}

jobs:
  setup_database:
    runs-on: ubuntu-latest
    outputs:
      db_path: ${{ steps.setup_db.outputs.db_path }}
      today_date: ${{ steps.date.outputs.today_date }}
      run_id: ${{ steps.runid.outputs.run_id }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v3
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r duckdb_api/scripts/requirements_db.txt

      - name: Get date
        id: date
        run: echo "today_date=$(date +'%Y%m%d')" >> $GITHUB_OUTPUT

      - name: Generate run ID
        id: runid
        run: echo "run_id=$(date +'%Y%m%d%H%M%S')" >> $GITHUB_OUTPUT

      - name: Set up database
        id: setup_db
        run: |
          mkdir -p benchmark_db
          python duckdb_api/scripts/create_benchmark_schema.py --output $BENCHMARK_DB_PATH --sample-data
          echo "db_path=$BENCHMARK_DB_PATH" >> $GITHUB_OUTPUT

      - name: Generate CI metadata
        run: |
          cat > ci_metadata.json << EOF
          {
            "workflow_id": "${{ github.run_id }}",
            "workflow_name": "${{ github.workflow }}",
            "run_id": "${{ steps.runid.outputs.run_id }}",
            "github_ref": "${{ github.ref }}",
            "github_repository": "${{ github.repository }}",
            "github_actor": "${{ github.actor }}",
            "trigger_event": "${{ github.event_name }}",
            "timestamp": "$(date -Iseconds)"
          }
          EOF

      - name: Upload database
        uses: actions/upload-artifact@v3
        with:
          name: benchmark-db
          path: ${{ env.BENCHMARK_DB_PATH }}

      - name: Upload CI metadata
        uses: actions/upload-artifact@v3
        with:
          name: ci-metadata
          path: ci_metadata.json

  run_tests:
    needs: setup_database
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-latest]
        python-version: ['3.10']
        model: ${{ github.event.inputs.models != '' && fromJSON('["' + join('","', split(github.event.inputs.models, ',')) + '"]') || fromJSON('["prajjwal1/bert-tiny", "BAAI/bge-small-en-v1.5"]') }}
        hardware: ${{ github.event.inputs.hardware != '' && fromJSON('["' + join('","', split(github.event.inputs.hardware, ',')) + '"]') || fromJSON('["cpu"]') }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v3
        with:
          fetch-depth: 0

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v4
        with:
          python-version: ${{ matrix.python-version }}
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install duckdb pandas torch torchvision torchaudio transformers pytest pytest-cov
          pip install -r requirements_api.txt

      - name: Download database
        uses: actions/download-artifact@v3
        with:
          name: benchmark-db
          path: .

      - name: Download CI metadata
        uses: actions/download-artifact@v3
        with:
          name: ci-metadata
          path: .

      - name: Run model tests
        run: |
          # Run tests and store results directly in the database
          python generators/models/test_ipfs_accelerate.py \
            --models ${{ matrix.model }} \
            --endpoints ${{ matrix.hardware }} \
            --db-path ${{ env.BENCHMARK_DB_PATH }} \
            --runs 3 \
            --ci-mode \
            --run-id ${{ needs.setup_database.outputs.run_id }}

      - name: Verify database contains results
        run: |
          # Verify database has the new results
          python -c "import duckdb; conn = duckdb.connect('${{ env.BENCHMARK_DB_PATH }}'); print(conn.execute('SELECT COUNT(*) FROM test_results WHERE run_id=\\'${{ needs.setup_database.outputs.run_id }}\\'').fetchone()[0])"
      
      - name: Generate test report
        run: |
          python generators/models/test_ipfs_accelerate.py \
            --db-path ${{ env.BENCHMARK_DB_PATH }} \
            --report \
            --format markdown \
            --output test_report_${{ matrix.model }}_${{ matrix.hardware }}.md \
            --run-id ${{ needs.setup_database.outputs.run_id }}

      - name: Upload updated database
        uses: actions/upload-artifact@v3
        with:
          name: benchmark-db-${{ matrix.model }}-${{ matrix.hardware }}
          path: ${{ env.BENCHMARK_DB_PATH }}

      - name: Upload test reports
        uses: actions/upload-artifact@v3
        with:
          name: test-reports-${{ matrix.model }}-${{ matrix.hardware }}
          path: test_report_*.md

  run_web_tests:
    needs: setup_database
    if: ${{ github.event.inputs.include_web == 'true' }}
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v3
        with:
          fetch-depth: 0

      - name: Set up Node.js
        uses: actions/setup-node@v3
        with:
          node-version: '18'

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install duckdb pandas torch torchvision torchaudio transformers pytest pytest-cov
          pip install -r requirements_api.txt
          npm install -g @xenova/transformers

      - name: Download database
        uses: actions/download-artifact@v3
        with:
          name: benchmark-db
          path: .

      - name: Download CI metadata
        uses: actions/download-artifact@v3
        with:
          name: ci-metadata
          path: .

      - name: Run web platform tests
        run: |
          # Run web platform tests
          python fixed_web_platform/web_platform_test_runner.py \
            --model bert-base-uncased \
            --platform webnn \
            --run-id ${{ needs.setup_database.outputs.run_id }} \
            --db-path ${{ env.BENCHMARK_DB_PATH }} \
            --ci-mode

      - name: Upload updated database
        uses: actions/upload-artifact@v3
        with:
          name: benchmark-db-web
          path: ${{ env.BENCHMARK_DB_PATH }}

  consolidate_results:
    needs: [setup_database, run_tests]
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v3
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
          cache: 'pip'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r duckdb_api/scripts/requirements_db.txt
          pip install requests pandas numpy matplotlib plotly

      - name: Download all artifacts
        uses: actions/download-artifact@v3
        with:
          path: artifacts

      - name: List downloaded artifacts
        run: |
          find artifacts -type f | sort

      - name: Process CI artifacts with integrator
        run: |
          python duckdb_api/scripts/ci_benchmark_integrator.py \
            --artifacts-dir ./artifacts \
            --db ./consolidated_db.duckdb \
            --ci-metadata ./artifacts/ci-metadata/ci_metadata.json \
            --commit ${{ github.sha }} \
            --branch ${{ github.ref_name }} \
            --build-id ${{ needs.setup_database.outputs.run_id }} \
            --ci-platform "github" \
            --archive-artifacts \
            --archive-dir ./archived_artifacts

      - name: Generate compatibility matrix
        run: |
          # Generate an updated compatibility matrix
          python duckdb_api/visualization/generate_compatibility_matrix.py \
            --db-path ./consolidated_db.duckdb \
            --format markdown \
            --output compatibility_matrix_${{ needs.setup_database.outputs.today_date }}.md

      - name: Generate performance report
        run: |
          # Generate performance report
          python duckdb_api/core/benchmark_db_query.py \
            --db ./consolidated_db.duckdb \
            --report performance \
            --format html \
            --output performance_report_${{ needs.setup_database.outputs.today_date }}.html

      - name: Detect performance regressions
        id: regression
        run: |
          python duckdb_api/analysis/benchmark_regression_detector.py \
            --db ./consolidated_db.duckdb \
            --run-id "${{ needs.setup_database.outputs.run_id }}" \
            --threshold 0.1 \
            --window 5 \
            --metrics "throughput,latency,memory_peak" \
            --output regression_report_${{ needs.setup_database.outputs.today_date }}.html \
            --format html

          # Additionally create markdown report
          python duckdb_api/analysis/benchmark_regression_detector.py \
            --db ./consolidated_db.duckdb \
            --run-id "${{ needs.setup_database.outputs.run_id }}" \
            --threshold 0.1 \
            --window 5 \
            --output regression_report_${{ needs.setup_database.outputs.today_date }}.md \
            --format markdown

      - name: Create GitHub issue for regressions
        if: ${{ github.event_name == 'schedule' || github.event_name == 'workflow_dispatch' }}
        run: |
          python duckdb_api/analysis/benchmark_regression_detector.py \
            --db ./consolidated_db.duckdb \
            --run-id "${{ needs.setup_database.outputs.run_id }}" \
            --threshold 0.1 \
            --create-issues \
            --github-token ${{ secrets.GITHUB_TOKEN }} \
            --github-repo ${{ github.repository }}

      - name: Upload consolidated database
        uses: actions/upload-artifact@v3
        with:
          name: consolidated-benchmark-db
          path: consolidated_db.duckdb

      - name: Upload reports
        uses: actions/upload-artifact@v3
        with:
          name: benchmark-reports
          path: |
            compatibility_matrix_*.md
            performance_report_*.html
            regression_report_*.html
            regression_report_*.md

  publish_reports:
    needs: [setup_database, consolidate_results]
    if: github.event_name == 'schedule' || github.event_name == 'push' && github.ref == 'refs/heads/main'
    runs-on: ubuntu-latest
    permissions:
      contents: read
      pages: write
      id-token: write
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v3
        with:
          fetch-depth: 0

      - name: Setup Pages
        uses: actions/configure-pages@v3

      - name: Download reports
        uses: actions/download-artifact@v3
        with:
          name: benchmark-reports
          path: reports

      - name: Create report index
        run: |
          # Generate HTML index file for reports
          cat > reports/index.html << EOF
          <!DOCTYPE html>
          <html>
          <head>
              <title>IPFS Accelerate Test Reports</title>
              <meta charset="utf-8">
              <meta name="viewport" content="width=device-width, initial-scale=1">
              <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0-alpha1/dist/css/bootstrap.min.css" rel="stylesheet">
          </head>
          <body>
              <div class="container mt-4">
                  <h1>IPFS Accelerate Test Reports</h1>
                  <p>Latest report date: ${{ needs.setup_database.outputs.today_date }}</p>
                  
                  <h2>Latest Reports</h2>
                  <ul>
                      <li><a href="compatibility_matrix_${{ needs.setup_database.outputs.today_date }}.md">Compatibility Matrix</a></li>
                      <li><a href="performance_report_${{ needs.setup_database.outputs.today_date }}.html">Performance Report</a></li>
                      <li><a href="regression_report_${{ needs.setup_database.outputs.today_date }}.html">Regression Report</a></li>
                  </ul>
                  
                  <h2>CI/CD Integration</h2>
                  <p>
                    This report was automatically generated by the CI/CD system.
                    The system runs comprehensive tests across hardware platforms 
                    and automatically detects performance regressions.
                  </p>
                  <p>
                    <a href="https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}" class="btn btn-primary">
                      View CI Run
                    </a>
                  </p>
              </div>
          </body>
          </html>
          EOF

      - name: Setup GitHub Pages
        uses: actions/configure-pages@v3

      - name: Upload Pages artifact
        uses: actions/upload-pages-artifact@v2
        with:
          path: reports

      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v2

  archive_database:
    needs: [setup_database, consolidate_results]
    if: github.event_name == 'schedule' || github.event_name == 'push' && github.ref == 'refs/heads/main'
    runs-on: ubuntu-latest
    steps:
      - name: Download consolidated database
        uses: actions/download-artifact@v3
        with:
          name: consolidated-benchmark-db
          path: db

      - name: Create historical database copy
        run: |
          mkdir -p historical_db
          cp db/consolidated_db.duckdb historical_db/benchmark_${{ needs.setup_database.outputs.today_date }}.duckdb

      - name: Upload historical database
        uses: actions/upload-artifact@v3
        with:
          name: historical-benchmark-db
          path: historical_db/
          retention-days: 90