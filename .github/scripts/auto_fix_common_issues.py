#!/usr/bin/env python3
"""
Auto-Fix Common Issues Script

This script attempts to automatically fix common workflow failures
based on the failure analysis.
"""

import json
import os
import re
import sys
from pathlib import Path
from typing import Dict, List, Any, Optional


class AutoFixer:
    """Automatically fixes common workflow issues."""
    
    def __init__(self, repo_root: str):
        """Initialize the auto-fixer."""
        self.repo_root = Path(repo_root)
        self.fixes_applied = []
        self.changes_made = False
    
    def apply_fixes(self, analysis: Dict[str, Any], failure_data: Dict[str, Any]) -> bool:
        """
        Apply automated fixes based on the failure analysis.
        
        Args:
            analysis: The detailed analysis from workflow_failure_analyzer
            failure_data: The original failure data
            
        Returns:
            True if fixes were applied, False otherwise
        """
        category = analysis.get('category', 'UNKNOWN')
        
        # Handle both string and enum-like category formats
        if isinstance(category, str):
            category = category.upper().replace('FAILURECATEGORY.', '')
        else:
            category = str(category).upper().replace('FAILURECATEGORY.', '')
        
        print(f"Processing category: {category}")
        
        # Route to appropriate fix handler
        if category == 'DEPENDENCY':
            return self._fix_dependency_issues(analysis, failure_data)
        elif category == 'TIMEOUT':
            return self._fix_timeout_issues(analysis, failure_data)
        elif category == 'SYNTAX':
            return self._fix_syntax_issues(analysis, failure_data)
        elif category == 'DOCKER':
            return self._fix_docker_issues(analysis, failure_data)
        elif category == 'PERMISSION':
            return self._fix_permission_issues(analysis, failure_data)
        else:
            print(f"No automated fix available for category: {category}")
            return False
    
    def _fix_dependency_issues(self, analysis: Dict[str, Any], failure_data: Dict[str, Any]) -> bool:
        """Fix Python dependency issues."""
        print("Attempting to fix dependency issues...")
        
        # Extract module name from logs
        logs = self._get_failure_logs(failure_data)
        
        # Try multiple patterns to extract module names
        patterns = [
            r"No module named ['\"]([^'\"]+)['\"]",
            r"ModuleNotFoundError: No module named ['\"]([^'\"]+)['\"]",
            r"ImportError: No module named ['\"]([^'\"]+)['\"]",
            r"cannot import name .* from ['\"]([^'\"]+)['\"]",
        ]
        
        missing_modules = []
        for pattern in patterns:
            matches = re.findall(pattern, logs)
            missing_modules.extend(matches)
        
        # Remove duplicates and filter out empty strings
        missing_modules = list(set([m.strip() for m in missing_modules if m.strip()]))
        
        if not missing_modules:
            print("Could not identify missing module from logs")
            print(f"Logs excerpt: {logs[:200]}")
            return False
        
        print(f"Identified missing modules: {missing_modules}")
        
        # Try to add to requirements.txt
        requirements_file = self.repo_root / "requirements.txt"
        if requirements_file.exists():
            with open(requirements_file, 'r') as f:
                current_requirements = f.read()
            
            # Check if module already in requirements
            modules_to_add = []
            for module in missing_modules:
                if module not in current_requirements:
                    modules_to_add.append(module)
            
            if modules_to_add:
                with open(requirements_file, 'a') as f:
                    f.write('\n# Added by auto-heal to fix dependency issues\n')
                    for module in modules_to_add:
                        f.write(f'{module}\n')
                
                self.fixes_applied.append(f"Added {', '.join(modules_to_add)} to requirements.txt")
                self.changes_made = True
                print(f"Added modules to requirements.txt: {modules_to_add}")
                return True
        else:
            # Create requirements.txt
            with open(requirements_file, 'w') as f:
                f.write('# Auto-generated by auto-heal\n')
                for module in missing_modules:
                    f.write(f'{module}\n')
            
            self.fixes_applied.append(f"Created requirements.txt with {', '.join(missing_modules)}")
            self.changes_made = True
            print(f"Created requirements.txt with modules: {missing_modules}")
            return True
        
        return False
    
    def _fix_timeout_issues(self, analysis: Dict[str, Any], failure_data: Dict[str, Any]) -> bool:
        """Fix timeout issues by increasing timeout values."""
        print("Attempting to fix timeout issues...")
        
        workflow_name = failure_data.get('workflow_name', '')
        
        # Find the workflow file
        workflows_dir = self.repo_root / ".github" / "workflows"
        workflow_files = []
        
        if workflows_dir.exists():
            for wf_file in workflows_dir.glob("*.yml"):
                with open(wf_file, 'r') as f:
                    content = f.read()
                    if workflow_name in content or wf_file.stem in workflow_name.lower().replace(' ', '-'):
                        workflow_files.append(wf_file)
        
        if not workflow_files:
            print("Could not find workflow file")
            return False
        
        # Update timeout in the workflow file(s)
        for wf_file in workflow_files:
            with open(wf_file, 'r') as f:
                lines = f.readlines()
            
            modified = False
            new_lines = []
            
            for i, line in enumerate(lines):
                if 'timeout-minutes:' in line:
                    # Extract current timeout
                    match = re.search(r'timeout-minutes:\s*(\d+)', line)
                    if match:
                        current_timeout = int(match.group(1))
                        new_timeout = min(current_timeout * 2, 360)  # Double it, max 6 hours
                        
                        # Replace the timeout value
                        new_line = re.sub(
                            r'timeout-minutes:\s*\d+',
                            f'timeout-minutes: {new_timeout}',
                            line
                        )
                        new_lines.append(new_line)
                        modified = True
                        print(f"Increased timeout from {current_timeout} to {new_timeout} minutes")
                    else:
                        new_lines.append(line)
                else:
                    new_lines.append(line)
            
            if modified:
                with open(wf_file, 'w') as f:
                    f.writelines(new_lines)
                
                self.fixes_applied.append(f"Increased timeout values in {wf_file.name}")
                self.changes_made = True
                return True
        
        return False
    
    def _fix_syntax_issues(self, analysis: Dict[str, Any], failure_data: Dict[str, Any]) -> bool:
        """Fix syntax issues - limited automated capability."""
        print("Syntax errors require manual intervention in most cases")
        
        # We can try to fix common YAML syntax issues
        affected_files = analysis.get('affected_files', [])
        
        for file_path in affected_files:
            if file_path.endswith(('.yml', '.yaml')):
                full_path = self.repo_root / file_path
                if full_path.exists():
                    # Try to fix common YAML issues
                    if self._fix_yaml_syntax(full_path):
                        self.fixes_applied.append(f"Fixed YAML syntax in {file_path}")
                        self.changes_made = True
                        return True
        
        return False
    
    def _fix_yaml_syntax(self, file_path: Path) -> bool:
        """Fix common YAML syntax errors."""
        try:
            with open(file_path, 'r') as f:
                content = f.read()
            
            original_content = content
            
            # Fix common issues:
            # 1. Inconsistent indentation (try to fix 2-space YAML)
            # 2. Missing colons
            # 3. Trailing spaces
            
            # Remove trailing whitespace
            lines = content.split('\n')
            lines = [line.rstrip() for line in lines]
            content = '\n'.join(lines)
            
            if content != original_content:
                with open(file_path, 'w') as f:
                    f.write(content)
                print(f"Fixed trailing whitespace in {file_path}")
                return True
            
        except Exception as e:
            print(f"Could not fix YAML syntax: {e}")
        
        return False
    
    def _fix_docker_issues(self, analysis: Dict[str, Any], failure_data: Dict[str, Any]) -> bool:
        """Fix Docker-related issues."""
        print("Docker issues often require manual intervention")
        
        # We can try to fix common Dockerfile issues
        dockerfile = self.repo_root / "Dockerfile"
        if dockerfile.exists():
            with open(dockerfile, 'r') as f:
                content = f.read()
            
            original_content = content
            
            # Fix common issues:
            # 1. Missing base image version
            # 2. Trailing slashes in COPY commands
            
            # Add more sophisticated fixes here
            
            if content != original_content:
                with open(dockerfile, 'w') as f:
                    f.write(content)
                
                self.fixes_applied.append("Fixed Dockerfile syntax issues")
                self.changes_made = True
                return True
        
        return False
    
    def _fix_permission_issues(self, analysis: Dict[str, Any], failure_data: Dict[str, Any]) -> bool:
        """Fix permission issues."""
        print("Attempting to fix permission issues...")
        
        workflow_name = failure_data.get('workflow_name', '')
        
        # Find the workflow file
        workflows_dir = self.repo_root / ".github" / "workflows"
        workflow_files = []
        
        if workflows_dir.exists():
            for wf_file in workflows_dir.glob("*.yml"):
                with open(wf_file, 'r') as f:
                    content = f.read()
                    if workflow_name in content:
                        workflow_files.append(wf_file)
        
        # Add permissions block if missing
        for wf_file in workflow_files:
            with open(wf_file, 'r') as f:
                content = f.read()
            
            if 'permissions:' not in content:
                # Add basic permissions after the 'on:' block
                lines = content.split('\n')
                new_lines = []
                added = False
                
                for i, line in enumerate(lines):
                    new_lines.append(line)
                    if not added and line.strip().startswith('on:'):
                        # Find the end of the 'on' block
                        indent_level = len(line) - len(line.lstrip())
                        j = i + 1
                        while j < len(lines) and (lines[j].strip() == '' or 
                              (lines[j].strip() and len(lines[j]) - len(lines[j].lstrip()) > indent_level)):
                            j += 1
                        
                        # Insert permissions before jobs
                        if j < len(lines):
                            new_lines.extend(lines[i+1:j])
                            new_lines.append('\npermissions:')
                            new_lines.append('  contents: write')
                            new_lines.append('  issues: write')
                            new_lines.append('  pull-requests: write')
                            new_lines.append('')
                            new_lines.extend(lines[j:])
                            added = True
                            break
                
                if added:
                    with open(wf_file, 'w') as f:
                        f.write('\n'.join(new_lines))
                    
                    self.fixes_applied.append(f"Added permissions block to {wf_file.name}")
                    self.changes_made = True
                    return True
        
        return False
    
    def _get_failure_logs(self, failure_data: Dict[str, Any]) -> str:
        """Extract all failure logs as a single string."""
        logs = []
        for detail in failure_data.get('failure_details', []):
            logs.append(detail.get('error_logs', ''))
        return '\n'.join(logs)
    
    def get_summary(self) -> str:
        """Get a summary of fixes applied."""
        if not self.fixes_applied:
            return "No automated fixes were applied."
        
        return "Automated fixes applied:\n" + '\n'.join(f"- {fix}" for fix in self.fixes_applied)


def main():
    """Main entry point."""
    if len(sys.argv) < 3:
        print("Usage: python auto_fix_common_issues.py <failure_analysis.json> <detailed_analysis.json>")
        sys.exit(1)
    
    # Load failure data
    with open(sys.argv[1], 'r') as f:
        failure_data = json.load(f)
    
    # Load detailed analysis
    with open(sys.argv[2], 'r') as f:
        analysis = json.load(f)
    
    # Get repository root (assume script is in .github/scripts/)
    repo_root = Path(__file__).parent.parent.parent
    
    # Apply fixes
    fixer = AutoFixer(str(repo_root))
    success = fixer.apply_fixes(analysis, failure_data)
    
    # Print summary
    print("\n" + "="*60)
    print(fixer.get_summary())
    print("="*60)
    
    # Save summary for workflow
    summary = {
        'fixes_applied': fixer.fixes_applied,
        'changes_made': fixer.changes_made,
        'success': success
    }
    
    with open('auto_fix_summary.json', 'w') as f:
        json.dump(summary, f, indent=2)
    
    # Exit with appropriate code
    sys.exit(0 if success else 1)


if __name__ == '__main__':
    main()
